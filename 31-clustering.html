<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.9.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>31&nbsp; Unsupervised Learning and Clustering – BANA 4080: Data Mining</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./32-dimension-reduction.html" rel="next">
<link href="./30-feature-engineering.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-4f72c1afe59a4edb82ad8e59b4b7d712.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-cada5050e646ab9f5721bf60d918d5a1.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-4f72c1afe59a4edb82ad8e59b4b7d712.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-4cfdc3d736ecff161be1eb1d41a540a2.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-c63e2d212c982719136a27eaebaaad95.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-4cfdc3d736ecff161be1eb1d41a540a2.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./31-clustering.html">Module 12</a></li><li class="breadcrumb-item"><a href="./31-clustering.html"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Unsupervised Learning and Clustering</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">BANA 4080: Data Mining</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/bradleyboehmke/uc-bana-4080" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./BANA-4080--Data-Mining.epub" title="Download ePub" class="quarto-navigation-tool px-1" aria-label="Download ePub"><i class="bi bi-journal"></i></a>
    <a href="https://twitter.com/intent/tweet?url=|url|" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro-data-mining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-preparing-for-code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Setting Up Your Python Environment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-python-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python Basics – Working with Data and Variables</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 2</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-jupyter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Getting Started with Jupyter Notebooks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-data-structures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Data Structures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-libraries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Packages, Libraries, and Modules</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-importing-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Importing Data and Exploring Pandas DataFrames</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-dataframes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Deeper Dive on DataFrames</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-subsetting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Subsetting Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 4</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-manipulating-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Manipulating Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_aggregating_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Summarizing Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-joining-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Relational data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 5</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-data-viz-pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Intro to Data Visualization with Pandas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-data-viz-matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Fundamentals of Plotting with Matplotlib</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-data-viz-bokeh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Interactive Data Visualization with Bokeh</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 6</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-control-statements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Controlling Program Flow with Conditional Statements</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-iteration-statements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Controlling Repetition with Iteration Statements</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Writing Your Own Functions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 7</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-intro-ml-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Introduction to Machine Learning and Artificial Intelligence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-before-we-build.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Before You Build: Key Considerations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 8</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-correlation-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Correlation and Linear Regression Foundations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-regression-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Evaluating Regression Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 9</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Introduction to Logistic Regression for Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-classification-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Evaluating Classification Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 10</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-decision-trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Decision Trees: Foundations and Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26-random-forests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Random Forests: Ensemble Power and Robustness</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./27-feature-importance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Understanding Feature Importance: Peeking Inside the Black Box</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 11</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./28-cross-validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Cross-validation: Reliable model evaluation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./29-hyperparameter-tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning: Finding Optimal Model Configurations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30-feature-engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Feature Engineering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 12</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./31-clustering.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Unsupervised Learning and Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./32-dimension-reduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Dimension Reduction with PCA</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 13</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./33-modern-ml-algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Beyond the Basics: Modern Machine Learning Algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./34-ml-roadmap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">The Machine Learning Roadmap: Where to Go Next</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99-anaconda-install.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Anaconda Installation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99-vscode-install.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">VS Code Installation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction-to-unsupervised-learning" id="toc-introduction-to-unsupervised-learning" class="nav-link active" data-scroll-target="#introduction-to-unsupervised-learning"><span class="header-section-number">31.1</span> Introduction to Unsupervised Learning</a>
  <ul class="collapse">
  <li><a href="#quick-refresh-what-is-unsupervised-learning" id="toc-quick-refresh-what-is-unsupervised-learning" class="nav-link" data-scroll-target="#quick-refresh-what-is-unsupervised-learning">Quick Refresh: What Is Unsupervised Learning?</a></li>
  <li><a href="#when-and-why-we-use-it" id="toc-when-and-why-we-use-it" class="nav-link" data-scroll-target="#when-and-why-we-use-it">When and Why We Use It</a></li>
  <li><a href="#two-main-types-of-unsupervised-learning" id="toc-two-main-types-of-unsupervised-learning" class="nav-link" data-scroll-target="#two-main-types-of-unsupervised-learning">Two Main Types of Unsupervised Learning</a></li>
  </ul></li>
  <li><a href="#clustering-finding-hidden-structure-in-data" id="toc-clustering-finding-hidden-structure-in-data" class="nav-link" data-scroll-target="#clustering-finding-hidden-structure-in-data"><span class="header-section-number">31.2</span> Clustering: Finding Hidden Structure in Data</a>
  <ul class="collapse">
  <li><a href="#the-goal-of-clustering" id="toc-the-goal-of-clustering" class="nav-link" data-scroll-target="#the-goal-of-clustering">The Goal of Clustering</a></li>
  <li><a href="#real-world-examples" id="toc-real-world-examples" class="nav-link" data-scroll-target="#real-world-examples">Real-World Examples</a></li>
  <li><a href="#key-terms-distance-similarity-and-centroids" id="toc-key-terms-distance-similarity-and-centroids" class="nav-link" data-scroll-target="#key-terms-distance-similarity-and-centroids">Key Terms: Distance, Similarity, and Centroids</a></li>
  </ul></li>
  <li><a href="#the-k-means-algorithm" id="toc-the-k-means-algorithm" class="nav-link" data-scroll-target="#the-k-means-algorithm"><span class="header-section-number">31.3</span> The K-Means Algorithm</a>
  <ul class="collapse">
  <li><a href="#step-by-step-overview" id="toc-step-by-step-overview" class="nav-link" data-scroll-target="#step-by-step-overview">Step-by-Step Overview</a></li>
  <li><a href="#visual-example-of-clustering-in-2d" id="toc-visual-example-of-clustering-in-2d" class="nav-link" data-scroll-target="#visual-example-of-clustering-in-2d">Visual Example of Clustering in 2D</a></li>
  <li><a href="#implementing-k-means-in-scikit-learn" id="toc-implementing-k-means-in-scikit-learn" class="nav-link" data-scroll-target="#implementing-k-means-in-scikit-learn">Implementing K-Means in scikit-learn</a></li>
  <li><a href="#key-assumptions-and-limitations" id="toc-key-assumptions-and-limitations" class="nav-link" data-scroll-target="#key-assumptions-and-limitations">Key Assumptions and Limitations</a></li>
  </ul></li>
  <li><a href="#choosing-the-right-number-of-clusters" id="toc-choosing-the-right-number-of-clusters" class="nav-link" data-scroll-target="#choosing-the-right-number-of-clusters"><span class="header-section-number">31.4</span> Choosing the Right Number of Clusters</a>
  <ul class="collapse">
  <li><a href="#why-selecting-k-is-challenging" id="toc-why-selecting-k-is-challenging" class="nav-link" data-scroll-target="#why-selecting-k-is-challenging">Why Selecting <em>k</em> Is Challenging</a></li>
  <li><a href="#the-elbow-method" id="toc-the-elbow-method" class="nav-link" data-scroll-target="#the-elbow-method">The Elbow Method</a></li>
  <li><a href="#silhouette-scores-and-interpretation" id="toc-silhouette-scores-and-interpretation" class="nav-link" data-scroll-target="#silhouette-scores-and-interpretation">Silhouette Scores and Interpretation</a></li>
  </ul></li>
  <li><a href="#practical-considerations" id="toc-practical-considerations" class="nav-link" data-scroll-target="#practical-considerations"><span class="header-section-number">31.5</span> Practical Considerations</a>
  <ul class="collapse">
  <li><a href="#feature-scaling-a-critical-reminder" id="toc-feature-scaling-a-critical-reminder" class="nav-link" data-scroll-target="#feature-scaling-a-critical-reminder">Feature Scaling: A Critical Reminder</a></li>
  <li><a href="#random-initialization-and-random_state" id="toc-random-initialization-and-random_state" class="nav-link" data-scroll-target="#random-initialization-and-random_state">Random Initialization and <code>random_state</code></a></li>
  <li><a href="#handling-outliers-and-non-spherical-clusters" id="toc-handling-outliers-and-non-spherical-clusters" class="nav-link" data-scroll-target="#handling-outliers-and-non-spherical-clusters">Handling Outliers and Non-Spherical Clusters</a></li>
  </ul></li>
  <li><a href="#other-clustering-techniques-overview" id="toc-other-clustering-techniques-overview" class="nav-link" data-scroll-target="#other-clustering-techniques-overview"><span class="header-section-number">31.6</span> Other Clustering Techniques (Overview)</a>
  <ul class="collapse">
  <li><a href="#when-to-use-alternatives-to-k-means" id="toc-when-to-use-alternatives-to-k-means" class="nav-link" data-scroll-target="#when-to-use-alternatives-to-k-means">When to Use Alternatives to K-Means</a></li>
  </ul></li>
  <li><a href="#case-study-complete-journey-customer-segmentation" id="toc-case-study-complete-journey-customer-segmentation" class="nav-link" data-scroll-target="#case-study-complete-journey-customer-segmentation"><span class="header-section-number">31.7</span> Case Study: Complete Journey Customer Segmentation</a>
  <ul class="collapse">
  <li><a href="#the-business-problem" id="toc-the-business-problem" class="nav-link" data-scroll-target="#the-business-problem">The Business Problem</a></li>
  <li><a href="#loading-and-exploring-the-data" id="toc-loading-and-exploring-the-data" class="nav-link" data-scroll-target="#loading-and-exploring-the-data">Loading and Exploring the Data</a></li>
  <li><a href="#feature-engineering-and-preprocessing" id="toc-feature-engineering-and-preprocessing" class="nav-link" data-scroll-target="#feature-engineering-and-preprocessing">Feature Engineering and Preprocessing</a></li>
  <li><a href="#finding-the-optimal-number-of-clusters" id="toc-finding-the-optimal-number-of-clusters" class="nav-link" data-scroll-target="#finding-the-optimal-number-of-clusters">Finding the Optimal Number of Clusters</a></li>
  <li><a href="#interpreting-cluster-profiles" id="toc-interpreting-cluster-profiles" class="nav-link" data-scroll-target="#interpreting-cluster-profiles">Interpreting Cluster Profiles</a></li>
  <li><a href="#visualizing-the-segments" id="toc-visualizing-the-segments" class="nav-link" data-scroll-target="#visualizing-the-segments">Visualizing the Segments</a></li>
  <li><a href="#actionable-marketing-recommendations" id="toc-actionable-marketing-recommendations" class="nav-link" data-scroll-target="#actionable-marketing-recommendations">Actionable Marketing Recommendations</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">31.8</span> Summary</a></li>
  <li><a href="#end-of-chapter-exercises" id="toc-end-of-chapter-exercises" class="nav-link" data-scroll-target="#end-of-chapter-exercises"><span class="header-section-number">31.9</span> End of Chapter Exercises</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/edit/main/31-clustering.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./31-clustering.html">Module 12</a></li><li class="breadcrumb-item"><a href="./31-clustering.html"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Unsupervised Learning and Clustering</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-clustering" class="quarto-section-identifier"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Unsupervised Learning and Clustering</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Think back to all the models you’ve built so far in this course. Whether predicting house prices with regression, classifying loan defaults with logistic regression, or diagnosing heart disease with decision trees, they all had one thing in common: you always had a target variable—a known outcome you were trying to predict. This is called <strong>supervised learning</strong> because you’re essentially supervising the algorithm by showing it examples of “correct answers” during training.</p>
<p>But what if you don’t have labels? What if you have customer data but no predetermined segments, or transaction records with no indication of which patterns are normal versus fraudulent? This is where <strong>unsupervised learning</strong> comes in—algorithms that discover hidden structures and patterns in data without being told what to look for.</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Remember These Terms?
</div>
</div>
<div class="callout-body-container callout-body">
<p>The distinction between supervised and unsupervised learning should feel familiar—we first introduced these concepts back in Chapter 19. Since then, we’ve been focusing exclusively on supervised learning methods: regression, classification, and ensemble techniques. In this chapter and the next, we’re shifting our focus to unsupervised learning, exploring how algorithms can discover patterns and structure in data without labeled outcomes to guide them.</p>
</div>
</div>
<p>This chapter introduces you to one of the most powerful and widely-used unsupervised learning techniques: <strong>clustering</strong>. You’ll learn how clustering algorithms automatically group similar observations together, revealing natural segments in your data that weren’t obvious before. We’ll focus primarily on <strong>K-Means clustering</strong>—the workhorse algorithm for customer segmentation, market analysis, and exploratory data analysis.</p>
<p>Through a comprehensive case study using real grocery store transaction data, you’ll master the complete clustering workflow: engineering behavioral features from raw transactions, selecting the optimal number of clusters (even when the answer is ambiguous), interpreting cluster profiles, and translating statistical findings into actionable marketing strategies. You’ll also learn when K-Means works well, when its assumptions break down, and what alternative methods exist for more complex data structures.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li>Explain the difference between supervised and unsupervised learning and when each is appropriate</li>
<li>Understand how the K-Means algorithm groups similar observations through iterative centroid updates</li>
<li>Implement K-Means clustering using scikit-learn’s <code>KMeans</code> class and interpret key attributes</li>
<li>Engineer behavioral features from transactional data for customer segmentation</li>
<li>Use the elbow method and silhouette scores to select the number of clusters—and understand when results are ambiguous</li>
<li>Apply proper feature scaling to ensure all features contribute equally to clustering</li>
<li>Handle categorical variables through ordinal and one-hot encoding</li>
<li>Interpret cluster profiles by analyzing both behavioral and demographic characteristics</li>
<li>Translate statistical clusters into actionable business strategies</li>
<li>Recognize K-Means assumptions and when alternative methods (hierarchical, DBSCAN) might be more appropriate</li>
<li>Apply the complete clustering workflow to real-world grocery retail data</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Follow along in Colab
</div>
</div>
<div class="callout-body-container callout-body">
<p>As you read through this chapter, we encourage you to follow along using the <a href="https://github.com/bradleyboehmke/uc-bana-4080/blob/main/example-notebooks/31_clustering.ipynb">companion notebook</a> in Google Colab (or another editor of your choice). This interactive notebook lets you run all the code examples covered here—and experiment with your own ideas.</p>
<p>👉 Open the <a href="https://colab.research.google.com/github/bradleyboehmke/uc-bana-4080/blob/main/example-notebooks/31_clustering.ipynb">Clustering Notebook in Colab</a>.</p>
</div>
</div>
<section id="introduction-to-unsupervised-learning" class="level2" data-number="31.1">
<h2 data-number="31.1" class="anchored" data-anchor-id="introduction-to-unsupervised-learning"><span class="header-section-number">31.1</span> Introduction to Unsupervised Learning</h2>
<section id="quick-refresh-what-is-unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="quick-refresh-what-is-unsupervised-learning">Quick Refresh: What Is Unsupervised Learning?</h3>
<p>Throughout this course, you’ve been building <strong>supervised learning</strong> models—algorithms that learn from labeled training data where the outcome is known. You had house prices to predict, disease diagnoses to classify, and customer defaults to forecast. The “supervision” comes from having these known outcomes guide the learning process.</p>
<p><strong>Unsupervised learning</strong> flips this paradigm. Instead of predicting a known outcome, unsupervised algorithms explore the data itself to discover hidden patterns, structures, and relationships. There’s no target variable, no correct answer to check against—just data waiting to reveal its natural organization.</p>
<p>Consider these contrasting scenarios:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Supervised Learning</strong></th>
<th><strong>Unsupervised Learning</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>“Given customer features, predict if they’ll churn (yes/no)”</td>
<td>“Given customer features, discover natural customer segments”</td>
</tr>
<tr class="even">
<td>“Given email content, classify as spam or not spam”</td>
<td>“Given document text, group similar documents together”</td>
</tr>
<tr class="odd">
<td>“Given patient symptoms, diagnose disease (known conditions)”</td>
<td>“Given patient symptoms, identify patterns that might represent new disease subtypes”</td>
</tr>
<tr class="even">
<td><strong>You have labeled data</strong></td>
<td><strong>You have unlabeled data</strong></td>
</tr>
<tr class="odd">
<td><strong>Goal: Predict outcomes</strong></td>
<td><strong>Goal: Discover structure</strong></td>
</tr>
</tbody>
</table>
</section>
<section id="when-and-why-we-use-it" class="level3">
<h3 class="anchored" data-anchor-id="when-and-why-we-use-it">When and Why We Use It</h3>
<p>Unsupervised learning shines in several important business contexts where labels are expensive, unavailable, or not yet defined:</p>
<p><strong>1. Exploratory Data Analysis</strong>: When you first encounter a new dataset, unsupervised methods help you understand its structure before building predictive models. You might discover that your customers naturally fall into 4-5 distinct groups, which could inform feature engineering for subsequent supervised learning.</p>
<p><strong>2. Discovering Hidden Patterns</strong>: Sometimes the most interesting insights aren’t about predicting known outcomes, but about revealing patterns you didn’t know existed. Retail companies use clustering to discover unexpected customer segments, healthcare researchers use it to identify disease subtypes, and fraud analysts use it to detect anomalous transaction patterns.</p>
<p><strong>3. Preprocessing for Supervised Learning</strong>: Unsupervised methods can create features for supervised models. For example, you might cluster customers into segments, then use those cluster labels as categorical features in a churn prediction model.</p>
<p><strong>4. When Labels Are Expensive</strong>: Labeling data is often costly and time-consuming. Medical diagnoses require expert physicians, customer satisfaction requires surveys, and fraud detection requires investigation. Unsupervised methods can work with the abundant unlabeled data you already have.</p>
<p><strong>5. Dimension Reduction</strong>: When you have hundreds or thousands of features, unsupervised techniques can compress them into a smaller set while preserving important information (this is beyond the scope of this chapter but we’ll touch on it in the next chapter).</p>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>The Tradeoff: Insight vs.&nbsp;Prediction
</div>
</div>
<div class="callout-body-container callout-body">
<p>Unsupervised learning trades prediction accuracy for discovery potential:</p>
<ul>
<li><strong>Supervised learning</strong> asks: “Can I accurately predict this outcome?”</li>
<li><strong>Unsupervised learning</strong> asks: “What interesting structure exists in this data?”</li>
</ul>
<p>Both are valuable, but they serve different purposes. You can’t evaluate unsupervised methods using accuracy or RMSE because there’s no ground truth to compare against. Instead, you evaluate them based on interpretability, actionability, and how well the discovered patterns align with business goals.</p>
</div>
</div>
</section>
<section id="two-main-types-of-unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="two-main-types-of-unsupervised-learning">Two Main Types of Unsupervised Learning</h3>
<p>While unsupervised learning encompasses many techniques, two categories dominate business applications:</p>
<p><strong>1. Clustering: Grouping Similar Observations</strong></p>
<p>Clustering algorithms partition data into groups (clusters) where observations within each group are more similar to each other than to observations in other groups. Think of it as automatic categorization:</p>
<ul>
<li><strong>Customer segmentation</strong>: Group customers by purchasing behavior, demographics, or engagement patterns</li>
<li><strong>Market segmentation</strong>: Identify distinct market segments for targeted marketing campaigns</li>
<li><strong>Document organization</strong>: Automatically group similar news articles, research papers, or support tickets</li>
<li><strong>Image compression</strong>: Group similar pixels to reduce image file sizes</li>
<li><strong>Anomaly detection</strong>: Identify observations that don’t fit well into any cluster</li>
</ul>
<p>This chapter focuses primarily on clustering, with emphasis on the K-Means algorithm—the most widely-used clustering method in business applications.</p>
<p><strong>2. Dimension Reduction: Simplifying Complex Data</strong></p>
<p>Dimension reduction techniques compress many features into fewer dimensions while preserving as much information as possible:</p>
<ul>
<li><strong>Principal Component Analysis (PCA)</strong>: Find linear combinations of features that capture maximum variance</li>
<li><strong>t-SNE and UMAP</strong>: Create 2D or 3D visualizations of high-dimensional data</li>
<li><strong>Autoencoders</strong>: Neural networks that learn compressed representations</li>
</ul>
<p>These methods are particularly valuable when you have hundreds of features and need to visualize the data or reduce computational costs. While we won’t cover dimension reduction in depth in this chapter, know that it’s a powerful complement to clustering.</p>
<p><strong>Visualizing the Difference: Rows vs.&nbsp;Columns</strong></p>
<p>To understand the distinction between clustering and dimension reduction, it helps to think about how each operates on your data matrix:</p>
<div id="135629e3" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-2-output-1.png" width="957" height="470" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Key Insight:</strong></p>
<ul>
<li><strong>Clustering</strong> works across <strong>rows</strong> (observations), asking: “Which customers/patients/transactions are similar to each other?”</li>
<li><strong>Dimension reduction</strong> works across <strong>columns</strong> (features), asking: “Which features can we combine or eliminate while preserving information?”</li>
</ul>
<p>Both techniques help make sense of complex data, but they operate in perpendicular directions!</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Knowledge Check: Supervised vs.&nbsp;Unsupervised
</div>
</div>
<div class="callout-body-container callout-body">
<p>For each scenario below, determine whether supervised or unsupervised learning is most appropriate, and explain your reasoning:</p>
<ul>
<li><p><strong>Scenario A</strong>: A hospital has electronic health records for 10,000 patients, including lab results, vital signs, medications, and diagnoses (disease names). They want to predict which patients are at risk for readmission within 30 days.</p></li>
<li><p><strong>Scenario B</strong>: A streaming music service has listening history for millions of users (songs played, skip rates, listening duration) but no explicit labels about user preferences. They want to create personalized playlists.</p></li>
<li><p><strong>Scenario C</strong>: An e-commerce company has millions of customer transactions with product purchases, but they don’t have predefined customer segments. They want to understand their customer base better for targeted marketing.</p></li>
</ul>
<details>
<summary>
Click to reveal answer
</summary>
<ul>
<li><p><strong>Scenario A: Supervised Learning</strong> - This is a clear supervised learning problem. The hospital has a labeled outcome (readmission within 30 days: yes/no) and wants to predict it for new patients. They would build a classification model using features like lab results and vital signs to predict the readmission target variable.</p></li>
<li><p><strong>Scenario B: Could be either, but likely unsupervised initially</strong> - While this could involve supervised learning if users explicitly rate songs (creating labels), the scenario describes unlabeled listening data. The music service would likely start with unsupervised methods like clustering to discover user taste profiles, then potentially use those clusters as features in supervised recommendation models. Collaborative filtering (often unsupervised) would help create playlists by finding users with similar listening patterns.</p></li>
<li><p><strong>Scenario C: Unsupervised Learning (Clustering)</strong> - This is a textbook unsupervised learning problem. There are no predefined labels or segments—the company wants to discover natural customer groupings that emerge from purchasing behavior. Clustering algorithms would reveal segments like “bargain hunters,” “brand loyalists,” or “occasional shoppers” without being told what to look for. These discovered segments then inform marketing strategies.</p></li>
</ul>
</details>
</div>
</div>
</section>
</section>
<section id="clustering-finding-hidden-structure-in-data" class="level2" data-number="31.2">
<h2 data-number="31.2" class="anchored" data-anchor-id="clustering-finding-hidden-structure-in-data"><span class="header-section-number">31.2</span> Clustering: Finding Hidden Structure in Data</h2>
<section id="the-goal-of-clustering" class="level3">
<h3 class="anchored" data-anchor-id="the-goal-of-clustering">The Goal of Clustering</h3>
<p>At its core, clustering is about organization—taking a messy, unstructured collection of observations and organizing them into meaningful groups. The fundamental principle is simple:</p>
<blockquote class="blockquote">
<p><strong>Observations within the same cluster should be more similar to each other than to observations in different clusters.</strong></p>
</blockquote>
<p>Think of clustering like organizing a large, unorganized bookstore. You don’t have predetermined categories, but you notice that certain books naturally go together—cookbooks share common features, science fiction novels have similarities, and business books cluster around related themes. Clustering algorithms formalize this intuitive process, using mathematical measures of similarity to automatically group observations.</p>
<p><strong>What makes observations “similar”?</strong> Similarity depends on the features you measure. In customer segmentation, similarity might be based on age, income, and purchase frequency. In document clustering, similarity might be based on word frequencies and topics. The algorithm doesn’t “understand” what these features mean—it simply measures how close or far apart observations are in feature space.</p>
</section>
<section id="real-world-examples" class="level3">
<h3 class="anchored" data-anchor-id="real-world-examples">Real-World Examples</h3>
<p>Clustering applications span nearly every industry and domain. Let’s explore some concrete examples to illustrate the breadth of clustering use cases:</p>
<p><strong>Customer Segmentation (Marketing &amp; Retail)</strong></p>
<p>A national retailer has transaction data for 500,000 customers but no formal customer segmentation strategy. Using clustering on features like purchase frequency, average order value, product categories, and recency of last purchase, they discover 5 distinct customer groups:</p>
<ul>
<li><strong>Loyal high-spenders</strong>: Frequent purchases, high order values, wide product range</li>
<li><strong>Bargain hunters</strong>: Only purchase during sales, low order values, long gaps between purchases</li>
<li><strong>New customers</strong>: Recent first purchase, low frequency but engaged with emails</li>
<li><strong>Inactive customers</strong>: Previously active but haven’t purchased in 6+ months</li>
<li><strong>Seasonal shoppers</strong>: Predictable purchase patterns around holidays</li>
</ul>
<p>These discovered segments inform targeted marketing campaigns, personalized offers, and retention strategies—all without requiring manual labeling or pre-defined categories.</p>
<p><strong>Document Grouping (Information Systems)</strong></p>
<p>A news organization publishes hundreds of articles daily across diverse topics. Instead of manually tagging every article, they use clustering on article text (converted to numerical features through TF-IDF) to automatically group similar articles. The algorithm discovers clusters corresponding to sports, politics, technology, health, and entertainment—plus some unexpected groupings like “environmental policy” that spans multiple traditional categories.</p>
<p><strong>Image Compression (Computer Vision)</strong></p>
<p>Digital images contain millions of pixels, each with red, green, and blue color values. K-Means clustering can group similar colors together—perhaps reducing an image with 16 million possible colors down to just 256 distinct colors. Each pixel is then represented by its nearest cluster center, dramatically reducing file size while maintaining visual quality. This is how GIF images achieve compression.</p>
<p><strong>Medical Diagnosis Refinement (Healthcare)</strong></p>
<p>Doctors have long recognized that diseases like diabetes or cancer aren’t single conditions but rather collections of related subtypes with different characteristics. Researchers use clustering on patient symptoms, biomarkers, and genetic data to identify these subtypes, revealing that what we call “Type 2 diabetes” might actually be 3-4 distinct conditions requiring different treatments.</p>
<p><strong>Anomaly Detection (Fraud &amp; Security)</strong></p>
<p>Credit card companies cluster transaction patterns to identify normal behavior. Transactions that don’t fit well into any established cluster—they’re far from all cluster centers—are flagged as potentially fraudulent. This unsupervised approach can detect new fraud patterns that weren’t seen during supervised model training.</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Common Thread: Discovery
</div>
</div>
<div class="callout-body-container callout-body">
<p>Notice that all these applications share a common theme: <strong>discovering structure that wasn’t predetermined</strong>. Clustering doesn’t impose categories from outside—it reveals the natural groupings that emerge from the data itself. This makes it particularly valuable for exploratory analysis and for situations where human intuition might miss subtle patterns.</p>
</div>
</div>
</section>
<section id="key-terms-distance-similarity-and-centroids" class="level3">
<h3 class="anchored" data-anchor-id="key-terms-distance-similarity-and-centroids">Key Terms: Distance, Similarity, and Centroids</h3>
<p>Before we dive into specific clustering algorithms, let’s establish the foundational concepts that make clustering work.</p>
<p><strong>Distance and Similarity</strong></p>
<p>Clustering algorithms need a way to measure how “close” or “far apart” observations are. This is typically done using distance metrics:</p>
<p><strong>Euclidean Distance</strong> (most common): The straight-line distance between two points in feature space. For two observations with features <span class="math inline">\([x_1, x_2, ..., x_n]\)</span> and <span class="math inline">\([y_1, y_2, ..., y_n]\)</span>:</p>
<p><span class="math display">\[\text{Euclidean Distance} = \sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + ... + (x_n - y_n)^2}\]</span></p>
<p>In two dimensions, this is just the Pythagorean theorem. For example, if Customer A has [age=30, income=50000] and Customer B has [age=35, income=60000]:</p>
<p><span class="math display">\[\text{Distance} = \sqrt{(30-35)^2 + (50000-60000)^2} = \sqrt{25 + 100000000} \approx 10000\]</span></p>
<p>Let’s visualize this distance calculation:</p>
<div id="ee8ce255" class="cell" data-fig-height="5" data-fig-width="10" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-3-output-1.png" width="1143" height="470" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>The need for feature scaling!
</div>
</div>
<div class="callout-body-container callout-body">
<p>Notice how the income difference dominates because income is measured in much larger numbers than age. The squared income difference (100,000,000) is <strong>4 million times</strong> larger than the squared age difference (25)! This means age contributes virtually nothing to the distance calculation, even though both features might be equally important for customer segmentation. This is why <strong>feature scaling</strong> is crucial for clustering—we’ll address this later.</p>
</div>
</div>
<p><strong>Other Distance Metrics</strong> exist for specific use cases:</p>
<ul>
<li><strong>Manhattan distance</strong>: Sum of absolute differences (like city block distance)</li>
<li><strong>Cosine similarity</strong>: Measures angle between vectors (useful for text data)</li>
<li><strong>Correlation distance</strong>: Measures pattern similarity regardless of magnitude</li>
</ul>
<p>For this chapter, we’ll focus on Euclidean distance, which K-Means uses by default.</p>
<p><strong>Centroids</strong></p>
<p>A <strong>centroid</strong> is the center point of a cluster—the “average” observation for that group. For each feature, the centroid’s value is the mean of all observations in the cluster.</p>
<p>If a cluster contains three customers:</p>
<ul>
<li>Customer 1: [age=25, income=40000]</li>
<li>Customer 2: [age=30, income=50000]</li>
<li>Customer 3: [age=35, income=45000]</li>
</ul>
<p>The centroid would be: [age=30, income=45000]</p>
<p><strong>Why centroids matter</strong>: K-Means and many other clustering algorithms work by iteratively updating cluster centroids to find the best grouping. Each observation is assigned to its nearest centroid, forming clusters.</p>
<p><strong>Within-Cluster Sum of Squares (WCSS)</strong></p>
<p>To measure cluster quality, we calculate how compact each cluster is:</p>
<p><span class="math display">\[\text{WCSS} = \sum_{i=1}^{k} \sum_{x \in C_i} \text{distance}(x, \text{centroid}_i)^2\]</span></p>
<p>This measures the total squared distance from each point to its cluster centroid. <strong>Lower WCSS means tighter, more compact clusters</strong>, which is generally desirable. We’ll use WCSS when determining the optimal number of clusters.</p>
<p>Let’s visualize what “compact” vs.&nbsp;“loose” clusters look like and how WCSS captures this:</p>
<div id="bb8dad79" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-4-output-1.png" width="951" height="565" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Key Observation</strong>: The compact clusters (left) have much lower WCSS because points are tightly grouped around their centroids. The loose clusters (right) have higher WCSS because points are more scattered. The dashed gray lines show the distances being squared and summed—longer lines mean larger WCSS.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Visualizing Distance and Centroids
</div>
</div>
<div class="callout-body-container callout-body">
<p>The visualization above shows how clustering algorithms work:</p>
<ol type="1">
<li>Place centroid markers (X symbols) at strategic locations</li>
<li>Assign each point to the nearest centroid (shown by colors)</li>
<li>Calculate distances from points to their centroids (dashed lines)</li>
<li>Move centroids to minimize these distances (minimize WCSS)</li>
<li>Repeat until centroids stop moving</li>
</ol>
<p>The result is groups of observations clustered around their respective centroids, with observations within each group being more similar to each other than to observations in other groups.</p>
</div>
</div>
</section>
</section>
<section id="the-k-means-algorithm" class="level2" data-number="31.3">
<h2 data-number="31.3" class="anchored" data-anchor-id="the-k-means-algorithm"><span class="header-section-number">31.3</span> The K-Means Algorithm</h2>
<p>K-Means is the most widely-used clustering algorithm in business applications, beloved for its simplicity, speed, and effectiveness. Despite its straightforward approach, K-Means powers customer segmentation at major retailers, image compression in software, and countless other real-world applications.</p>
<section id="step-by-step-overview" class="level3">
<h3 class="anchored" data-anchor-id="step-by-step-overview">Step-by-Step Overview</h3>
<p>The K-Means algorithm follows an elegant iterative process that’s easy to understand and visualize. Let’s walk through exactly how it works:</p>
<p><strong>Step 1: Choose <em>k</em> clusters</strong></p>
<p>Before running the algorithm, you must specify <em>k</em>—the number of clusters you want. This is both a strength (you control the granularity) and a challenge (you need to choose wisely). We’ll discuss how to select <em>k</em> in the next section, but for now, let’s say we’ve chosen <em>k</em>=3 clusters.</p>
<p><strong>Step 2: Initialize <em>k</em> centroids</strong></p>
<p>The algorithm randomly places <em>k</em> centroid points in your feature space. These initial placements are random, which means K-Means can produce different results on different runs (we’ll address this with <code>random_state</code>). Think of these centroids as the initial “guesses” for where cluster centers should be.</p>
<p><strong>Step 3: Assign points to nearest centroid</strong></p>
<p>For each observation in your dataset, calculate the distance to each centroid and assign the observation to the closest one. After this step, every observation has been assigned to exactly one cluster.</p>
<p><strong>Step 4: Update centroids</strong></p>
<p>For each cluster, calculate the mean (average) of all observations assigned to it. Move the centroid to this new average position. This is why it’s called K-“Means”—the centroids represent the mean of their assigned points.</p>
<p><strong>Step 5: Repeat until convergence</strong></p>
<p>Go back to Step 3 and repeat the assign-update cycle. With each iteration, observations might switch clusters as centroids move. Eventually, the centroids stop moving (or move only trivially), meaning we’ve reached <strong>convergence</strong>—a stable solution where assignments no longer change.</p>
<p><strong>Convergence criteria</strong>: The algorithm stops when either:</p>
<ul>
<li>No observations change cluster assignments between iterations</li>
<li>Centroids move less than a tiny threshold distance</li>
<li>A maximum number of iterations is reached</li>
</ul>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>K-Means Is Not Deterministic
</div>
</div>
<div class="callout-body-container callout-body">
<p>Because K-Means starts with random centroid positions, running it multiple times on the same data can produce different results. Some initializations lead to better final clusters than others. Scikit-learn addresses this by running the algorithm multiple times (default: 10 times) with different random initializations and keeping the best result (lowest WCSS). You can control this with the <code>n_init</code> parameter.</p>
<p>Always set <code>random_state</code> for reproducibility in your code.</p>
</div>
</div>
</section>
<section id="visual-example-of-clustering-in-2d" class="level3">
<h3 class="anchored" data-anchor-id="visual-example-of-clustering-in-2d">Visual Example of Clustering in 2D</h3>
<p>Let’s see K-Means in action with a simple visual example. We’ll create synthetic customer data with two features (age and income) and watch the algorithm discover natural groupings.</p>
<div id="8757fd6d" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Synthetic data creation</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate three distinct customer groups</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Group 1: Young, lower income (students/entry-level)</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>group1_age <span class="op">=</span> np.random.normal(<span class="dv">25</span>, <span class="dv">3</span>, <span class="dv">50</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>group1_income <span class="op">=</span> np.random.normal(<span class="dv">35000</span>, <span class="dv">5000</span>, <span class="dv">50</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Group 2: Middle-aged, moderate income (professionals)</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>group2_age <span class="op">=</span> np.random.normal(<span class="dv">40</span>, <span class="dv">4</span>, <span class="dv">50</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>group2_income <span class="op">=</span> np.random.normal(<span class="dv">65000</span>, <span class="dv">8000</span>, <span class="dv">50</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Group 3: Older, higher income (executives/established)</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>group3_age <span class="op">=</span> np.random.normal(<span class="dv">55</span>, <span class="dv">5</span>, <span class="dv">50</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>group3_income <span class="op">=</span> np.random.normal(<span class="dv">95000</span>, <span class="dv">12000</span>, <span class="dv">50</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine into single dataset</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>age <span class="op">=</span> np.concatenate([group1_age, group2_age, group3_age])</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>income <span class="op">=</span> np.concatenate([group1_income, group2_income, group3_income])</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>customer_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">'age'</span>: age,</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'income'</span>: income</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>customer_data.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">age</th>
<th data-quarto-table-cell-role="th">income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>26.490142</td>
<td>36620.419847</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>24.585207</td>
<td>33074.588598</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>26.943066</td>
<td>31615.389998</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>29.569090</td>
<td>38058.381444</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>24.297540</td>
<td>40154.997612</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now let’s visualize the data before and after clustering:</p>
<div id="d470d257" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Clustering illustration</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit K-Means with k=3</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>customer_data[<span class="st">'cluster'</span>] <span class="op">=</span> kmeans.fit_predict(customer_data[[<span class="st">'age'</span>, <span class="st">'income'</span>]])</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get cluster centers</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>centers <span class="op">=</span> kmeans.cluster_centers_</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create side-by-side plots</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Left plot: Original data (no clusters visible)</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(customer_data[<span class="st">'age'</span>], customer_data[<span class="st">'income'</span>],</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Age (years)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Income ($)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Before Clustering: Unlabeled Customer Data'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Right plot: After clustering with centroids</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'#FF6B6B'</span>, <span class="st">'#4ECDC4'</span>, <span class="st">'#45B7D1'</span>]</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    cluster_data <span class="op">=</span> customer_data[customer_data[<span class="st">'cluster'</span>] <span class="op">==</span> i]</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].scatter(cluster_data[<span class="st">'age'</span>], cluster_data[<span class="st">'income'</span>],</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>                   alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>colors[i], label<span class="op">=</span><span class="ss">f'Cluster </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot centroids</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(centers[:, <span class="dv">0</span>], centers[:, <span class="dv">1</span>],</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>               marker<span class="op">=</span><span class="st">'X'</span>, s<span class="op">=</span><span class="dv">200</span>, c<span class="op">=</span><span class="st">'black'</span>, edgecolors<span class="op">=</span><span class="st">'white'</span>, linewidths<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>               label<span class="op">=</span><span class="st">'Centroids'</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Age (years)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Income ($)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'After K-Means: Discovered Customer Segments'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Print cluster summaries</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Cluster Summaries:"</span>)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>    cluster_data <span class="op">=</span> customer_data[customer_data[<span class="st">'cluster'</span>] <span class="op">==</span> i]</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Cluster </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Size: </span><span class="sc">{</span><span class="bu">len</span>(cluster_data)<span class="sc">}</span><span class="ss"> customers"</span>)</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Average age: </span><span class="sc">{</span>cluster_data[<span class="st">'age'</span>]<span class="sc">.</span>mean()<span class="sc">:.1f}</span><span class="ss"> years"</span>)</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Average income: $</span><span class="sc">{</span>cluster_data[<span class="st">'income'</span>]<span class="sc">.</span>mean()<span class="sc">:,.0f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-6-output-1.png" width="951" height="375" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Cluster Summaries:

Cluster 1:
  Size: 43 customers
  Average age: 55.6 years
  Average income: $98,232

Cluster 2:
  Size: 50 customers
  Average age: 24.3 years
  Average income: $35,089

Cluster 3:
  Size: 57 customers
  Average age: 41.9 years
  Average income: $66,612</code></pre>
</div>
</div>
<p>The visualization demonstrates K-Means’ fundamental behavior: it discovered three natural groupings in customer data that weren’t explicitly labeled. The left plot shows the raw data—you can see there are groups, but they’re not formally defined. The right plot shows K-Means’ solution: three distinct clusters with centroids (marked with X) at each cluster’s center.</p>
<p>Notice how the algorithm created three sensible customer segments:</p>
<ul>
<li><strong>Cluster 1</strong>: Younger customers with lower incomes (entry-level workers)</li>
<li><strong>Cluster 2</strong>: Middle-aged customers with moderate incomes (established professionals)</li>
<li><strong>Cluster 3</strong>: Older customers with higher incomes (senior professionals/executives)</li>
</ul>
<p>These segments emerged purely from the age and income patterns—K-Means identified the natural groupings without being told what to look for.</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Animated Visualization of K-Means
</div>
</div>
<div class="callout-body-container callout-body">
<p>For an excellent animated visualization showing how K-Means iteratively updates centroids and assignments, see <a href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/">this interactive demo</a> or <a href="https://stanford.edu/class/engr108/visualizations/kmeans/kmeans.html">this Stanford visualization</a>. Watching the centroids move and clusters form/reform gives great intuition for the algorithm’s behavior.</p>
</div>
</div>
</section>
<section id="implementing-k-means-in-scikit-learn" class="level3">
<h3 class="anchored" data-anchor-id="implementing-k-means-in-scikit-learn">Implementing K-Means in scikit-learn</h3>
<p>Now that you understand how K-Means works conceptually, let’s see how easy it is to apply in Python using scikit-learn. The process follows a familiar pattern if you’ve used scikit-learn for supervised learning.</p>
<p><strong>Basic K-Means Workflow:</strong></p>
<div id="a44e4f18" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Create synthetic customer data</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample customer data</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>n_customers <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>customer_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'customer_id'</span>: <span class="bu">range</span>(<span class="dv">1</span>, n_customers <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'age'</span>: np.random.randint(<span class="dv">20</span>, <span class="dv">70</span>, n_customers),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'annual_income'</span>: np.random.randint(<span class="dv">20000</span>, <span class="dv">120000</span>, n_customers),</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'purchase_frequency'</span>: np.random.randint(<span class="dv">1</span>, <span class="dv">50</span>, n_customers)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="dfcaf40c" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Prepare your data (features only, no target variable)</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume we have a DataFrame with customer features</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> customer_data[[<span class="st">'age'</span>, <span class="st">'annual_income'</span>, <span class="st">'purchase_frequency'</span>]]</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Scale your features (IMPORTANT!)</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Create and fit the K-Means model</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    n_clusters<span class="op">=</span><span class="dv">3</span>,        <span class="co"># Number of clusters</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,     <span class="co"># For reproducibility</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    n_init<span class="op">=</span><span class="dv">10</span>            <span class="co"># Number of different initializations (default=10)</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>kmeans.fit(X_scaled)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Get cluster assignments</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>customer_data[<span class="st">'cluster'</span>] <span class="op">=</span> kmeans.predict(X_scaled)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>customer_data.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">customer_id</th>
<th data-quarto-table-cell-role="th">age</th>
<th data-quarto-table-cell-role="th">annual_income</th>
<th data-quarto-table-cell-role="th">purchase_frequency</th>
<th data-quarto-table-cell-role="th">cluster</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1</td>
<td>58</td>
<td>43419</td>
<td>33</td>
<td>2</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>2</td>
<td>48</td>
<td>70636</td>
<td>24</td>
<td>0</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>3</td>
<td>34</td>
<td>70015</td>
<td>11</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>4</td>
<td>62</td>
<td>74268</td>
<td>49</td>
<td>2</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>5</td>
<td>27</td>
<td>107939</td>
<td>8</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p><strong>Key Parameters to Know:</strong></p>
<ul>
<li><strong><code>n_clusters</code></strong>: The number of clusters (<em>k</em>). You must specify this upfront.</li>
<li><strong><code>random_state</code></strong>: Sets the random seed for reproducibility. Always use this for consistent results.</li>
<li><strong><code>n_init</code></strong>: Number of times K-Means runs with different centroid initializations. The best result (lowest WCSS) is kept. Default is 10.</li>
<li><strong><code>max_iter</code></strong>: Maximum iterations for convergence. Default is 300 (usually more than enough).</li>
</ul>
<p><strong>Accessing Results:</strong></p>
<p>After fitting, the K-Means object contains useful attributes and we can even make predictions on which cluster a new customer aligns to:</p>
<div id="ea84d48f" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get cluster centers (centroids)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>centroids <span class="op">=</span> kmeans.cluster_centers_</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cluster centroids shape:"</span>, centroids.shape)  <span class="co"># (n_clusters, n_features)</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get cluster labels for training data</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.labels_</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cluster assignments:"</span>, labels[:<span class="dv">10</span>])  <span class="co"># First 10 assignments</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Get WCSS (inertia)</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>wcss <span class="op">=</span> kmeans.inertia_</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Within-Cluster Sum of Squares: </span><span class="sc">{</span>wcss<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict cluster for new data</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>new_customer <span class="op">=</span> pd.DataFrame([[<span class="dv">35</span>, <span class="dv">60000</span>, <span class="dv">12</span>]], columns<span class="op">=</span>[<span class="st">'age'</span>, <span class="st">'annual_income'</span>, <span class="st">'purchase_frequency'</span>])</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>new_customer_scaled <span class="op">=</span> scaler.transform(new_customer)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>predicted_cluster <span class="op">=</span> kmeans.predict(new_customer_scaled)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New customer assigned to cluster: </span><span class="sc">{</span>predicted_cluster[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cluster centroids shape: (3, 3)
Cluster assignments: [2 0 1 2 1 2 0 1 1 1]
Within-Cluster Sum of Squares: 254.15
New customer assigned to cluster: 1</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Don’t Forget Feature Scaling!
</div>
</div>
<div class="callout-body-container callout-body">
<p>Notice that we <strong>always scale features</strong> before applying K-Means. This is critical! Without scaling, features with larger numeric ranges (like income) will dominate the clustering, making other features (like age) virtually irrelevant. We’ll explore this in detail in the “Practical Considerations” section.</p>
</div>
</div>
</section>
<section id="key-assumptions-and-limitations" class="level3">
<h3 class="anchored" data-anchor-id="key-assumptions-and-limitations">Key Assumptions and Limitations</h3>
<p>While K-Means is powerful and widely applicable, it makes certain assumptions that don’t always hold in real data. Understanding these limitations helps you recognize when K-Means is appropriate and when alternative methods might work better.</p>
<div class="callout callout-style-simple callout-warning callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Assumption 1: Clusters are spherical (roughly circular)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>K-Means works best when clusters form compact, roughly circular groups. Because it uses Euclidean distance and assigns points to the nearest centroid, it naturally creates spherical-shaped clusters.</p>
<p><strong>Problem</strong>: Real data often forms non-spherical patterns—elongated clusters, crescents, or nested shapes. K-Means will struggle with these.</p>
<div id="e1641b2b" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-10-output-1.png" width="902" height="374" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Solution</strong>: Alternative clustering algorithms such as DBSCAN (Density-based Spatial Clustering of Applications with Noise) have been developed to capture non-circular clusters.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-warning callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Assumption 2: Clusters are roughly equal in size
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>K-Means tends to create clusters with similar numbers of observations because each point is assigned to its nearest centroid. This can cause problems when natural groups have very different sizes.</p>
<p><strong>Problem</strong>: If you have 1,000 typical customers and 50 VIP customers, K-Means might split the typical customers into multiple clusters instead of keeping the small VIP cluster intact.</p>
<div id="79b2502b" class="cell" data-execution_count="10">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-11-output-1.png" width="901" height="373" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Solution</strong>: If you know certain groups should remain intact regardless of size, consider:</p>
<ul>
<li>Using DBSCAN, which doesn’t assume equal cluster sizes</li>
<li>Manually segmenting the VIP group first, then clustering the remainder</li>
<li>Using hierarchical clustering with specific linkage criteria</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-warning callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Assumption 3: Clusters have similar variance (spread)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>K-Means assumes clusters are roughly equally “spread out.” Clusters with very different densities or sizes can confuse the algorithm.</p>
<p><strong>Problem</strong>: A tight cluster of 20 observations might get absorbed into a nearby large, diffuse cluster of 200 observations, even if they’re conceptually distinct groups.</p>
<div id="9bb45665" class="cell" data-execution_count="11">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-12-output-1.png" width="901" height="373" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Solution</strong>:</p>
<ul>
<li>Use <strong>Gaussian Mixture Models (GMM)</strong>, which allow clusters to have different variances</li>
<li>Consider <strong>hierarchical clustering</strong> with appropriate linkage methods</li>
<li>Standardize features, though this doesn’t fully solve variance differences</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-warning callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Assumption 4: Features are on comparable scales
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This is perhaps the most important practical consideration. K-Means uses Euclidean distance, which means features with larger numeric ranges will dominate the clustering.</p>
<p><strong>Problem</strong>: If you cluster customers using age (20-80) and income (20,000-200,000), income differences will completely dominate age differences because income values are much larger. A 10-year age gap means little compared to a $10,000 income gap, even though both might be equally important for segmentation.</p>
<p>We already visualized this problem earlier in the Euclidean distance section, where we saw that income contributed 4 million times more to the distance calculation than age!</p>
<p><strong>Solution</strong>: Always scale your features before clustering. We’ll cover this in detail in the “Practical Considerations” section, where you’ll see the dramatic difference feature scaling makes.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>When to Consider Alternatives to K-Means
</div>
</div>
<div class="callout-body-container callout-body">
<p>If your data violates K-Means assumptions, consider these alternatives:</p>
<ul>
<li><strong>Non-spherical clusters</strong>: Use DBSCAN (density-based clustering) or hierarchical clustering</li>
<li><strong>Varying cluster sizes/densities</strong>: Use DBSCAN or Gaussian Mixture Models</li>
<li><strong>Uncertain number of clusters</strong>: Use hierarchical clustering to explore different <em>k</em> values simultaneously</li>
<li><strong>Categorical features</strong>: Use K-Modes or K-Prototypes instead of K-Means</li>
</ul>
<p>We’ll briefly cover these alternatives later in the chapter.</p>
</div>
</div>
</section>
</section>
<section id="choosing-the-right-number-of-clusters" class="level2" data-number="31.4">
<h2 data-number="31.4" class="anchored" data-anchor-id="choosing-the-right-number-of-clusters"><span class="header-section-number">31.4</span> Choosing the Right Number of Clusters</h2>
<p>One of K-Means’ biggest challenges is that you must specify <em>k</em> (the number of clusters) before running the algorithm. But how do you know how many clusters exist in your data? Should you segment customers into 3 groups? 5 groups? 10 groups? Unlike supervised learning where you can measure accuracy against known labels, clustering has no ground truth to validate against. This makes selecting <em>k</em> both an art and a science, combining quantitative methods with business judgment.</p>
<section id="why-selecting-k-is-challenging" class="level3">
<h3 class="anchored" data-anchor-id="why-selecting-k-is-challenging">Why Selecting <em>k</em> Is Challenging</h3>
<p>The number of clusters you choose fundamentally shapes your results:</p>
<ul>
<li><p><strong>Too few clusters</strong> (<em>k</em> too small): You’ll miss important distinctions in your data. For example, clustering customers into just 2 groups might combine high-spending young professionals with high-spending retirees, even though they need different marketing strategies.</p></li>
<li><p><strong>Too many clusters</strong> (<em>k</em> too large): You’ll create overly granular segments that are hard to act on. Imagine discovering 25 customer segments—your marketing team can’t create 25 different campaigns, and many segments will be too small to matter.</p></li>
<li><p><strong>No single “correct” answer</strong>: The “best” <em>k</em> depends on your goals. A market researcher might want 3-5 interpretable segments, while a recommendation system might use 20+ clusters for fine-grained personalization.</p></li>
</ul>
<p>This is fundamentally different from supervised learning, where you can calculate accuracy or RMSE and definitively say Model A is better than Model B. With clustering, “better” depends on your business objectives, interpretability needs, and the tradeoff between detail and actionability.</p>
</section>
<section id="the-elbow-method" class="level3">
<h3 class="anchored" data-anchor-id="the-elbow-method">The Elbow Method</h3>
<p>The <strong>elbow method</strong> is the most popular quantitative approach for selecting <em>k</em>. It helps you visualize the tradeoff between cluster count and cluster quality.</p>
<p><strong>How it works:</strong></p>
<ol type="1">
<li>Run K-Means for different values of <em>k</em> (typically k=1 through k=10 or k=15)</li>
<li>For each <em>k</em>, calculate the <strong>Within-Cluster Sum of Squares (WCSS)</strong>—the total squared distance from each point to its cluster centroid</li>
<li>Plot <em>k</em> on the x-axis and WCSS on the y-axis</li>
<li>Look for the “elbow”—the point where WCSS stops decreasing rapidly</li>
</ol>
<p><strong>Why WCSS decreases with <em>k</em></strong>: More clusters means smaller, tighter groups, so WCSS naturally decreases. At the extreme, if <em>k</em> equals the number of observations, WCSS is zero (each point is its own cluster). But this overfits completely!</p>
<p><strong>The elbow point</strong>: Look for where the WCSS curve bends—where adding more clusters gives diminishing returns. This suggests a natural grouping in the data.</p>
<p>Let’s demonstrate with our customer data:</p>
<div id="f3cc5033" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate WCSS for different values of k</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>wcss <span class="op">=</span> []</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>k_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_range:</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    kmeans_temp <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    kmeans_temp.fit(customer_data[[<span class="st">'age'</span>, <span class="st">'annual_income'</span>]])</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    wcss.append(kmeans_temp.inertia_)  <span class="co"># inertia_ is scikit-learn's name for WCSS</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot elbow curve</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>plt.plot(k_range, wcss, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters (k)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Within-Cluster Sum of Squares (WCSS)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Elbow Method for Optimal k'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>plt.xticks(k_range)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight the elbow at k=3</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">3</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Elbow at k=3'</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"WCSS values:"</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, wcss_val <span class="kw">in</span> <span class="bu">zip</span>(k_range, wcss):</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">: WCSS = </span><span class="sc">{</span>wcss_val<span class="sc">:,.0f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-13-output-1.png" width="759" height="470" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>WCSS values:
  k=1: WCSS = 126,552,534,350
  k=2: WCSS = 33,757,522,560
  k=3: WCSS = 13,262,950,265
  k=4: WCSS = 7,384,215,611
  k=5: WCSS = 4,073,559,733
  k=6: WCSS = 2,884,717,759
  k=7: WCSS = 2,138,310,306
  k=8: WCSS = 1,664,123,578
  k=9: WCSS = 1,232,399,430
  k=10: WCSS = 947,366,531</code></pre>
</div>
</div>
<p>In the elbow plot above, notice how WCSS drops sharply from <em>k</em>=1 to <em>k</em>=3, then the rate of decrease slows significantly. The “elbow” occurs around <em>k</em>=3, suggesting three natural clusters in the data—which aligns with how we generated the data (three distinct customer groups).</p>
<p><strong>Interpreting the elbow</strong>:</p>
<ul>
<li><strong>Steep drop</strong>: Large improvement in cluster quality</li>
<li><strong>Gradual decrease</strong>: Diminishing returns from additional clusters</li>
<li><strong>Elbow point</strong>: Best balance between cluster count and quality</li>
</ul>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>The Elbow Is Not Always Clear
</div>
</div>
<div class="callout-body-container callout-body">
<p>Real data often produces elbow plots without obvious bends. The curve might decrease smoothly without a distinct elbow, or you might see multiple potential elbow points. In these cases:</p>
<ul>
<li>Try complementary methods like silhouette scores (covered next)</li>
<li>Consider business constraints (can you realistically act on 8 segments?)</li>
<li>Test a few values of <em>k</em> and compare the interpretability of results</li>
<li>Remember that <em>k</em> selection involves judgment, not just optimization</li>
</ul>
</div>
</div>
</section>
<section id="silhouette-scores-and-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="silhouette-scores-and-interpretation">Silhouette Scores and Interpretation</h3>
<p>While the elbow method focuses on cluster compactness (WCSS), <strong>silhouette scores</strong> measure both compactness <em>and</em> separation—how well-separated different clusters are from each other.</p>
<p><strong>What silhouette scores measure</strong>: For each observation, the silhouette score compares:</p>
<ul>
<li><strong>a</strong>: Average distance to other points in the same cluster (how compact is my cluster?)</li>
<li><strong>b</strong>: Average distance to points in the nearest different cluster (how separated am I from other clusters?)</li>
</ul>
<p>The silhouette score for an observation is:</p>
<p><span class="math display">\[s = \frac{b - a}{\max(a, b)}\]</span></p>
<p><strong>Score interpretation</strong>:</p>
<ul>
<li><strong>s close to +1</strong>: The observation is well-matched to its cluster and far from other clusters (excellent)</li>
<li><strong>s close to 0</strong>: The observation is on the border between clusters (ambiguous)</li>
<li><strong>s close to -1</strong>: The observation might be in the wrong cluster (poor clustering)</li>
</ul>
<p>The <strong>average silhouette score</strong> across all observations measures overall clustering quality:</p>
<ul>
<li><strong>0.71 - 1.0</strong>: Strong, well-separated clusters</li>
<li><strong>0.51 - 0.70</strong>: Reasonable structure, clusters are somewhat separated</li>
<li><strong>0.26 - 0.50</strong>: Weak structure, clusters overlap considerably</li>
<li><strong>&lt; 0.25</strong>: No substantial structure detected</li>
</ul>
<p>Let’s calculate silhouette scores for different values of <em>k</em>:</p>
<div id="f2620a1e" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate silhouette scores for k=2 through k=10</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>silhouette_scores <span class="op">=</span> []</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>k_range_sil <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">11</span>)  <span class="co"># Need at least 2 clusters for silhouette</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_range_sil:</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    kmeans_temp <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    cluster_labels <span class="op">=</span> kmeans_temp.fit_predict(customer_data[[<span class="st">'age'</span>, <span class="st">'annual_income'</span>]])</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    silhouette_avg <span class="op">=</span> silhouette_score(customer_data[[<span class="st">'age'</span>, <span class="st">'annual_income'</span>]], cluster_labels)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    silhouette_scores.append(silhouette_avg)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot silhouette scores</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>plt.plot(k_range_sil, silhouette_scores, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters (k)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Average Silhouette Score'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Silhouette Analysis for Optimal k'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>plt.xticks(k_range_sil)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight the maximum</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>max_k <span class="op">=</span> k_range_sil[silhouette_scores.index(<span class="bu">max</span>(silhouette_scores))]</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>max_k, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Maximum at k=</span><span class="sc">{</span>max_k<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Silhouette scores:"</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, score <span class="kw">in</span> <span class="bu">zip</span>(k_range_sil, silhouette_scores):</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">: Silhouette = </span><span class="sc">{</span>score<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-14-output-1.png" width="759" height="470" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Silhouette scores:
  k=2: Silhouette = 0.605
  k=3: Silhouette = 0.609
  k=4: Silhouette = 0.617
  k=5: Silhouette = 0.613
  k=6: Silhouette = 0.616
  k=7: Silhouette = 0.591
  k=8: Silhouette = 0.583
  k=9: Silhouette = 0.585
  k=10: Silhouette = 0.590</code></pre>
</div>
</div>
<p><strong>Interpreting the results:</strong> Interestingly, the silhouette analysis suggests <em>k</em>=4 as optimal (highest silhouette score around 0.617), while the elbow method suggested <em>k</em>=3. This is actually quite common and highlights an important point: <strong>different methods can suggest different optimal values of <em>k</em></strong>.</p>
<p><strong>Why do the methods disagree?</strong></p>
<ul>
<li><p><strong>Elbow method</strong> focuses on minimizing within-cluster variance (WCSS). It identified <em>k</em>=3 as the point where adding more clusters provides diminishing returns in compactness.</p></li>
<li><p><strong>Silhouette method</strong> balances both compactness <em>and</em> separation between clusters. It found that <em>k</em>=4 creates clusters that are both internally cohesive and well-separated from each other.</p></li>
<li><p>The silhouette scores show that <em>k</em>=3, <em>k</em>=4, <em>k</em>=5, and <em>k</em>=6 all have similar scores (between 0.609 and 0.617), suggesting there isn’t one definitively “best” choice based purely on statistics.</p></li>
</ul>
<p><strong>So which should you choose?</strong> This is where clustering becomes as much art as science. Both <em>k</em>=3 and <em>k</em>=4 are defensible choices. You might:</p>
<ul>
<li>Choose <em>k</em>=3 if you prefer simpler, broader customer segments that are easier for marketing teams to manage</li>
<li>Choose <em>k</em>=4 if the additional granularity provides more actionable insights</li>
<li>Actually fit both models and examine which produces more interpretable, business-relevant segments</li>
</ul>
<p><strong>Using elbow + silhouette together</strong>:</p>
<ol type="1">
<li><strong>Use the elbow method</strong> to identify a range of candidate <em>k</em> values (here: <em>k</em>=3 to <em>k</em>=6)</li>
<li><strong>Use silhouette scores</strong> to evaluate cluster quality within that range (here: all similar, slight edge to <em>k</em>=4)</li>
<li><strong>Consider business context</strong> to finalize your choice (can your team act on 3 vs 4 segments?)</li>
<li><strong>Examine actual cluster profiles</strong> for both options to see which tells a clearer story</li>
</ol>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Practical Advice for Choosing <em>k</em>
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Start with domain knowledge</strong>: Do you expect 3 customer types based on business intuition? Start there.</li>
<li><strong>Use elbow + silhouette</strong> to validate or refine your intuition</li>
<li><strong>Consider business constraints</strong>: Can you actually create different strategies for 8 segments?</li>
<li><strong>Try multiple values</strong>: Build models with <em>k</em>=3, <em>k</em>=4, and <em>k</em>=5, then compare interpretability</li>
<li><strong>Iterate</strong>: Clustering is exploratory—you can refine <em>k</em> as you learn more about the data</li>
</ol>
<p>Remember: The goal isn’t to find the “mathematically optimal” <em>k</em>, but rather the <em>k</em> that produces actionable, interpretable insights for your business problem.</p>
</div>
</div>
</section>
</section>
<section id="practical-considerations" class="level2" data-number="31.5">
<h2 data-number="31.5" class="anchored" data-anchor-id="practical-considerations"><span class="header-section-number">31.5</span> Practical Considerations</h2>
<p>Before you can successfully apply K-Means to real business data, you need to address several practical challenges that can significantly impact your results. These considerations—feature scaling, random initialization, and handling outliers—are often the difference between clustering that reveals genuine insights and clustering that produces meaningless noise.</p>
<section id="feature-scaling-a-critical-reminder" class="level3">
<h3 class="anchored" data-anchor-id="feature-scaling-a-critical-reminder">Feature Scaling: A Critical Reminder</h3>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Always Scale Before K-Means Clustering
</div>
</div>
<div class="callout-body-container callout-body">
<p>Remember from our earlier discussion on K-Means assumptions: features must be on comparable scales. Since K-Means uses Euclidean distance, features with larger numeric ranges will dominate the clustering, making smaller-scale features virtually irrelevant.</p>
<p><strong>Standard workflow</strong>:</p>
<ol type="1">
<li>Scale your features using <code>StandardScaler</code></li>
<li>Fit K-Means on the scaled data</li>
<li>Interpret results using the original feature scales</li>
</ol>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>kmeans.fit(X_scaled)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="random-initialization-and-random_state" class="level3">
<h3 class="anchored" data-anchor-id="random-initialization-and-random_state">Random Initialization and <code>random_state</code></h3>
<p>K-Means starts by randomly placing <em>k</em> centroids in your feature space. This randomness means running the algorithm multiple times can produce different results—sometimes significantly different.</p>
<p><strong>Why this happens</strong>: The initial random placement can lead to different local optima. Imagine two starting configurations:</p>
<ul>
<li><strong>Good initialization</strong>: Random centroids happen to land near the true cluster centers, and the algorithm quickly converges to a sensible solution</li>
<li><strong>Poor initialization</strong>: Random centroids land in awkward positions, and the algorithm gets stuck in a suboptimal configuration</li>
</ul>
<p><strong>Scikit-learn’s solution</strong>: By default, <code>KMeans</code> uses the <code>k-means++</code> initialization algorithm, which chooses initial centroids smartly to be far apart from each other. Additionally, it runs the entire K-Means algorithm 10 times (controlled by <code>n_init=10</code>) with different random starts and keeps the best result (lowest WCSS).</p>
<p><strong>For reproducibility</strong>: Always set <code>random_state</code> in your code:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This ensures:</p>
<ul>
<li>Your results are reproducible</li>
<li>Collaborators can verify your findings</li>
<li>Your code produces consistent results in production</li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Tuning <code>n_init</code> for Better Results
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you have time and computational resources, increasing <code>n_init</code> from 10 to 50 or 100 can help find better clusterings, especially with challenging datasets. However, the default of 10 is usually sufficient for most business applications, especially when using k-means++ initialization.</p>
</div>
</div>
</section>
<section id="handling-outliers-and-non-spherical-clusters" class="level3">
<h3 class="anchored" data-anchor-id="handling-outliers-and-non-spherical-clusters">Handling Outliers and Non-Spherical Clusters</h3>
<p>K-Means is sensitive to outliers and struggles with non-spherical cluster shapes. Understanding these limitations helps you preprocess data appropriately or recognize when alternative algorithms are needed.</p>
<p><strong>Outlier sensitivity</strong>: Extreme values pull centroids toward them, distorting clusters. A single customer with $10 million income in a dataset of mostly $30k-$100k incomes will skew the high-income cluster centroid.</p>
<p><strong>Strategies for handling outliers</strong>:</p>
<ol type="1">
<li><strong>Remove extreme outliers</strong> before clustering (but document this decision)</li>
<li><strong>Winsorize</strong> features (cap extreme values at percentiles like 1st and 99th)</li>
<li><strong>Use robust scaling</strong> (e.g., <code>RobustScaler</code> instead of <code>StandardScaler</code>)</li>
<li><strong>Consider alternative algorithms</strong> like DBSCAN that are inherently robust to outliers</li>
</ol>
<p><strong>Non-spherical clusters</strong>: We saw earlier how K-Means fails on crescent-shaped clusters. Real business data often exhibits:</p>
<ul>
<li><strong>Elongated clusters</strong>: Customer segments that stretch along one dimension</li>
<li><strong>Nested clusters</strong>: Premium customers forming a small cluster within broader markets</li>
<li><strong>Irregularly shaped groups</strong>: Geographic regions, time-series patterns</li>
</ul>
<p>For such data, consider:</p>
<ul>
<li><strong>Hierarchical clustering</strong>: Builds trees of clusters, handling various shapes</li>
<li><strong>DBSCAN</strong>: Finds dense regions of any shape</li>
<li><strong>Gaussian Mixture Models</strong>: Allows elliptical (elongated) clusters</li>
</ul>
<p>We’ll briefly cover these alternatives later in this chapter.</p>
<div class="callout callout-style-simple callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Don’t Force K-Means on Inappropriate Data
</div>
</div>
<div class="callout-body-container callout-body">
<p>If exploratory visualization reveals clearly non-spherical patterns, crescent shapes, or highly varying cluster densities, K-Means likely isn’t the right tool. Forcing it will produce mathematically “optimal” but meaningless results. This is one reason why visualizing your data (at least in 2D projections) before clustering is valuable.</p>
</div>
</div>
</section>
</section>
<section id="other-clustering-techniques-overview" class="level2" data-number="31.6">
<h2 data-number="31.6" class="anchored" data-anchor-id="other-clustering-techniques-overview"><span class="header-section-number">31.6</span> Other Clustering Techniques (Overview)</h2>
<p>While K-Means is the workhorse of business clustering, alternative algorithms handle situations where K-Means assumptions don’t hold. You don’t need to master these techniques in this course, but understanding when they’re useful will make you a more versatile data scientist.</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Hierarchical Clustering: Building a Tree of Clusters
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Hierarchical clustering</strong> builds a tree-like structure (dendrogram) that shows how observations group at different levels of similarity. Unlike K-Means, you don’t need to specify <em>k</em> upfront—the tree shows clustering solutions for all possible values of <em>k</em>.</p>
<p><strong>How it works</strong>:</p>
<ol type="1">
<li><strong>Start</strong>: Each observation is its own cluster</li>
<li><strong>Repeat</strong>: Find the two most similar clusters and merge them</li>
<li><strong>End</strong>: Continue until all observations are in one big cluster</li>
<li><strong>Visualize</strong>: The dendrogram shows the order and distance of merges</li>
</ol>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Explore multiple values of <em>k</em> simultaneously</li>
<li>Naturally handles non-spherical shapes better than K-Means</li>
<li>Produces a hierarchy that might reflect natural taxonomies (e.g., product categories)</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Computationally expensive for large datasets (scales poorly beyond ~10,000 observations)</li>
<li>Still sensitive to outliers</li>
<li>Hard to interpret dendrograms with many observations</li>
</ul>
<p><strong>When to use</strong>: When you’re uncertain about <em>k</em>, have a small-to-moderate dataset, and want to explore hierarchical relationships in your data.</p>
<div id="6f4c9f13" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> dendrogram, linkage</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Use a subset of customers for clarity</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>sample_customers <span class="op">=</span> customer_data.sample(<span class="dv">30</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale the data</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>sample_scaled <span class="op">=</span> scaler.fit_transform(sample_customers[[<span class="st">'age'</span>, <span class="st">'annual_income'</span>]])</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform hierarchical clustering</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>linkage_matrix <span class="op">=</span> linkage(sample_scaled, method<span class="op">=</span><span class="st">'ward'</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot dendrogram</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">6</span>))</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>dendrogram(linkage_matrix,</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>           labels<span class="op">=</span>sample_customers.index.tolist(),</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>           leaf_font_size<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Customer Index'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Distance (Ward Linkage)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Hierarchical Clustering Dendrogram'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">6</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Cut at k=3'</span>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Reading the dendrogram:"</span>)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"- Each leaf (bottom) represents one customer"</span>)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"- Branches merge at heights indicating dissimilarity"</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"- Cutting the tree horizontally (red line) gives k=3 clusters"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-15-output-1.png" width="855" height="566" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reading the dendrogram:
- Each leaf (bottom) represents one customer
- Branches merge at heights indicating dissimilarity
- Cutting the tree horizontally (red line) gives k=3 clusters</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-23-contents" aria-controls="callout-23" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Density-Based Clustering (DBSCAN)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-23" class="callout-23-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>DBSCAN</strong> (Density-Based Spatial Clustering of Applications with Noise) finds clusters based on density rather than distance from centroids. It groups together observations that are closely packed, marking sparse regions as outliers.</p>
<p><strong>How it works</strong>:</p>
<ol type="1">
<li>Define two parameters: <code>eps</code> (neighborhood radius) and <code>min_samples</code> (minimum points to form a cluster)</li>
<li>For each point, count how many neighbors it has within distance <code>eps</code></li>
<li>Points with enough neighbors become “core points” that form clusters</li>
<li>Points that aren’t core points but are near them join those clusters</li>
<li>Points that don’t belong to any cluster are marked as outliers (-1)</li>
</ol>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Handles arbitrary cluster shapes (crescents, elongated, irregular)</li>
<li>Automatically identifies outliers/noise</li>
<li>No need to specify <em>k</em> upfront</li>
<li>Robust to outliers</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Requires tuning <code>eps</code> and <code>min_samples</code> parameters (can be tricky)</li>
<li>Struggles with clusters of varying densities</li>
<li>Doesn’t work well in high-dimensional spaces (&gt; 10-15 features)</li>
</ul>
<p><strong>When to use</strong>: When clusters have irregular shapes, when you suspect outliers, or when cluster counts are unknown and K-Means fails.</p>
<div id="dd629e55" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the crescent-shaped data from earlier</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.2</span>, min_samples<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>dbscan_labels <span class="op">=</span> dbscan.fit_predict(X_moons)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot DBSCAN results</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>unique_labels <span class="op">=</span> <span class="bu">set</span>(dbscan_labels)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'blue'</span>, <span class="st">'green'</span>, <span class="st">'yellow'</span>]</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label <span class="kw">in</span> unique_labels:</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> label <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Outliers</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        color <span class="op">=</span> <span class="st">'yellow'</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        marker <span class="op">=</span> <span class="st">'x'</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        label_text <span class="op">=</span> <span class="st">'Outliers'</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        color <span class="op">=</span> colors[label <span class="op">%</span> <span class="bu">len</span>(colors)]</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        marker <span class="op">=</span> <span class="st">'o'</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        label_text <span class="op">=</span> <span class="ss">f'Cluster </span><span class="sc">{</span>label<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> dbscan_labels <span class="op">==</span> label</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X_moons[mask, <span class="dv">0</span>], X_moons[mask, <span class="dv">1</span>],</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>               c<span class="op">=</span>color, marker<span class="op">=</span>marker, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">60</span>,</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>               edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>               label<span class="op">=</span>label_text)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Feature 1'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature 2'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'DBSCAN: Handles Non-Spherical Clusters'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"DBSCAN found </span><span class="sc">{</span><span class="bu">len</span>(<span class="bu">set</span>(dbscan_labels) <span class="op">-</span> {<span class="op">-</span><span class="dv">1</span>})<span class="sc">}</span><span class="ss"> clusters"</span>)</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of outliers: </span><span class="sc">{</span><span class="bu">sum</span>(dbscan_labels <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-16-output-1.png" width="759" height="566" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>DBSCAN found 2 clusters
Number of outliers: 0</code></pre>
</div>
</div>
</div>
</div>
</div>
<section id="when-to-use-alternatives-to-k-means" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-alternatives-to-k-means">When to Use Alternatives to K-Means</h3>
<p>Here’s a decision guide for choosing clustering algorithms:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Situation</strong></th>
<th><strong>Recommended Algorithm</strong></th>
<th><strong>Why</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Spherical, well-separated clusters</td>
<td>K-Means</td>
<td>Fast, interpretable, works well</td>
</tr>
<tr class="even">
<td>Non-spherical, irregular shapes</td>
<td>DBSCAN or Hierarchical</td>
<td>Handle arbitrary shapes</td>
</tr>
<tr class="odd">
<td>Uncertain about <em>k</em></td>
<td>Hierarchical or DBSCAN</td>
<td>Explore multiple <em>k</em> or auto-detect</td>
</tr>
<tr class="even">
<td>Clusters of varying size/density</td>
<td>DBSCAN or Gaussian Mixture</td>
<td>Not constrained to equal sizes</td>
</tr>
<tr class="odd">
<td>Outliers present</td>
<td>DBSCAN</td>
<td>Explicitly identifies outliers</td>
</tr>
<tr class="even">
<td>Small dataset (&lt; 10k observations)</td>
<td>Hierarchical</td>
<td>Computationally feasible</td>
</tr>
<tr class="odd">
<td>Large dataset (&gt; 100k observations)</td>
<td>K-Means or Mini-Batch K-Means</td>
<td>Scales efficiently</td>
</tr>
<tr class="even">
<td>Need interpretability</td>
<td>K-Means or Hierarchical</td>
<td>Clear centroids or dendrogram</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Start with K-Means, Then Explore
</div>
</div>
<div class="callout-body-container callout-body">
<p>For most business applications, start with K-Means. It’s fast, interpretable, and works well when assumptions hold. If you get poor results or suspect violations of assumptions (visualize your data!), then explore alternatives. Don’t overthink algorithm choice until you’ve validated that K-Means isn’t working.</p>
</div>
</div>
</section>
</section>
<section id="case-study-complete-journey-customer-segmentation" class="level2" data-number="31.7">
<h2 data-number="31.7" class="anchored" data-anchor-id="case-study-complete-journey-customer-segmentation"><span class="header-section-number">31.7</span> Case Study: Complete Journey Customer Segmentation</h2>
<p>Let’s apply everything we’ve learned to a real business problem: segmenting grocery store customers using both their purchasing behavior and demographic characteristics. This case study walks through the complete workflow from data preparation to actionable insights using the <strong>Complete Journey</strong> dataset—a rich collection of transaction data from 801 households tracked over one full year at a grocery retailer.</p>
<section id="the-business-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-business-problem">The Business Problem</h3>
<p>A grocery retailer wants to better understand their customer base to personalize marketing campaigns, optimize product placement, and design targeted promotions. They have detailed transaction history and demographic data for hundreds of households but no existing segmentation strategy. The marketing and analytics teams ask:</p>
<ul>
<li>What natural customer segments exist based on shopping behavior?</li>
<li>How do these segments differ in spending, visit frequency, and discount sensitivity?</li>
<li>Do demographic characteristics align with behavioral patterns?</li>
<li>Can we create actionable, targeted campaigns for each segment?</li>
</ul>
<p>We’ll use the Complete Journey dataset to discover these segments using K-Means clustering, combining behavioral features from transactions with demographic attributes.</p>
</section>
<section id="loading-and-exploring-the-data" class="level3">
<h3 class="anchored" data-anchor-id="loading-and-exploring-the-data">Loading and Exploring the Data</h3>
<p>The Complete Journey dataset includes multiple related tables. For customer segmentation, we’ll primarily use transactions (purchase behavior) and demographics (household characteristics):</p>
<div id="9e1ff496" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> completejourney_py <span class="im">import</span> get_data</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Complete Journey datasets</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> get_data()</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>transactions <span class="op">=</span> data[<span class="st">'transactions'</span>]</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>demographics <span class="op">=</span> data[<span class="st">"demographics"</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="aaf5864a" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>transactions.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">household_id</th>
<th data-quarto-table-cell-role="th">store_id</th>
<th data-quarto-table-cell-role="th">basket_id</th>
<th data-quarto-table-cell-role="th">product_id</th>
<th data-quarto-table-cell-role="th">quantity</th>
<th data-quarto-table-cell-role="th">sales_value</th>
<th data-quarto-table-cell-role="th">retail_disc</th>
<th data-quarto-table-cell-role="th">coupon_disc</th>
<th data-quarto-table-cell-role="th">coupon_match_disc</th>
<th data-quarto-table-cell-role="th">week</th>
<th data-quarto-table-cell-role="th">transaction_timestamp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>900</td>
<td>330</td>
<td>31198570044</td>
<td>1095275</td>
<td>1</td>
<td>0.50</td>
<td>0.00</td>
<td>0.0</td>
<td>0.0</td>
<td>1</td>
<td>2017-01-01 11:53:26</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>900</td>
<td>330</td>
<td>31198570047</td>
<td>9878513</td>
<td>1</td>
<td>0.99</td>
<td>0.10</td>
<td>0.0</td>
<td>0.0</td>
<td>1</td>
<td>2017-01-01 12:10:28</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>1228</td>
<td>406</td>
<td>31198655051</td>
<td>1041453</td>
<td>1</td>
<td>1.43</td>
<td>0.15</td>
<td>0.0</td>
<td>0.0</td>
<td>1</td>
<td>2017-01-01 12:26:30</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>906</td>
<td>319</td>
<td>31198705046</td>
<td>1020156</td>
<td>1</td>
<td>1.50</td>
<td>0.29</td>
<td>0.0</td>
<td>0.0</td>
<td>1</td>
<td>2017-01-01 12:30:27</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>906</td>
<td>319</td>
<td>31198705046</td>
<td>1053875</td>
<td>2</td>
<td>2.78</td>
<td>0.80</td>
<td>0.0</td>
<td>0.0</td>
<td>1</td>
<td>2017-01-01 12:30:27</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="da3ecf1f" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>demographics.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">household_id</th>
<th data-quarto-table-cell-role="th">age</th>
<th data-quarto-table-cell-role="th">income</th>
<th data-quarto-table-cell-role="th">home_ownership</th>
<th data-quarto-table-cell-role="th">marital_status</th>
<th data-quarto-table-cell-role="th">household_size</th>
<th data-quarto-table-cell-role="th">household_comp</th>
<th data-quarto-table-cell-role="th">kids_count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1</td>
<td>65+</td>
<td>35-49K</td>
<td>Homeowner</td>
<td>Married</td>
<td>2</td>
<td>2 Adults No Kids</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>1001</td>
<td>45-54</td>
<td>50-74K</td>
<td>Homeowner</td>
<td>Unmarried</td>
<td>1</td>
<td>1 Adult No Kids</td>
<td>0</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>1003</td>
<td>35-44</td>
<td>25-34K</td>
<td>None</td>
<td>Unmarried</td>
<td>1</td>
<td>1 Adult No Kids</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>1004</td>
<td>25-34</td>
<td>15-24K</td>
<td>None</td>
<td>Unmarried</td>
<td>1</td>
<td>1 Adult No Kids</td>
<td>0</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>101</td>
<td>45-54</td>
<td>Under 15K</td>
<td>Homeowner</td>
<td>Married</td>
<td>4</td>
<td>2 Adults Kids</td>
<td>2</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The transactions table contains detailed purchase records including quantities, sales values, discounts, and timestamps. The demographics table provides household characteristics like age, income, marital status, home ownership, and household composition.</p>
</section>
<section id="feature-engineering-and-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="feature-engineering-and-preprocessing">Feature Engineering and Preprocessing</h3>
<p>Our clustering will combine two types of features:</p>
<ol type="1">
<li><strong>Behavioral features</strong>: Aggregated from transaction data (spending, frequency, basket patterns, discount usage)</li>
<li><strong>Demographic features</strong>: From the demographics table (age, income, household composition)</li>
</ol>
<p>Let’s start by creating household-level behavioral features. I’ve collapsed this code since its a bit lengthy but feel free to explore it. It results in the following dataframe that contains features such as average basket value, number of trips, unique products purchased, etc. for each household.</p>
<div id="52aff037" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Feature engineering</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Create behavioral features from transactions</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert transaction_timestamp to datetime (suppress warning)</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>transactions[<span class="st">'transaction_timestamp'</span>] <span class="op">=</span> pd.to_datetime(transactions[<span class="st">'transaction_timestamp'</span>], <span class="bu">format</span><span class="op">=</span><span class="st">'mixed'</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the last date in the dataset for recency calculations</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>max_date <span class="op">=</span> transactions[<span class="st">'transaction_timestamp'</span>].<span class="bu">max</span>()</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggregate transaction data by household</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>behavioral_features <span class="op">=</span> transactions.groupby(<span class="st">'household_id'</span>).agg({</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Spending metrics</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'sales_value'</span>: [<span class="st">'sum'</span>, <span class="st">'mean'</span>],  <span class="co"># Total spending and average transaction value</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'basket_id'</span>: <span class="st">'nunique'</span>,  <span class="co"># Number of unique shopping trips</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'product_id'</span>: <span class="st">'nunique'</span>,  <span class="co"># Number of unique products purchased</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Discount sensitivity</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'retail_disc'</span>: <span class="st">'sum'</span>,  <span class="co"># Total retail discounts used</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'coupon_disc'</span>: <span class="st">'sum'</span>,  <span class="co"># Total coupon discounts used</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Temporal patterns</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">'transaction_timestamp'</span>: [<span class="st">'min'</span>, <span class="st">'max'</span>]  <span class="co"># First and last purchase dates</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>}).reset_index()</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten column names</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>behavioral_features.columns <span class="op">=</span> [<span class="st">'household_id'</span>, <span class="st">'total_spending'</span>, <span class="st">'avg_basket_value'</span>,</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>                                <span class="st">'num_trips'</span>, <span class="st">'num_unique_products'</span>,</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>                                <span class="st">'total_retail_disc'</span>, <span class="st">'total_coupon_disc'</span>,</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>                                <span class="st">'first_purchase'</span>, <span class="st">'last_purchase'</span>]</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Create additional engineered features</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>behavioral_features[<span class="st">'days_active'</span>] <span class="op">=</span> (behavioral_features[<span class="st">'last_purchase'</span>] <span class="op">-</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>                                      behavioral_features[<span class="st">'first_purchase'</span>]).dt.days <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>behavioral_features[<span class="st">'recency_days'</span>] <span class="op">=</span> (max_date <span class="op">-</span> behavioral_features[<span class="st">'last_purchase'</span>]).dt.days</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>behavioral_features[<span class="st">'avg_days_between_trips'</span>] <span class="op">=</span> (behavioral_features[<span class="st">'days_active'</span>] <span class="op">/</span></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>                                                  behavioral_features[<span class="st">'num_trips'</span>])</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate discount usage rates</span></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>behavioral_features[<span class="st">'total_discount'</span>] <span class="op">=</span> (behavioral_features[<span class="st">'total_retail_disc'</span>] <span class="op">+</span></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>                                         behavioral_features[<span class="st">'total_coupon_disc'</span>])</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>behavioral_features[<span class="st">'discount_rate'</span>] <span class="op">=</span> (behavioral_features[<span class="st">'total_discount'</span>] <span class="op">/</span></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>                                        behavioral_features[<span class="st">'total_spending'</span>])</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>behavioral_features[<span class="st">'coupon_usage_rate'</span>] <span class="op">=</span> (behavioral_features[<span class="st">'total_coupon_disc'</span>] <span class="op">/</span></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>                                            behavioral_features[<span class="st">'total_spending'</span>])</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop temporary date columns</span></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>behavioral_features <span class="op">=</span> behavioral_features.drop([<span class="st">'first_purchase'</span>, <span class="st">'last_purchase'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Merge behavioral features with demographics</span></span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a><span class="co"># The demographics table already has household_id column from completejourney_py</span></span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>customer_data <span class="op">=</span> behavioral_features.merge(demographics, on<span class="op">=</span><span class="st">'household_id'</span>, how<span class="op">=</span><span class="st">'inner'</span>)</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Encode demographic features</span></span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Map column names (completejourney_py may use different names than CSV files)</span></span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>col_mapping <span class="op">=</span> {}</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> customer_data.columns:</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>    lower_col <span class="op">=</span> col.lower()</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'age'</span> <span class="kw">in</span> lower_col <span class="kw">and</span> <span class="st">'age_encoded'</span> <span class="kw">not</span> <span class="kw">in</span> lower_col:</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>        col_mapping[<span class="st">'age'</span>] <span class="op">=</span> col</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">'income'</span> <span class="kw">in</span> lower_col <span class="kw">and</span> <span class="st">'income_encoded'</span> <span class="kw">not</span> <span class="kw">in</span> lower_col:</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>        col_mapping[<span class="st">'income'</span>] <span class="op">=</span> col</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">'household_size'</span> <span class="kw">in</span> lower_col <span class="kw">or</span> <span class="st">'hh_size'</span> <span class="kw">in</span> lower_col:</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>        col_mapping[<span class="st">'household_size'</span>] <span class="op">=</span> col</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">'marital'</span> <span class="kw">in</span> lower_col:</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>        col_mapping[<span class="st">'marital_status'</span>] <span class="op">=</span> col</span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">'homeowner'</span> <span class="kw">in</span> lower_col <span class="kw">or</span> <span class="st">'home_owner'</span> <span class="kw">in</span> lower_col:</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>        col_mapping[<span class="st">'homeowner'</span>] <span class="op">=</span> col</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">'kid'</span> <span class="kw">in</span> lower_col <span class="kw">or</span> <span class="st">'child'</span> <span class="kw">in</span> lower_col:</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>        col_mapping[<span class="st">'kids'</span>] <span class="op">=</span> col</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert age brackets to ordinal numbers</span></span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>age_map <span class="op">=</span> {</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>    <span class="st">'19-24'</span>: <span class="dv">1</span>, <span class="st">'25-34'</span>: <span class="dv">2</span>, <span class="st">'35-44'</span>: <span class="dv">3</span>, <span class="st">'45-54'</span>: <span class="dv">4</span>,</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a>    <span class="st">'55-64'</span>: <span class="dv">5</span>, <span class="st">'65+'</span>: <span class="dv">6</span></span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>customer_data[<span class="st">'age_encoded'</span>] <span class="op">=</span> customer_data[col_mapping.get(<span class="st">'age'</span>, <span class="st">'age'</span>)].<span class="bu">map</span>(age_map)</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert income brackets to ordinal numbers</span></span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>income_map <span class="op">=</span> {</span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Under 15K'</span>: <span class="dv">1</span>, <span class="st">'15-24K'</span>: <span class="dv">2</span>, <span class="st">'25-34K'</span>: <span class="dv">3</span>, <span class="st">'35-49K'</span>: <span class="dv">4</span>,</span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>    <span class="st">'50-74K'</span>: <span class="dv">5</span>, <span class="st">'75-99K'</span>: <span class="dv">6</span>, <span class="st">'100-124K'</span>: <span class="dv">7</span>, <span class="st">'125-149K'</span>: <span class="dv">8</span>,</span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a>    <span class="st">'150-174K'</span>: <span class="dv">9</span>, <span class="st">'175-199K'</span>: <span class="dv">10</span>, <span class="st">'200-249K'</span>: <span class="dv">11</span>, <span class="st">'250K+'</span>: <span class="dv">12</span></span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>customer_data[<span class="st">'income_encoded'</span>] <span class="op">=</span> customer_data[col_mapping.get(<span class="st">'income'</span>, <span class="st">'income'</span>)].<span class="bu">map</span>(income_map)</span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract household size</span></span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a>hh_size_col <span class="op">=</span> col_mapping.get(<span class="st">'household_size'</span>, <span class="st">'household_size'</span>)</span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> customer_data[hh_size_col].dtype <span class="op">==</span> <span class="st">'object'</span>:</span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a>    customer_data[<span class="st">'household_size_num'</span>] <span class="op">=</span> customer_data[hh_size_col].<span class="bu">str</span>.extract(<span class="vs">r'</span><span class="kw">(</span><span class="dv">\d</span><span class="op">+</span><span class="kw">)</span><span class="vs">'</span>).astype(<span class="bu">float</span>)</span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>    customer_data[<span class="st">'household_size_num'</span>] <span class="op">=</span> customer_data[hh_size_col]</span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract number of kids</span></span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'kids'</span> <span class="kw">in</span> col_mapping:</span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>    kids_col <span class="op">=</span> col_mapping[<span class="st">'kids'</span>]</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> customer_data[kids_col].dtype <span class="op">==</span> <span class="st">'object'</span>:</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a>        customer_data[<span class="st">'num_kids'</span>] <span class="op">=</span> customer_data[kids_col].replace(<span class="st">'None/Unknown'</span>, <span class="st">'0'</span>)</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>        customer_data[<span class="st">'num_kids'</span>] <span class="op">=</span> customer_data[<span class="st">'num_kids'</span>].<span class="bu">str</span>.extract(<span class="vs">r'</span><span class="kw">(</span><span class="dv">\d</span><span class="op">+</span><span class="kw">)</span><span class="vs">'</span>).fillna(<span class="dv">0</span>).astype(<span class="bu">int</span>)</span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a>        customer_data[<span class="st">'num_kids'</span>] <span class="op">=</span> customer_data[kids_col].fillna(<span class="dv">0</span>).astype(<span class="bu">int</span>)</span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a>    customer_data[<span class="st">'num_kids'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a><span class="co"># Create binary features</span></span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a>marital_col <span class="op">=</span> col_mapping.get(<span class="st">'marital_status'</span>, <span class="st">'marital_status'</span>)</span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a>customer_data[<span class="st">'is_married'</span>] <span class="op">=</span> (customer_data[marital_col] <span class="op">==</span> <span class="st">'Married'</span>).astype(<span class="bu">int</span>)</span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a>homeowner_col <span class="op">=</span> col_mapping.get(<span class="st">'homeowner'</span>, <span class="st">'homeowner'</span>)</span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a>customer_data[<span class="st">'is_homeowner'</span>] <span class="op">=</span> (customer_data[homeowner_col] <span class="op">==</span> <span class="st">'Homeowner'</span>).astype(<span class="bu">int</span>)</span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a><span class="co"># Handle missing values - drop rows with missing demographics</span></span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a>customer_data_clean <span class="op">=</span> customer_data.dropna(subset<span class="op">=</span>[<span class="st">'age_encoded'</span>, <span class="st">'income_encoded'</span>])</span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Select features for clustering</span></span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a>cluster_features <span class="op">=</span> [</span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Behavioral features</span></span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a>    <span class="st">'total_spending'</span>,</span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a>    <span class="st">'avg_basket_value'</span>,</span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a>    <span class="st">'num_trips'</span>,</span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a>    <span class="st">'num_unique_products'</span>,</span>
<span id="cb21-121"><a href="#cb21-121" aria-hidden="true" tabindex="-1"></a>    <span class="st">'avg_days_between_trips'</span>,</span>
<span id="cb21-122"><a href="#cb21-122" aria-hidden="true" tabindex="-1"></a>    <span class="st">'recency_days'</span>,</span>
<span id="cb21-123"><a href="#cb21-123" aria-hidden="true" tabindex="-1"></a>    <span class="st">'discount_rate'</span>,</span>
<span id="cb21-124"><a href="#cb21-124" aria-hidden="true" tabindex="-1"></a>    <span class="st">'coupon_usage_rate'</span>,</span>
<span id="cb21-125"><a href="#cb21-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-126"><a href="#cb21-126" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Demographic features</span></span>
<span id="cb21-127"><a href="#cb21-127" aria-hidden="true" tabindex="-1"></a>    <span class="st">'age_encoded'</span>,</span>
<span id="cb21-128"><a href="#cb21-128" aria-hidden="true" tabindex="-1"></a>    <span class="st">'income_encoded'</span>,</span>
<span id="cb21-129"><a href="#cb21-129" aria-hidden="true" tabindex="-1"></a>    <span class="st">'household_size_num'</span>,</span>
<span id="cb21-130"><a href="#cb21-130" aria-hidden="true" tabindex="-1"></a>    <span class="st">'num_kids'</span>,</span>
<span id="cb21-131"><a href="#cb21-131" aria-hidden="true" tabindex="-1"></a>    <span class="st">'is_married'</span>,</span>
<span id="cb21-132"><a href="#cb21-132" aria-hidden="true" tabindex="-1"></a>    <span class="st">'is_homeowner'</span></span>
<span id="cb21-133"><a href="#cb21-133" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb21-134"><a href="#cb21-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-135"><a href="#cb21-135" aria-hidden="true" tabindex="-1"></a>X_cluster <span class="op">=</span> customer_data_clean[cluster_features]</span>
<span id="cb21-136"><a href="#cb21-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-137"><a href="#cb21-137" aria-hidden="true" tabindex="-1"></a>X_cluster.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">total_spending</th>
<th data-quarto-table-cell-role="th">avg_basket_value</th>
<th data-quarto-table-cell-role="th">num_trips</th>
<th data-quarto-table-cell-role="th">num_unique_products</th>
<th data-quarto-table-cell-role="th">avg_days_between_trips</th>
<th data-quarto-table-cell-role="th">recency_days</th>
<th data-quarto-table-cell-role="th">discount_rate</th>
<th data-quarto-table-cell-role="th">coupon_usage_rate</th>
<th data-quarto-table-cell-role="th">age_encoded</th>
<th data-quarto-table-cell-role="th">income_encoded</th>
<th data-quarto-table-cell-role="th">household_size_num</th>
<th data-quarto-table-cell-role="th">num_kids</th>
<th data-quarto-table-cell-role="th">is_married</th>
<th data-quarto-table-cell-role="th">is_homeowner</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>2415.56</td>
<td>2.459837</td>
<td>51</td>
<td>437</td>
<td>7.039216</td>
<td>0</td>
<td>0.176862</td>
<td>0.023001</td>
<td>6</td>
<td>4</td>
<td>2.0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>1952.37</td>
<td>2.555458</td>
<td>32</td>
<td>556</td>
<td>10.750000</td>
<td>5</td>
<td>0.151821</td>
<td>0.007043</td>
<td>4</td>
<td>5</td>
<td>2.0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>3080.81</td>
<td>2.808396</td>
<td>65</td>
<td>790</td>
<td>5.523077</td>
<td>3</td>
<td>0.198656</td>
<td>0.004658</td>
<td>2</td>
<td>3</td>
<td>3.0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>7448.22</td>
<td>5.659742</td>
<td>157</td>
<td>656</td>
<td>2.305732</td>
<td>0</td>
<td>0.143786</td>
<td>0.023471</td>
<td>2</td>
<td>6</td>
<td>4.0</td>
<td>2</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>646.87</td>
<td>2.967294</td>
<td>49</td>
<td>129</td>
<td>7.387755</td>
<td>1</td>
<td>0.112758</td>
<td>0.000000</td>
<td>4</td>
<td>5</td>
<td>1.0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="finding-the-optimal-number-of-clusters" class="level3">
<h3 class="anchored" data-anchor-id="finding-the-optimal-number-of-clusters">Finding the Optimal Number of Clusters</h3>
<p>Let’s use both the elbow method and silhouette analysis:</p>
<div id="f001e513" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale the features first</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>X_cluster_scaled <span class="op">=</span> scaler.fit_transform(X_cluster)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Elbow method</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>wcss_values <span class="op">=</span> []</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>k_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">21</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_range:</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    kmeans_temp <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    kmeans_temp.fit(X_cluster_scaled)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    wcss_values.append(kmeans_temp.inertia_)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Silhouette scores</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>sil_scores <span class="op">=</span> []</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_range:</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    kmeans_temp <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    labels_temp <span class="op">=</span> kmeans_temp.fit_predict(X_cluster_scaled)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    sil_score <span class="op">=</span> silhouette_score(X_cluster_scaled, labels_temp)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    sil_scores.append(sil_score)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot both methods</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="fl">9.5</span>, <span class="dv">4</span>))</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Elbow plot</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(k_range, wcss_values, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Number of Clusters (k)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'WCSS'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Elbow Method'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xticks(k_range)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Silhouette plot</span></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(k_range, sil_scores, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>             markersize<span class="op">=</span><span class="dv">8</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Number of Clusters (k)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Silhouette Score'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Silhouette Analysis'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticks(k_range)</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Results for different k values:"</span>)</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, wcss_val, sil_val <span class="kw">in</span> <span class="bu">zip</span>(k_range, wcss_values, sil_scores):</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">: WCSS=</span><span class="sc">{</span>wcss_val<span class="sc">:,.0f}</span><span class="ss">, Silhouette=</span><span class="sc">{</span>sil_val<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-21-output-1.png" width="903" height="374" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Results for different k values:
  k=2: WCSS=9,663, Silhouette=0.173
  k=3: WCSS=8,618, Silhouette=0.150
  k=4: WCSS=7,898, Silhouette=0.140
  k=5: WCSS=7,425, Silhouette=0.144
  k=6: WCSS=6,991, Silhouette=0.146
  k=7: WCSS=6,616, Silhouette=0.140
  k=8: WCSS=6,338, Silhouette=0.135
  k=9: WCSS=6,106, Silhouette=0.127
  k=10: WCSS=5,911, Silhouette=0.125
  k=11: WCSS=5,722, Silhouette=0.126
  k=12: WCSS=5,537, Silhouette=0.122
  k=13: WCSS=5,359, Silhouette=0.126
  k=14: WCSS=5,249, Silhouette=0.122
  k=15: WCSS=5,134, Silhouette=0.126
  k=16: WCSS=5,043, Silhouette=0.119
  k=17: WCSS=4,930, Silhouette=0.115
  k=18: WCSS=4,842, Silhouette=0.122
  k=19: WCSS=4,744, Silhouette=0.115
  k=20: WCSS=4,683, Silhouette=0.111</code></pre>
</div>
</div>
<p><strong>Interpreting the Results: Welcome to Real-World Data!</strong></p>
<p>Notice something important here: unlike the clean textbook examples you might have seen, there’s no obvious “elbow” in the WCSS plot, and the silhouette scores show only modest peaks without a clear winner. The elbow curve decreases gradually without a sharp bend, and silhouette scores hover around 0.12-0.17 with k=2 being highest but subsequent values showing relatively similar performance.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>This is Completely Normal for Real Data
</div>
</div>
<div class="callout-body-container callout-body">
<p>What you’re seeing is <strong>typical behavior with real-world customer data</strong>:</p>
<ol type="1">
<li><p><strong>No clear elbow</strong>: Real customer behavior exists on a spectrum, not in neat, well-separated groups. The gradual WCSS decrease reflects this reality.</p></li>
<li><p><strong>Low silhouette scores</strong>: Values around 0.15 indicate overlapping clusters with fuzzy boundaries—exactly what we expect when segmenting human behavior. Customers don’t fall into perfectly distinct categories.</p></li>
<li><p><strong>Ambiguity in optimal k</strong>: Multiple values of k (3, 4, 5, or 6) could all be “reasonable” choices. This ambiguity reflects the fact that customer segmentation is as much a <strong>business decision</strong> as a statistical one.</p></li>
</ol>
<p><strong>So how do you choose k?</strong></p>
<p>When the data doesn’t give you a clear answer, consider:</p>
<ul>
<li><strong>Business interpretability</strong>: Can you tell a coherent story about 3 segments? 4? 5? Which feels most actionable to your marketing team?</li>
<li><strong>Operational feasibility</strong>: Can your organization realistically create differentiated strategies for k segments? (More isn’t always better!)</li>
<li><strong>Stakeholder input</strong>: Domain experts might have intuitions about natural customer groupings</li>
<li><strong>Practical constraints</strong>: Budget, team size, and campaign capabilities might favor simpler segmentations</li>
</ul>
<p>For this analysis, we’ll proceed with <strong>k=4</strong> as a reasonable middle ground that balances granularity with manageability, but k=3 or k=5 would be equally defensible choices.</p>
</div>
</div>
<p>Based on this analysis, let’s proceed with k=4:</p>
<div id="87638a81" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit final K-Means model with k=4</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>optimal_k <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>kmeans_final <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>optimal_k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>customer_data_clean[<span class="st">'cluster'</span>] <span class="op">=</span> kmeans_final.fit_predict(X_cluster_scaled)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Cluster assignments:"</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(customer_data_clean[<span class="st">'cluster'</span>].value_counts().sort_index())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Cluster assignments:
cluster
0    305
1    261
2    119
3    116
Name: count, dtype: int64</code></pre>
</div>
</div>
</section>
<section id="interpreting-cluster-profiles" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-cluster-profiles">Interpreting Cluster Profiles</h3>
<p>Now comes the most important part: understanding what each cluster represents. We’ll examine the average characteristics of each segment:</p>
<div id="c5f55d2f" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create cluster profiles using original (unscaled) features</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CLUSTER PROFILES"</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Behavioral characteristics by cluster</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>behavioral_profiles <span class="op">=</span> customer_data_clean.groupby(<span class="st">'cluster'</span>).agg({</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'total_spending'</span>: <span class="st">'mean'</span>,</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'avg_basket_value'</span>: <span class="st">'mean'</span>,</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'num_trips'</span>: <span class="st">'mean'</span>,</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'num_unique_products'</span>: <span class="st">'mean'</span>,</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'avg_days_between_trips'</span>: <span class="st">'mean'</span>,</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'recency_days'</span>: <span class="st">'mean'</span>,</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'discount_rate'</span>: <span class="st">'mean'</span>,</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'coupon_usage_rate'</span>: <span class="st">'mean'</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>}).<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>behavioral_profiles[<span class="st">'count'</span>] <span class="op">=</span> customer_data_clean[<span class="st">'cluster'</span>].value_counts().sort_index()</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Behavioral Characteristics:"</span>)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(behavioral_profiles)</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Demographic characteristics by cluster</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Build aggregation dict dynamically based on available columns</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>demo_agg_dict <span class="op">=</span> {</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'household_size_num'</span>: <span class="st">'mean'</span>,</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">'num_kids'</span>: <span class="st">'mean'</span>,</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">'is_married'</span>: <span class="kw">lambda</span> x: <span class="ss">f"</span><span class="sc">{</span>x<span class="sc">.</span>mean()<span class="sc">:.1%}</span><span class="ss">"</span>,  <span class="co"># Percentage married</span></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'is_homeowner'</span>: <span class="kw">lambda</span> x: <span class="ss">f"</span><span class="sc">{</span>x<span class="sc">.</span>mean()<span class="sc">:.1%}</span><span class="ss">"</span>  <span class="co"># Percentage homeowners</span></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Add age and income if they exist in the dataframe</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>age_col <span class="op">=</span> col_mapping.get(<span class="st">'age'</span>, <span class="va">None</span>)</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>income_col <span class="op">=</span> col_mapping.get(<span class="st">'income'</span>, <span class="va">None</span>)</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> age_col <span class="kw">and</span> age_col <span class="kw">in</span> customer_data_clean.columns:</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>    demo_agg_dict[age_col] <span class="op">=</span> <span class="kw">lambda</span> x: x.mode()[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">len</span>(x.mode()) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">'Mixed'</span></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> income_col <span class="kw">and</span> income_col <span class="kw">in</span> customer_data_clean.columns:</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>    demo_agg_dict[income_col] <span class="op">=</span> <span class="kw">lambda</span> x: x.mode()[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">len</span>(x.mode()) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">'Mixed'</span></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>demographic_profiles <span class="op">=</span> customer_data_clean.groupby(<span class="st">'cluster'</span>).agg(demo_agg_dict).<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Demographic Characteristics:"</span>)</span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(demographic_profiles)</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Add more detailed analysis for each cluster</span></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">Detailed Segment Descriptions:"</span>)</span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cluster_id <span class="kw">in</span> <span class="bu">range</span>(optimal_k):</span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>    cluster_data <span class="op">=</span> customer_data_clean[customer_data_clean[<span class="st">'cluster'</span>] <span class="op">==</span> cluster_id]</span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Cluster </span><span class="sc">{</span>cluster_id<span class="sc">}</span><span class="ss"> (n=</span><span class="sc">{</span><span class="bu">len</span>(cluster_data)<span class="sc">}</span><span class="ss">):"</span>)</span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Total spending: $</span><span class="sc">{</span>cluster_data[<span class="st">'total_spending'</span>]<span class="sc">.</span>mean()<span class="sc">:,.0f}</span><span class="ss">"</span>)</span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Avg basket value: $</span><span class="sc">{</span>cluster_data[<span class="st">'avg_basket_value'</span>]<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Shopping trips: </span><span class="sc">{</span>cluster_data[<span class="st">'num_trips'</span>]<span class="sc">.</span>mean()<span class="sc">:.0f}</span><span class="ss">"</span>)</span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Discount rate: </span><span class="sc">{</span>cluster_data[<span class="st">'discount_rate'</span>]<span class="sc">.</span>mean()<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Coupon usage: </span><span class="sc">{</span>cluster_data[<span class="st">'coupon_usage_rate'</span>]<span class="sc">.</span>mean()<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show age and income if available</span></span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> age_col <span class="kw">and</span> age_col <span class="kw">in</span> cluster_data.columns:</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Dominant age: </span><span class="sc">{</span>cluster_data[age_col]<span class="sc">.</span>mode()[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">len</span>(cluster_data[age_col].mode()) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">'Mixed'</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> income_col <span class="kw">and</span> income_col <span class="kw">in</span> cluster_data.columns:</span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Dominant income: </span><span class="sc">{</span>cluster_data[income_col]<span class="sc">.</span>mode()[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">len</span>(cluster_data[income_col].mode()) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">'Mixed'</span><span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
================================================================================
CLUSTER PROFILES
================================================================================

Behavioral Characteristics:
         total_spending  avg_basket_value  num_trips  num_unique_products  \
cluster                                                                     
0               2352.07              3.26      70.54               426.00   
1               2591.18              2.91     100.03               512.23   
2               3319.07              3.10      83.97               618.75   
3               7209.74              3.59     208.64              1017.30   

         avg_days_between_trips  recency_days  discount_rate  \
cluster                                                        
0                          6.00          7.25           0.19   
1                          4.51          4.92           0.19   
2                          5.32          4.44           0.21   
3                          2.33          1.78           0.15   

         coupon_usage_rate  count  
cluster                            
0                     0.01    305  
1                     0.00    261  
2                     0.01    119  
3                     0.01    116  

Demographic Characteristics:
         household_size_num  num_kids is_married is_homeowner    age  income
cluster                                                                     
0                       1.9       0.3      52.1%        95.7%  45-54  50-74K
1                       1.5       0.2       8.4%         6.5%  45-54  35-49K
2                       4.4       2.4      78.2%        83.2%  35-44  35-49K
3                       2.3       0.6      56.9%        82.8%  45-54  50-74K


Detailed Segment Descriptions:
================================================================================

Cluster 0 (n=305):
  Total spending: $2,352
  Avg basket value: $3.26
  Shopping trips: 71
  Discount rate: 18.9%
  Coupon usage: 0.7%
  Dominant age: 45-54
  Dominant income: 50-74K

Cluster 1 (n=261):
  Total spending: $2,591
  Avg basket value: $2.91
  Shopping trips: 100
  Discount rate: 18.6%
  Coupon usage: 0.5%
  Dominant age: 45-54
  Dominant income: 35-49K

Cluster 2 (n=119):
  Total spending: $3,319
  Avg basket value: $3.10
  Shopping trips: 84
  Discount rate: 20.6%
  Coupon usage: 0.8%
  Dominant age: 35-44
  Dominant income: 35-49K

Cluster 3 (n=116):
  Total spending: $7,210
  Avg basket value: $3.59
  Shopping trips: 209
  Discount rate: 15.3%
  Coupon usage: 0.6%
  Dominant age: 45-54
  Dominant income: 50-74K</code></pre>
</div>
</div>
</section>
<section id="visualizing-the-segments" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-segments">Visualizing the Segments</h3>
<p>Let’s create visualizations to help understand the segments:</p>
<div id="2163ad74" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 2D visualization showing behavioral patterns</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: Total Spending vs Number of Trips</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>colors_segments <span class="op">=</span> [<span class="st">'#FF6B6B'</span>, <span class="st">'#4ECDC4'</span>, <span class="st">'#45B7D1'</span>, <span class="st">'#96CEB4'</span>]</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(optimal_k):</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    cluster_data <span class="op">=</span> customer_data_clean[customer_data_clean[<span class="st">'cluster'</span>] <span class="op">==</span> i]</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].scatter(cluster_data[<span class="st">'num_trips'</span>], cluster_data[<span class="st">'total_spending'</span>],</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>                   alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>colors_segments[i],</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span><span class="ss">f'Cluster </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidths<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Number of Shopping Trips'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Total Spending ($)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Customer Segments: Spending vs. Frequency'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend(loc<span class="op">=</span><span class="st">'best'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 2: Discount Rate vs Coupon Usage</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(optimal_k):</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>    cluster_data <span class="op">=</span> customer_data_clean[customer_data_clean[<span class="st">'cluster'</span>] <span class="op">==</span> i]</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].scatter(cluster_data[<span class="st">'discount_rate'</span>], cluster_data[<span class="st">'coupon_usage_rate'</span>],</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>                   alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span>colors_segments[i],</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span><span class="ss">f'Cluster </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidths<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Discount Rate'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Coupon Usage Rate'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Customer Segments: Discount Sensitivity'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend(loc<span class="op">=</span><span class="st">'best'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="31-clustering_files/figure-html/cell-24-output-1.png" width="1335" height="566" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="actionable-marketing-recommendations" class="level3">
<h3 class="anchored" data-anchor-id="actionable-marketing-recommendations">Actionable Marketing Recommendations</h3>
<p>Now we translate statistical clusters into business strategy:</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Marketing Strategy by Segment
</div>
</div>
<div class="callout-body-container callout-body">
<p>Based on the behavioral and demographic profiles discovered in the clustering analysis, here are data-driven marketing recommendations for a grocery retailer. The specific strategies should be customized based on your actual cluster characteristics, but here’s a framework based on common grocery shopping patterns:</p>
<p><strong>High-Value Loyal Shoppers</strong> (Example: High spending, frequent trips, low discount usage)</p>
<ul>
<li><strong>Behavioral profile</strong>: Large total spending, frequent shopping trips, high basket values, minimal reliance on discounts or coupons</li>
<li><strong>Marketing strategy</strong>: VIP loyalty tier with exclusive benefits, personalized recommendations, early access to new products, premium private label emphasis</li>
<li><strong>Promotional approach</strong>: Focus on convenience (online ordering, curbside pickup), quality messaging over price, targeted product bundles based on purchase history</li>
<li><strong>Engagement tactics</strong>: Personal shopper services, recipe ideas featuring premium ingredients, wine/cheese pairing events</li>
</ul>
<p><strong>Bargain Hunters</strong> (Example: High discount/coupon usage, price-sensitive)</p>
<ul>
<li><strong>Behavioral profile</strong>: Heavy coupon and discount usage, shops sales aggressively, may have lower basket values but decent frequency</li>
<li><strong>Marketing strategy</strong>: Maximize coupon redemption, highlight weekly specials, emphasize savings opportunities</li>
<li><strong>Promotional approach</strong>: Double coupon days, loyalty program with points-based discounts, digital coupons via app, loss leaders to drive traffic</li>
<li><strong>Engagement tactics</strong>: Weekly circular emails, SMS alerts for flash sales, gamified savings challenges</li>
</ul>
<p><strong>Convenience Seekers</strong> (Example: Infrequent large trips, higher basket values)</p>
<ul>
<li><strong>Behavioral profile</strong>: Less frequent shopping trips but larger basket sizes, moderate spending, may shop for longer periods between visits</li>
<li><strong>Marketing strategy</strong>: Stock-up promotions, bulk sizing options, one-stop shopping convenience</li>
<li><strong>Promotional approach</strong>: Family pack discounts, pantry staple bundles, month-end promotions timed with typical shopping cycles</li>
<li><strong>Engagement tactics</strong>: Shopping list app integration, “don’t forget” reminder campaigns, meal planning resources</li>
</ul>
<p><strong>Light Shoppers</strong> (Example: Low spending, infrequent visits, small baskets)</p>
<ul>
<li><strong>Behavioral profile</strong>: Lower total spending, fewer trips, smaller basket sizes, may be new customers or those supplementing elsewhere</li>
<li><strong>Marketing strategy</strong>: Engagement and frequency-building campaigns, trial incentives for new products</li>
<li><strong>Promotional approach</strong>: Welcome offers, “try me free” campaigns, basket-building incentives (“spend $X, save $Y”), first-time buyer coupons</li>
<li><strong>Engagement tactics</strong>: Category exploration campaigns, meal kit samples, partner with meal delivery apps to capture more wallet share</li>
</ul>
<p><strong>Key Insight</strong>: Notice how these recommendations are grounded in <strong>behavioral patterns</strong> (spending, frequency, discount sensitivity) rather than just demographics. While demographic data helps refine messaging and channel selection, purchasing behavior provides the most actionable insights for grocery retail strategy.</p>
</div>
</div>
</section>
</section>
<section id="summary" class="level2" data-number="31.8">
<h2 data-number="31.8" class="anchored" data-anchor-id="summary"><span class="header-section-number">31.8</span> Summary</h2>
<p>This chapter introduced you to <strong>unsupervised learning</strong> and <strong>clustering</strong>—discovering hidden patterns in data without labeled outcomes. You learned how <strong>K-Means clustering</strong> works by iteratively assigning observations to the nearest centroid and updating centroids to minimize within-cluster variance. Through a comprehensive case study using the Complete Journey grocery retail dataset, you practiced the complete workflow: engineering behavioral features from transaction data, scaling features, selecting k using elbow and silhouette methods (and handling ambiguous results), interpreting cluster profiles, and translating statistical findings into actionable marketing strategies. You also learned that K-Means makes important assumptions (spherical clusters, similar sizes, comparable scales) and explored alternative methods like hierarchical clustering and DBSCAN for when those assumptions don’t hold.</p>
<p>The key insight: <strong>clustering reveals structure by grouping similar observations (rows)</strong>, helping us segment customers, organize documents, or detect patterns. But what if we want to find structure across <strong>features (columns)</strong> instead? In the next chapter, we’ll explore <strong>dimension reduction</strong>—unsupervised techniques that compress many features into fewer dimensions while preserving information, enabling visualization of high-dimensional data and feature engineering for supervised models.</p>
</section>
<section id="end-of-chapter-exercises" class="level2" data-number="31.9">
<h2 data-number="31.9" class="anchored" data-anchor-id="end-of-chapter-exercises"><span class="header-section-number">31.9</span> End of Chapter Exercises</h2>
<p>These exercises build on Chapter 30’s feature engineering skills by applying clustering to discover natural groupings in housing data. You’ll progress from basic numeric clustering to incorporating categorical features, mirroring the complete workflow you learned in this chapter.</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Before You Start
</div>
</div>
<div class="callout-body-container callout-body">
<p>Make sure you have:</p>
<ul>
<li>The <a href="https://github.com/bradleyboehmke/uc-bana-4080/blob/main/data/ames_clean.csv"><code>ames_clean.csv</code></a> dataset loaded into a pandas DataFrame</li>
<li>Imported necessary libraries: <code>pandas</code>, <code>numpy</code>, <code>matplotlib.pyplot</code>, <code>sklearn.cluster.KMeans</code>, <code>sklearn.preprocessing.StandardScaler</code>, <code>sklearn.metrics.silhouette_score</code></li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-28-contents" aria-controls="callout-28" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 1: Clustering Houses with Numeric Features
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-28" class="callout-28-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Objective:</strong> Discover natural groupings in the Ames housing market using only numeric features.</p>
<p><strong>Business Context:</strong> A real estate investment firm wants to segment the Ames housing market to identify distinct property types for their portfolio strategy. They’ll start by analyzing properties based purely on their physical characteristics and financial metrics.</p>
<p><strong>Tasks:</strong></p>
<ol type="1">
<li><p><strong>Load and explore the data:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>ames <span class="op">=</span> pd.read_csv(<span class="st">'../data/ames_clean.csv'</span>)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Select numeric features</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'GrLivArea'</span>, <span class="st">'YearBuilt'</span>, <span class="st">'TotalBsmtSF'</span>, <span class="st">'GarageArea'</span>,</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'OverallQual'</span>, <span class="st">'OverallCond'</span>, <span class="st">'LotArea'</span>, <span class="st">'1stFlrSF'</span>,</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'2ndFlrSF'</span>, <span class="st">'FullBath'</span>, <span class="st">'HalfBath'</span>, <span class="st">'BedroomAbvGr'</span>]</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for missing values</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ames[numeric_features].isnull().<span class="bu">sum</span>())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p><strong>Prepare features for clustering:</strong></p>
<ul>
<li>Handle any missing values (drop rows with missing values or impute with median)</li>
<li>Create a feature matrix <code>X</code> containing only the numeric features listed above</li>
<li>Scale the features using <code>StandardScaler()</code> (fit and transform in one step for now)</li>
<li><strong>Why is scaling essential for K-Means?</strong> Write a comment explaining.</li>
</ul></li>
<li><p><strong>Find the optimal number of clusters:</strong></p>
<ul>
<li>Calculate inertia (within-cluster sum of squares) for k=2 through k=10</li>
<li>Calculate silhouette scores for k=2 through k=10</li>
<li>Create two plots side-by-side: elbow plot (k vs.&nbsp;inertia) and silhouette plot (k vs.&nbsp;silhouette score)</li>
<li>Based on these metrics, what seems like a reasonable number of clusters? Explain your reasoning.</li>
</ul></li>
<li><p><strong>Fit K-Means with your chosen k:</strong></p>
<ul>
<li>Fit a K-Means model with <code>random_state=42</code> for reproducibility</li>
<li>Add cluster labels to your original DataFrame as a new column called <code>Cluster</code></li>
</ul></li>
<li><p><strong>Profile and interpret your clusters:</strong></p>
<ul>
<li>Calculate mean values for each feature by cluster using <code>.groupby('Cluster').mean()</code></li>
<li>Calculate mean <code>SalePrice</code> by cluster (even though price wasn’t used for clustering!)</li>
<li>For each cluster, describe the “typical” house profile:
<ul>
<li>What size is it? (GrLivArea, TotalBsmtSF, GarageArea)</li>
<li>How old or new? (YearBuilt)</li>
<li>What quality level? (OverallQual)</li>
<li>What’s the typical price range?</li>
</ul></li>
<li>Give each cluster a descriptive name (e.g., “Starter Homes,” “Luxury Properties,” “Mid-Century Ranch Homes”)</li>
</ul></li>
<li><p><strong>Visualize your clusters:</strong></p>
<ul>
<li>Create a scatter plot with <code>GrLivArea</code> on x-axis and <code>SalePrice</code> on y-axis</li>
<li>Color points by cluster</li>
<li>Does K-Means successfully separate houses into meaningful groups?</li>
</ul></li>
</ol>
<p><strong>Hints:</strong></p>
<ul>
<li>Missing values in basement-related features often mean “no basement”—imputing with 0 can be appropriate</li>
<li>For the elbow plot, look for the “elbow” where adding more clusters provides diminishing returns</li>
<li>Silhouette scores closer to 1 indicate well-separated, compact clusters</li>
<li>Real estate often has 3-5 natural market segments (starter homes, mid-range, move-up buyers, luxury)</li>
<li>The cluster with highest OverallQual should correlate with highest SalePrice</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-29-contents" aria-controls="callout-29" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 2: Adding Categorical Features to Clustering
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-29" class="callout-29-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Objective:</strong> Enhance your clustering by incorporating categorical features through proper encoding.</p>
<p><strong>Business Context:</strong> The investment firm from Exercise 1 realizes that physical characteristics alone don’t capture everything. Location (neighborhood) and property type might reveal different market segments. They want to see if adding these categorical features uncovers new patterns.</p>
<p><strong>Tasks:</strong></p>
<ol type="1">
<li><strong>Select and encode categorical features:</strong>
<ul>
<li>Start with the numeric features from Exercise 1</li>
<li>Add these categorical features: <code>Neighborhood</code>, <code>BldgType</code>, <code>HouseStyle</code>, <code>CentralAir</code></li>
<li>Encode the categorical features using an appropriate method:
<ul>
<li><strong>Option A:</strong> One-hot encoding with <code>pd.get_dummies()</code> (recommended for nominal categories)</li>
<li><strong>Option B:</strong> Ordinal encoding if you can justify a meaningful order</li>
</ul></li>
<li><strong>Combine</strong> your numeric features with your encoded categorical features into a single feature matrix</li>
</ul></li>
<li><strong>Scale all features:</strong>
<ul>
<li>Remember: One-hot encoded features (0s and 1s) should generally still be scaled when combined with continuous features</li>
<li>Apply <code>StandardScaler()</code> to your complete feature matrix</li>
<li>How many total features do you have now after encoding and combining?</li>
</ul></li>
<li><strong>Repeat the cluster analysis:</strong>
<ul>
<li>Perform elbow method and silhouette analysis for k=2 through k=10</li>
<li>Compare these plots to your results from Exercise 1:
<ul>
<li>Did the optimal k change?</li>
<li>Did the silhouette scores improve or worsen?</li>
</ul></li>
<li>Choose your optimal k (can be same or different from Exercise 1)</li>
</ul></li>
<li><strong>Fit K-Means and profile clusters:</strong>
<ul>
<li>Fit K-Means with your chosen k</li>
<li>Add cluster labels as <code>Cluster_WithCategorical</code> to distinguish from Exercise 1</li>
<li>Create cluster profiles showing:
<ul>
<li>Average numeric features (GrLivArea, YearBuilt, OverallQual, etc.)</li>
<li>Most common categorical values per cluster (use <code>.mode()</code> or counts)</li>
<li>Average SalePrice per cluster</li>
</ul></li>
</ul></li>
<li><strong>Compare to Exercise 1:</strong>
<ul>
<li>Create a crosstab: <code>pd.crosstab(ames['Cluster'], ames['Cluster_WithCategorical'])</code></li>
<li>How much do the cluster assignments differ?</li>
<li>Which clustering approach (numeric-only vs.&nbsp;numeric + categorical) gives more interpretable, actionable segments?</li>
<li>Give descriptive names to your new clusters</li>
</ul></li>
<li><strong>Visualize the impact of categorical features:</strong>
<ul>
<li>Create a scatter plot colored by your new clusters</li>
<li>Consider using <code>GrLivArea</code> vs <code>SalePrice</code> again, or try <code>OverallQual</code> vs <code>SalePrice</code></li>
<li>Optionally: Color by cluster and use marker shapes to show <code>BldgType</code> or another categorical feature</li>
<li>Can you see how neighborhoods or building types now influence cluster assignments?</li>
</ul></li>
</ol>
<p><strong>Challenge Tasks:</strong></p>
<ul>
<li><strong>Neighborhood-specific insights:</strong> For each cluster, identify which neighborhoods are overrepresented. This helps with targeted marketing by location.</li>
<li><strong>Feature importance:</strong> Which features seem to drive cluster separation most? Compare cluster centroids to identify the largest differences.</li>
<li><strong>Alternative encoding:</strong> Try target encoding for <code>Neighborhood</code> (encoding it as the mean SalePrice in that neighborhood). Does this improve cluster interpretability? (Warning: This can introduce data leakage if not done carefully in production pipelines!)</li>
</ul>
<p><strong>Hints:</strong></p>
<ul>
<li><code>pd.get_dummies(ames, columns=['Neighborhood', 'BldgType'])</code> creates dummy variables for specified columns</li>
<li>After one-hot encoding Neighborhood, you might have 20+ new binary features</li>
<li>Use <code>.value_counts()</code> within each cluster to see which neighborhoods or building types dominate</li>
<li>If silhouette scores drop after adding categorical features, it might mean the categories don’t define clear boundaries—that’s okay and realistic!</li>
<li>For interpretation, focus on clusters that are <em>both</em> statistically distinct AND business-interpretable</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-30-contents" aria-controls="callout-30" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 3: Complete Clustering Pipeline (Challenge)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-30" class="callout-30-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Objective:</strong> Build a production-ready, reusable clustering pipeline that handles preprocessing automatically.</p>
<p><strong>Context:</strong> Your real estate firm wants to deploy your clustering analysis as a repeatable workflow they can run monthly as new listings appear. Build a pipeline that ensures consistent preprocessing and clustering.</p>
<p><strong>Tasks:</strong></p>
<ol type="1">
<li><strong>Design your pipeline structure:</strong>
<ul>
<li>Separate features into numerical and categorical lists</li>
<li>Create a numerical preprocessing pipeline: Imputation (median) → StandardScaler</li>
<li>Create a categorical preprocessing pipeline: Imputation (constant=‘missing’) → OneHotEncoder</li>
<li>Use <code>ColumnTransformer</code> to apply the appropriate pipeline to each feature type</li>
</ul></li>
<li><strong>Build the complete pipeline:</strong>
<ul>
<li><p>Combine your preprocessing with K-Means clustering</p></li>
<li><p>Your pipeline should look like:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define feature lists</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'GrLivArea'</span>, <span class="st">'YearBuilt'</span>, ...]</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>categorical_features <span class="op">=</span> [<span class="st">'Neighborhood'</span>, <span class="st">'BldgType'</span>, ...]</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create preprocessing pipelines</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>numeric_transformer <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'imputer'</span>, SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>)),</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'scaler'</span>, StandardScaler())</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>categorical_transformer <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'imputer'</span>, SimpleImputer(strategy<span class="op">=</span><span class="st">'constant'</span>, fill_value<span class="op">=</span><span class="st">'missing'</span>)),</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'onehot'</span>, OneHotEncoder(handle_unknown<span class="op">=</span><span class="st">'ignore'</span>, sparse_output<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine preprocessing</span></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> ColumnTransformer(</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    transformers<span class="op">=</span>[</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'num'</span>, numeric_transformer, numeric_features),</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'cat'</span>, categorical_transformer, categorical_features)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Complete clustering pipeline</span></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>clustering_pipeline <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'clusterer'</span>, KMeans(n_clusters<span class="op">=</span>YOUR_OPTIMAL_K, random_state<span class="op">=</span><span class="dv">42</span>))</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
</ul></li>
<li><strong>Fit and predict with your pipeline:</strong>
<ul>
<li>Fit the pipeline on the Ames data: <code>clustering_pipeline.fit(X)</code></li>
<li>Get cluster labels: <code>labels = clustering_pipeline.named_steps['clusterer'].labels_</code></li>
<li>Add labels to your DataFrame</li>
</ul></li>
<li><strong>Validate your pipeline:</strong>
<ul>
<li>Create a small holdout sample of 10 houses from your data</li>
<li>Use your fitted pipeline to predict clusters for these houses: <code>clustering_pipeline.predict(X_holdout)</code></li>
<li>Verify that preprocessing happens automatically (no manual scaling needed!)</li>
</ul></li>
<li><strong>Profile clusters from your pipeline:</strong>
<ul>
<li>Extract cluster centroids from your fitted K-Means model</li>
<li>Remember: The centroids are in the transformed (scaled, encoded) feature space</li>
<li>Create interpretable profiles by grouping the original data by cluster labels</li>
<li>Compare: Are the results identical to your manual approach from Exercise 2?</li>
</ul></li>
</ol>
<p><strong>Challenge Extensions:</strong></p>
<ul>
<li><strong>Custom transformer:</strong> Create a <code>FunctionTransformer</code> that engineers new features (like <code>HouseAge = current_year - YearBuilt</code>) before preprocessing. Insert it at the start of your pipeline.</li>
<li><strong>Grid search for optimal k:</strong> Use <code>GridSearchCV</code> or loop through k values, fitting the pipeline for each, to automate finding optimal k.</li>
<li><strong>Save your pipeline:</strong> Use <code>joblib</code> to save your fitted pipeline to disk so it can be loaded and used later without refitting.</li>
</ul>
<p><strong>Hints:</strong></p>
<ul>
<li>Pipelines prevent data leakage by ensuring transformations are fit on training data only</li>
<li>Access fitted pipeline components with <code>.named_steps['step_name']</code></li>
<li>The clusterer’s <code>.labels_</code> attribute gives cluster assignments for the training data</li>
<li>Use <code>.predict()</code> on the pipeline for new data (it applies all transformations automatically)</li>
</ul>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./30-feature-engineering.html" class="pagination-link" aria-label="Feature Engineering">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Feature Engineering</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./32-dimension-reduction.html" class="pagination-link" aria-label="Dimension Reduction with PCA">
        <span class="nav-page-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Dimension Reduction with PCA</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/edit/main/31-clustering.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>