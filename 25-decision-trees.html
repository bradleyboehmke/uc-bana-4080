<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>25&nbsp; Decision Trees: Foundations and Interpretability – BANA 4080: Data Mining</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./26-random-forests.html" rel="next">
<link href="./24-classification-evaluation.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-5d254f1e278c2921d96b26102a150bb1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-530b29c22fe67fc61ace1451aaa50055.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-5d254f1e278c2921d96b26102a150bb1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-45c1b2e5a2b0567ccfb99e4dfc03f650.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-54ba87e1857bbaa32a381632a2aab8bf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-45c1b2e5a2b0567ccfb99e4dfc03f650.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="mermaid-theme" content="neutral">
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./25-decision-trees.html">Module 10</a></li><li class="breadcrumb-item"><a href="./25-decision-trees.html"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Decision Trees: Foundations and Interpretability</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">BANA 4080: Data Mining</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/bradleyboehmke/uc-bana-4080" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./BANA-4080--Data-Mining.epub" title="Download ePub" class="quarto-navigation-tool px-1" aria-label="Download ePub"><i class="bi bi-journal"></i></a>
    <a href="https://twitter.com/intent/tweet?url=|url|" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro-data-mining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-preparing-for-code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Setting Up Your Python Environment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-python-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python Basics – Working with Data and Variables</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 2</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-jupyter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Getting Started with Jupyter Notebooks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-data-structures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Data Structures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-libraries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Packages, Libraries, and Modules</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-importing-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Importing Data and Exploring Pandas DataFrames</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-dataframes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Deeper Dive on DataFrames</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-subsetting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Subsetting Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 4</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-manipulating-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Manipulating Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_aggregating_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Summarizing Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-joining-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Relational data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 5</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-data-viz-pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Intro to Data Visualization with Pandas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-data-viz-matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Fundamentals of Plotting with Matplotlib</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-data-viz-bokeh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Interactive Data Visualization with Bokeh</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 6</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-control-statements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Controlling Program Flow with Conditional Statements</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-iteration-statements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Controlling Repetition with Iteration Statements</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Writing Your Own Functions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 7</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-intro-ml-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Introduction to Machine Learning and Artificial Intelligence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-before-we-build.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Before You Build: Key Considerations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 8</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-correlation-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Correlation and Linear Regression Foundations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-regression-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Evaluating Regression Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 9</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Introduction to Logistic Regression for Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-classification-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Evaluating Classification Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 10</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-decision-trees.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Decision Trees: Foundations and Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26-random-forests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Random Forests: Ensemble Power and Robustness</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./27-feature-importance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Understanding Feature Importance: Peeking Inside the Black Box</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 11</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./28-cross-validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Cross-validation: Reliable model evaluation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./29-hyperparameter-tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning: Finding Optimal Model Configurations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30-feature-engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Feature Engineering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99-anaconda-install.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Anaconda Installation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99-vscode-install.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">VS Code Installation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#when-linear-methods-hit-their-limits" id="toc-when-linear-methods-hit-their-limits" class="nav-link active" data-scroll-target="#when-linear-methods-hit-their-limits"><span class="header-section-number">25.1</span> When Linear Methods Hit Their Limits</a>
  <ul class="collapse">
  <li><a href="#where-linear-methods-struggle" id="toc-where-linear-methods-struggle" class="nav-link" data-scroll-target="#where-linear-methods-struggle">Where Linear Methods Struggle</a></li>
  <li><a href="#where-decision-trees-excel" id="toc-where-decision-trees-excel" class="nav-link" data-scroll-target="#where-decision-trees-excel">Where Decision Trees Excel</a></li>
  </ul></li>
  <li><a href="#how-decision-trees-think" id="toc-how-decision-trees-think" class="nav-link" data-scroll-target="#how-decision-trees-think"><span class="header-section-number">25.2</span> How Decision Trees Think</a>
  <ul class="collapse">
  <li><a href="#the-decision-making-process" id="toc-the-decision-making-process" class="nav-link" data-scroll-target="#the-decision-making-process">The Decision-Making Process</a></li>
  <li><a href="#tree-anatomy-nodes-splits-and-leaves" id="toc-tree-anatomy-nodes-splits-and-leaves" class="nav-link" data-scroll-target="#tree-anatomy-nodes-splits-and-leaves">Tree Anatomy: Nodes, Splits, and Leaves</a></li>
  <li><a href="#lets-see-this-in-action" id="toc-lets-see-this-in-action" class="nav-link" data-scroll-target="#lets-see-this-in-action">Let’s See This in Action</a></li>
  <li><a href="#understanding-how-cart-trees-make-decisions" id="toc-understanding-how-cart-trees-make-decisions" class="nav-link" data-scroll-target="#understanding-how-cart-trees-make-decisions">Understanding How CART Trees Make Decisions</a></li>
  <li><a href="#how-cart-handles-multiple-variables" id="toc-how-cart-handles-multiple-variables" class="nav-link" data-scroll-target="#how-cart-handles-multiple-variables">How CART Handles Multiple Variables</a></li>
  <li><a href="#reading-through-the-two-variable-tree" id="toc-reading-through-the-two-variable-tree" class="nav-link" data-scroll-target="#reading-through-the-two-variable-tree">Reading Through the Two-Variable Tree</a></li>
  </ul></li>
  <li><a href="#building-your-first-decision-tree" id="toc-building-your-first-decision-tree" class="nav-link" data-scroll-target="#building-your-first-decision-tree"><span class="header-section-number">25.3</span> Building Your First Decision Tree</a>
  <ul class="collapse">
  <li><a href="#classification-trees" id="toc-classification-trees" class="nav-link" data-scroll-target="#classification-trees">Classification Trees</a></li>
  <li><a href="#regression-trees" id="toc-regression-trees" class="nav-link" data-scroll-target="#regression-trees">Regression Trees</a></li>
  <li><a href="#tree-parameters-and-overfitting" id="toc-tree-parameters-and-overfitting" class="nav-link" data-scroll-target="#tree-parameters-and-overfitting">Tree Parameters and Overfitting</a></li>
  </ul></li>
  <li><a href="#when-to-use-decision-trees" id="toc-when-to-use-decision-trees" class="nav-link" data-scroll-target="#when-to-use-decision-trees"><span class="header-section-number">25.4</span> When to Use Decision Trees</a>
  <ul class="collapse">
  <li><a href="#advantages-over-linear-models" id="toc-advantages-over-linear-models" class="nav-link" data-scroll-target="#advantages-over-linear-models">Advantages Over Linear Models</a></li>
  <li><a href="#limitations-to-consider" id="toc-limitations-to-consider" class="nav-link" data-scroll-target="#limitations-to-consider">Limitations to Consider</a></li>
  <li><a href="#business-scenarios-where-trees-excel" id="toc-business-scenarios-where-trees-excel" class="nav-link" data-scroll-target="#business-scenarios-where-trees-excel">Business Scenarios Where Trees Excel</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">25.5</span> Summary</a></li>
  <li><a href="#end-of-chapter-exercise" id="toc-end-of-chapter-exercise" class="nav-link" data-scroll-target="#end-of-chapter-exercise"><span class="header-section-number">25.6</span> End of Chapter Exercise</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/edit/main/25-decision-trees.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./25-decision-trees.html">Module 10</a></li><li class="breadcrumb-item"><a href="./25-decision-trees.html"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Decision Trees: Foundations and Interpretability</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Decision Trees: Foundations and Interpretability</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>After mastering linear and logistic regression, you might think these methods can handle any business problem. However, many real-world relationships don’t follow the straight-line assumptions that linear methods require. Consider these challenging business scenarios:</p>
<ul>
<li><em>A customer’s spending doesn’t increase steadily with income—wealthy customers might become price-conscious while middle-income customers splurge on certain categories</em></li>
<li><em>Marketing response isn’t linear—ads might need to reach a minimum frequency before they work, then plateau at high levels</em></li>
<li><em>Risk doesn’t increase smoothly—loan defaults might jump suddenly at certain credit score thresholds</em></li>
<li><em>Complex interactions matter—“high income AND young age” behaves very differently than either factor alone</em></li>
</ul>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Experiential Learning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Think about a decision you make regularly that involves multiple factors, but where you don’t apply the same “weight” to each factor in every situation. Maybe you choose restaurants differently when you’re with family versus friends, or you evaluate job candidates differently based on the specific role requirements.</p>
<p>Write down one such decision where your process changes based on context. How do your decision rules shift? Do you have explicit thresholds like “If it’s a family dinner AND price is above $50, then look for kid-friendly options”? By the end of this chapter, you’ll understand how decision trees can capture this type of context-dependent decision-making that linear models struggle with.</p>
</div>
</div>
<p>This chapter introduces <strong>decision trees</strong>, algorithms designed specifically to handle the limitations of linear methods. Unlike regression models that assume relationships are linear and consistent across all observations, decision trees automatically discover non-linear patterns, complex interactions, and context-dependent rules that mirror how humans actually make decisions.</p>
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li>Explain how decision trees make predictions through recursive splitting and yes/no questions</li>
<li>Understand the CART algorithm and how it uses Gini impurity (classification) and SSE (regression) to find optimal splits</li>
<li>Build both classification and regression trees using scikit-learn’s <code>DecisionTreeClassifier</code> and <code>DecisionTreeRegressor</code></li>
<li>Control tree complexity and prevent overfitting using parameters like <code>max_depth</code>, <code>min_samples_split</code>, and <code>min_samples_leaf</code></li>
<li>Recognize when decision trees are preferable to linear models based on data characteristics and business requirements</li>
<li>Apply decision trees to business problems requiring transparency and interpretability</li>
</ul>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>📓 Follow Along in Colab!
</div>
</div>
<div class="callout-body-container callout-body">
<p>As you read through this chapter, we encourage you to follow along using the <a href="https://github.com/bradleyboehmke/uc-bana-4080/blob/main/example-notebooks/25_decision_trees.ipynb">companion notebook</a> in Google Colab (or another editor of your choice). This interactive notebook lets you run all the code examples covered here—and experiment with your own ideas.</p>
<p>👉 Open the <a href="https://colab.research.google.com/github/bradleyboehmke/uc-bana-4080/blob/main/example-notebooks/25_decision_trees.ipynb">Decision Trees Notebook in Colab</a>.</p>
</div>
</div>
<section id="when-linear-methods-hit-their-limits" class="level2" data-number="25.1">
<h2 data-number="25.1" class="anchored" data-anchor-id="when-linear-methods-hit-their-limits"><span class="header-section-number">25.1</span> When Linear Methods Hit Their Limits</h2>
<p>You’ve built solid foundations with linear and logistic regression, but these methods make strong assumptions that don’t always match business reality. Understanding these limitations helps you recognize when decision trees (and later, more advanced methods) become necessary.</p>
<section id="where-linear-methods-struggle" class="level3">
<h3 class="anchored" data-anchor-id="where-linear-methods-struggle">Where Linear Methods Struggle</h3>
<p>Understanding why linear methods fall short helps you recognize when more sophisticated approaches like decision trees become necessary. Let’s explore these limitations with concrete examples that demonstrate how real business relationships often violate linear assumptions.</p>
<p><strong>1. Non-linear Relationships</strong>: Linear models assume that changes in predictors have consistent effects across their entire range. But real business relationships often involve complex curves, thresholds, and saturation points.</p>
<div id="01ccd361" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show code for non-linear relationship examples</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrate non-linear relationships that linear models can't capture</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Example 1: Diminishing Returns - Marketing Spend vs Sales</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>marketing_spend <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">100</span>, <span class="dv">150</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Sales show diminishing returns - big gains early, then plateau</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>sales <span class="op">=</span> <span class="dv">50</span> <span class="op">+</span> <span class="dv">40</span> <span class="op">*</span> np.sqrt(marketing_spend) <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="dv">8</span>, <span class="bu">len</span>(marketing_spend))</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>sales <span class="op">=</span> np.clip(sales, <span class="dv">0</span>, <span class="va">None</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>linear_model1 <span class="op">=</span> LinearRegression()</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>X_marketing <span class="op">=</span> marketing_spend.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>linear_model1.fit(X_marketing, sales)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>linear_pred1 <span class="op">=</span> linear_model1.predict(X_marketing)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>plt.scatter(marketing_spend, sales, alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span><span class="st">'steelblue'</span>, s<span class="op">=</span><span class="dv">25</span>, label<span class="op">=</span><span class="st">'Actual Sales'</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>plt.plot(marketing_spend, linear_pred1, color<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Linear Model'</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Marketing Spend ($000s)'</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Sales ($000s)'</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Diminishing Returns Pattern'</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Example 2: Threshold Effect - Experience vs Performance</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>experience_years <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dv">150</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Performance jumps after certain experience levels</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>performance <span class="op">=</span> np.where(</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    experience_years <span class="op">&lt;</span> <span class="dv">2</span>, <span class="dv">60</span> <span class="op">+</span> experience_years <span class="op">*</span> <span class="dv">5</span>,  <span class="co"># Slow start</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    np.where(</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        experience_years <span class="op">&lt;</span> <span class="dv">8</span>, <span class="dv">70</span> <span class="op">+</span> (experience_years <span class="op">-</span> <span class="dv">2</span>) <span class="op">*</span> <span class="dv">15</span>,  <span class="co"># Rapid improvement</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        <span class="dv">160</span> <span class="op">+</span> (experience_years <span class="op">-</span> <span class="dv">8</span>) <span class="op">*</span> <span class="dv">2</span>  <span class="co"># Gradual improvement</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>) <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="dv">5</span>, <span class="bu">len</span>(experience_years))</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>linear_model2 <span class="op">=</span> LinearRegression()</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>X_experience <span class="op">=</span> experience_years.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>linear_model2.fit(X_experience, performance)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>linear_pred2 <span class="op">=</span> linear_model2.predict(X_experience)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>plt.scatter(experience_years, performance, alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span><span class="st">'darkgreen'</span>, s<span class="op">=</span><span class="dv">25</span>, label<span class="op">=</span><span class="st">'Actual Performance'</span>)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>plt.plot(experience_years, linear_pred2, color<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Linear Model'</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Years of Experience'</span>)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Performance Score'</span>)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Threshold Effects Pattern'</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="25-decision-trees_files/figure-html/cell-2-output-1.png" width="854" height="374" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>These examples reveal critical business patterns that linear models consistently miss:</p>
<ul>
<li><strong>Diminishing returns</strong> (left plot): Marketing spend shows dramatic early gains that plateau over time, but linear models assume constant returns throughout</li>
<li><strong>Threshold effects</strong> (right plot): Employee performance jumps occur at specific experience milestones—junior employees improve slowly, then accelerate rapidly between years 2-8, then plateau again</li>
<li><strong>Non-linear optimization</strong>: Linear models would suggest unlimited marketing spend or that all experience years are equally valuable, leading to poor resource allocation decisions</li>
</ul>
<p><strong>2. Complex Interactions</strong>: Linear models require you to manually specify interactions (like creating age × income features). But in real business data, the most important interactions often involve multiple variables and aren’t obvious upfront.</p>
<div id="ff827ca0" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show code for complex interaction example</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrate complex interactions: Product pricing strategy</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>n_products <span class="op">=</span> <span class="dv">400</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate product data</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>product_quality <span class="op">=</span> np.random.uniform(<span class="dv">1</span>, <span class="dv">10</span>, n_products)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>brand_reputation <span class="op">=</span> np.random.choice([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], n_products, p<span class="op">=</span>[<span class="fl">0.4</span>, <span class="fl">0.4</span>, <span class="fl">0.2</span>])  <span class="co"># 1=unknown, 2=known, 3=premium</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>market_competition <span class="op">=</span> np.random.uniform(<span class="dv">1</span>, <span class="dv">5</span>, n_products)  <span class="co"># 1=low competition, 5=high competition</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Complex interaction: pricing strategy depends on quality AND brand AND competition</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># High quality + premium brand + low competition = premium pricing</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># High quality + unknown brand + high competition = competitive pricing</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># The effect of quality depends entirely on brand and competition context</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>pricing_multiplier <span class="op">=</span> np.where(</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    (product_quality <span class="op">&gt;</span> <span class="dv">7</span>) <span class="op">&amp;</span> (brand_reputation <span class="op">==</span> <span class="dv">3</span>) <span class="op">&amp;</span> (market_competition <span class="op">&lt;</span> <span class="fl">2.5</span>),</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="fl">2.5</span> <span class="op">+</span> product_quality <span class="op">*</span> <span class="fl">0.3</span>,  <span class="co"># Premium pricing strategy</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    np.where(</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        (product_quality <span class="op">&gt;</span> <span class="dv">7</span>) <span class="op">&amp;</span> (brand_reputation <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (market_competition <span class="op">&gt;</span> <span class="fl">3.5</span>),</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        <span class="fl">0.8</span> <span class="op">+</span> product_quality <span class="op">*</span> <span class="fl">0.1</span>,  <span class="co"># Competitive pricing strategy</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="fl">1.0</span> <span class="op">+</span> product_quality <span class="op">*</span> <span class="fl">0.15</span>  <span class="co"># Standard pricing</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate final prices with some noise</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>base_cost <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>price <span class="op">=</span> base_cost <span class="op">*</span> pricing_multiplier <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="dv">10</span>, n_products)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>price <span class="op">=</span> np.clip(price, <span class="dv">30</span>, <span class="dv">300</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization showing the interaction</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: Quality vs Price by Brand (shows interaction)</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'red'</span>, <span class="st">'orange'</span>, <span class="st">'blue'</span>]</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>brand_names <span class="op">=</span> [<span class="st">'Unknown'</span>, <span class="st">'Known'</span>, <span class="st">'Premium'</span>]</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, brand <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]):</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> brand_reputation <span class="op">==</span> brand</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    plt.scatter(product_quality[mask], price[mask],</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>               alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span>colors[i], s<span class="op">=</span><span class="dv">30</span>, label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>brand_names[i]<span class="sc">}</span><span class="ss"> Brand'</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Product Quality (1-10)'</span>)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Price ($)'</span>)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Quality-Price Relationship by Brand'</span>)</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 2: Same quality, different contexts = different prices</span></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Focus on high-quality products (quality &gt; 7) to show interaction effect</span></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>high_quality <span class="op">=</span> product_quality <span class="op">&gt;</span> <span class="dv">7</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>premium_brand_low_comp <span class="op">=</span> (brand_reputation <span class="op">==</span> <span class="dv">3</span>) <span class="op">&amp;</span> (market_competition <span class="op">&lt;</span> <span class="fl">2.5</span>) <span class="op">&amp;</span> high_quality</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>unknown_brand_high_comp <span class="op">=</span> (brand_reputation <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (market_competition <span class="op">&gt;</span> <span class="fl">3.5</span>) <span class="op">&amp;</span> high_quality</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>plt.scatter(market_competition[premium_brand_low_comp], price[premium_brand_low_comp],</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>           alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'blue'</span>, s<span class="op">=</span><span class="dv">40</span>, label<span class="op">=</span><span class="st">'Premium Brand + High Quality'</span>)</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>plt.scatter(market_competition[unknown_brand_high_comp], price[unknown_brand_high_comp],</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>           alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">40</span>, label<span class="op">=</span><span class="st">'Unknown Brand + High Quality'</span>)</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Market Competition (1-5)'</span>)</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Price ($)'</span>)</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Same Quality, Different Pricing Strategy'</span>)</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="25-decision-trees_files/figure-html/cell-3-output-1.png" width="854" height="374" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The pricing example reveals how business interactions work in practice. In the left plot, notice how the relationship between quality and price completely changes depending on brand reputation - premium brands can charge much more for the same quality level. The right plot shows an even more striking interaction: products with identical high quality end up with dramatically different prices depending on the competitive context and brand positioning.</p>
<p>This demonstrates why linear models often miss the mark in business contexts:</p>
<ul>
<li><strong>Context-dependent relationships</strong>: The value of “high quality” depends entirely on brand reputation and competitive environment</li>
<li><strong>Segment-specific strategies</strong>: Premium brands follow completely different pricing rules than unknown brands</li>
<li><strong>Multi-way interactions</strong>: Success requires understanding how quality AND brand AND competition work together, not just their individual effects and this is very difficult for linear models to capture.</li>
</ul>
<p><strong>3. Mixed Data Types</strong>: Linear models require extensive preprocessing for categorical variables, often losing important information in the process:</p>
<ul>
<li><strong>Dummy encoding explosion</strong>: A categorical variable with 20 categories becomes 19 binary columns with sparse data</li>
<li><strong>Lost ordinal relationships</strong>: Converting “Low/Medium/High” to binary variables loses the natural ordering</li>
<li><strong>Production brittleness</strong>: New categories in live data can break existing dummy encoding schemes</li>
</ul>
<p><strong>4. Rule Generation</strong>: Linear coefficients don’t easily translate to actionable business rules that stakeholders can understand and implement:</p>
<ul>
<li><strong>Mathematical abstractions</strong>: “Increase marketing coefficient by 0.003” isn’t as useful as “If customer age &gt; 45 AND income &gt; $75k, then offer premium products”</li>
<li><strong>Stakeholder communication</strong>: Business leaders want clear decision criteria, not mathematical equations</li>
<li><strong>Implementation challenges</strong>: Complex linear combinations are harder to operationalize than simple if-then rules</li>
</ul>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Why Linear Models Struggle in Business
</div>
</div>
<div class="callout-body-container callout-body">
<p>Linear models make strong assumptions that rarely hold in real business environments: they assume relationships are straight lines, effects are consistent across all data ranges, and interactions must be manually specified. Business data typically exhibits non-linear patterns like diminishing returns, threshold effects, and complex multi-way interactions that change based on context.</p>
<p>Non-linear models like decision trees offer a more flexible approach by automatically discovering these complex patterns without requiring you to specify them upfront. Instead of forcing data into linear relationships, trees adapt to the natural structure of business data—making them particularly valuable when relationships are complex and stakeholder interpretability matters.</p>
</div>
</div>
</section>
<section id="where-decision-trees-excel" class="level3">
<h3 class="anchored" data-anchor-id="where-decision-trees-excel">Where Decision Trees Excel</h3>
<p>While linear methods struggle with the complexities we’ve just described, decision trees are designed specifically to handle these challenges. Think of decision trees as the business world’s natural problem-solving approach—breaking complex decisions into a series of simple yes/no questions. Here are the key advantages that make trees particularly powerful for business applications:</p>
<ul>
<li><strong>Automatic Threshold Detection</strong>: Trees find meaningful cut-points in your data without you having to specify them.</li>
<li><strong>Natural Interaction Modeling</strong>: Trees automatically create different rules for different subgroups, capturing complex interactions.</li>
<li><strong>Mixed Data Handling</strong>: Trees can conceptually handle numeric, categorical, and ordinal data (though sklearn requires encoding).</li>
<li><strong>Business-Friendly Output</strong>: Trees generate interpretable “if-then” rules that translate directly into business processes.</li>
<li><strong>No Distribution Assumptions</strong>: Trees don’t assume your data follows any particular statistical distribution.</li>
</ul>
<p>Beyond these individual strengths, decision trees excel because they mirror how humans naturally make complex decisions in business contexts. When evaluating loan applications, hiring candidates, or diagnosing problems, we instinctively break down complex situations into a series of simpler questions. Decision trees formalize this intuitive approach, making them both powerful and understandable.</p>
<p>Consider how a seasoned sales manager evaluates leads: they might first ask “Is the company budget above $100K?” Then, depending on the answer, ask different follow-up questions. High-budget prospects get questions about decision timeline and authority, while lower-budget prospects get questions about growth potential and pain points. This context-dependent questioning is exactly how decision trees operate—automatically learning the most informative questions and when to ask them.</p>
<div class="cell" data-fig-width="4" data-fig-height="4" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[Sales Lead] --&gt; B{"Budget above 100K?"}
    B --&gt;|Yes| C{"Timeline under 6 months?"}
    B --&gt;|No| D{"High Growth Potential?"}
    C --&gt;|Yes| E{"Decision Maker Access?"}
    C --&gt;|No| F[Nurture Lead]
    D --&gt;|Yes| G{"Significant Pain Points?"}
    D --&gt;|No| H[Low Priority]
    E --&gt;|Yes| I[High Priority Prospect]
    E --&gt;|No| J[Identify Decision Maker]
    G --&gt;|Yes| K[Medium Priority Prospect]
    G --&gt;|No| L[Monitor for Changes]

    style A fill:#e1f5fe
    style I fill:#c8e6c9
    style K fill:#fff3c4
    style F fill:#ffcdd2
    style H fill:#ffcdd2
    style J fill:#fff3c4
    style L fill:#ffcdd2
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The combination of these advantages makes decision trees particularly valuable in business environments where both accuracy and interpretability matter. Unlike black-box algorithms that provide predictions without explanations, trees offer a clear audit trail from input features to final decisions.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Decision Tree Advantages Summary
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Flexibility</strong>: Automatically handle non-linear relationships, complex interactions, and mixed data types without manual specification</li>
<li><strong>Interpretability</strong>: Generate clear if-then rules that stakeholders can understand, verify, and implement in business processes</li>
<li><strong>Robustness</strong>: Work with imperfect data (missing values, outliers) and make no assumptions about underlying distributions</li>
<li><strong>Business Alignment</strong>: Mirror natural human decision-making processes, making them intuitive for domain experts to evaluate and trust</li>
</ul>
</div>
</div>
</section>
</section>
<section id="how-decision-trees-think" class="level2" data-number="25.2">
<h2 data-number="25.2" class="anchored" data-anchor-id="how-decision-trees-think"><span class="header-section-number">25.2</span> How Decision Trees Think</h2>
<p><strong>Decision trees</strong> work by learning a series of yes/no questions that best separate the data into meaningful groups. Each question splits the data based on a single feature, creating a tree-like structure where each internal node represents a question, each branch represents an answer, and each leaf represents a final prediction.</p>
<section id="the-decision-making-process" class="level3">
<h3 class="anchored" data-anchor-id="the-decision-making-process">The Decision-Making Process</h3>
<p>Imagine you’re a loan officer deciding whether to approve credit applications. You might naturally think through questions like:</p>
<ol type="1">
<li>“Is the applicant’s income above $50,000?”</li>
<li>If yes: “Is their credit score above 700?”</li>
<li>If no: “Do they have a co-signer?”</li>
</ol>
<div class="cell" data-fig-width="3" data-fig-height="4" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[Loan Application] --&gt; B{"Income above 50K?"}
    B --&gt;|Yes| C{"Credit Score above 700?"}
    B --&gt;|No| D{"Has Co-signer?"}
    C --&gt;|Yes| E[Approve Loan]
    C --&gt;|No| F[Review Additional Factors]
    D --&gt;|Yes| G[Consider Approval]
    D --&gt;|No| H[Deny Loan]

    style A fill:#e1f5fe
    style E fill:#c8e6c9
    style G fill:#fff3c4
    style F fill:#fff3c4
    style H fill:#ffcdd2
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This sequential questioning process is exactly how decision trees operate, but they learn the optimal questions and thresholds automatically from data.</p>
</section>
<section id="tree-anatomy-nodes-splits-and-leaves" class="level3">
<h3 class="anchored" data-anchor-id="tree-anatomy-nodes-splits-and-leaves">Tree Anatomy: Nodes, Splits, and Leaves</h3>
<p>Before we build our first tree, let’s understand the key components:</p>
<ul>
<li><strong>Root Node</strong>: The starting point where all data begins</li>
<li><strong>Internal Nodes</strong>: Decision points that ask yes/no questions</li>
<li><strong>Branches</strong>: Paths representing answers to questions</li>
<li><strong>Leaf Nodes</strong>: Final destinations that provide predictions</li>
<li><strong>Depth</strong>: How many questions deep the tree goes</li>
</ul>
<div class="cell" data-fig-width="6" data-fig-height="5" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A["🏠 ROOT NODE&lt;br/&gt;All Data Starts Here"] --&gt; B{"🔀 INTERNAL NODE&lt;br/&gt;Question 1"}
    B --&gt;|"📈 BRANCH&lt;br/&gt;(Yes)"| C{"🔀 INTERNAL NODE&lt;br/&gt;Question 2A"}
    B --&gt;|"📉 BRANCH&lt;br/&gt;(No)"| D{"🔀 INTERNAL NODE&lt;br/&gt;Question 2B"}
    C --&gt;|"📈 BRANCH&lt;br/&gt;(Yes)"| E["🎯 LEAF NODE&lt;br/&gt;Prediction A"]
    C --&gt;|"📉 BRANCH&lt;br/&gt;(No)"| F["🎯 LEAF NODE&lt;br/&gt;Prediction B"]
    D --&gt;|"📈 BRANCH&lt;br/&gt;(Yes)"| G["🎯 LEAF NODE&lt;br/&gt;Prediction C"]
    D --&gt;|"📉 BRANCH&lt;br/&gt;(No)"| H["🎯 LEAF NODE&lt;br/&gt;Prediction D"]

    %% Depth indicators
    I["📏 DEPTH = 3&lt;br/&gt;(3 levels of questions)"]

    %% Styling
    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style B fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style C fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style D fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style E fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style F fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style G fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style H fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style I fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="lets-see-this-in-action" class="level3">
<h3 class="anchored" data-anchor-id="lets-see-this-in-action">Let’s See This in Action</h3>
<p>To understand how decision trees work, let’s start simple and build up complexity. We’ll begin with a tree that uses just one variable, then expand to show how multiple variables work together.</p>
<section id="example-1-single-variable-decision-tree" class="level4">
<h4 class="anchored" data-anchor-id="example-1-single-variable-decision-tree">Example 1: Single-Variable Decision Tree</h4>
<p>Let’s start with the simplest possible case—predicting loan approval based solely on income. We’ll create a synthetic dataset that mimics realistic loan approval patterns, where higher incomes generally lead to higher approval rates, but with some natural variation to reflect real-world complexity:</p>
<div id="316127a2" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show code for simple one-variable example</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create simple loan approval dataset with one variable</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate simple income data</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>income <span class="op">=</span> np.random.uniform(<span class="dv">30000</span>, <span class="dv">120000</span>, n_samples)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create simple approval logic based on income thresholds</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Higher income = higher approval probability, but with some variation</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>approval_prob <span class="op">=</span> np.where(income <span class="op">&lt;</span> <span class="dv">50000</span>, <span class="fl">0.2</span>,</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>                        np.where(income <span class="op">&lt;</span> <span class="dv">80000</span>, <span class="fl">0.7</span>, <span class="fl">0.9</span>))</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Add some randomness</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>approval_prob <span class="op">+=</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.1</span>, n_samples)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>approved <span class="op">=</span> (approval_prob <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>simple_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'income'</span>: income,</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'approved'</span>: approved</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample size: </span><span class="sc">{</span><span class="bu">len</span>(simple_data)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Overall approval rate: </span><span class="sc">{</span>simple_data[<span class="st">'approved'</span>]<span class="sc">.</span>mean()<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First few rows of our simulated loan data:"</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(simple_data.head())</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Build simple decision tree with one variable</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>X_simple <span class="op">=</span> simple_data[[<span class="st">'income'</span>]]</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>y_simple <span class="op">=</span> simple_data[<span class="st">'approved'</span>]</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a very simple tree (max_depth=2) to see clear splits</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>simple_tree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">2</span>, min_samples_split<span class="op">=</span><span class="dv">20</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>simple_tree.fit(X_simple, y_simple)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Single-variable tree accuracy: </span><span class="sc">{</span>simple_tree<span class="sc">.</span>score(X_simple, y_simple)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Sample size: 200
Overall approval rate: 75.5%

First few rows of our simulated loan data:
          income  approved
0   63708.610696         1
1  115564.287577         1
2   95879.454763         1
3   83879.263578         1
4   44041.677640         0
Single-variable tree accuracy: 0.985</code></pre>
</div>
</div>
<div id="22ef5019" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show code for visualizing single-variable tree</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the simple tree</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>tree.plot_tree(</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    simple_tree,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    feature_names<span class="op">=</span>[<span class="st">'Income'</span>],</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    class_names<span class="op">=</span>[<span class="st">'Denied'</span>, <span class="st">'Approved'</span>],</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    filled<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    rounded<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    fontsize<span class="op">=</span><span class="dv">10</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Simple Decision Tree: Loan Approval Based on Income Only"</span>, fontsize<span class="op">=</span><span class="dv">14</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="25-decision-trees_files/figure-html/cell-5-output-1.png" width="758" height="470" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Reading Tree Node Information
</div>
</div>
<div class="callout-body-container callout-body">
<p>Each box (node) in the tree diagram contains valuable information:</p>
<ul>
<li><strong>Splitting Condition</strong> (top line): The yes/no question being asked (e.g., “Income ≤ 50,187.5”)</li>
<li><strong>gini</strong>: Impurity measure ranging from 0.0 to 0.5 (more on this below)</li>
<li><strong>samples</strong>: Number of data points that reach this node</li>
<li><strong>value</strong>: Count for each class as [denied_count, approved_count]</li>
<li><strong>class</strong>: The predicted class for observations at this node (shown by the majority class)</li>
<li><strong>Color</strong>: Node color indicates the dominant class - darker colors mean more pure (confident) predictions</li>
</ul>
<p><strong>Path Navigation</strong>: Follow the left branch when the condition is TRUE, right branch when FALSE.</p>
</div>
</div>
</section>
</section>
<section id="understanding-how-cart-trees-make-decisions" class="level3">
<h3 class="anchored" data-anchor-id="understanding-how-cart-trees-make-decisions">Understanding How CART Trees Make Decisions</h3>
<p>The tree you see above was built using the <strong>CART</strong> (Classification and Regression Trees) algorithm—the foundation of scikit-learn’s DecisionTreeClassifier. Understanding how CART chooses where to split helps you appreciate why trees are so powerful for business applications.</p>
<p><strong>How CART Finds the Best Split:</strong></p>
<ol type="1">
<li><p><strong>Exhaustive Search</strong>: At each node, CART considers every possible split for every feature. For income, it tests thresholds like “income ≤ $45,000”, “income ≤ $46,000”, etc.</p></li>
<li><p><strong>Purity Measurement</strong>: Each potential split is evaluated using <strong>Gini impurity</strong>, which measures how “mixed” the resulting groups are:</p>
<ul>
<li>Gini = 0: Perfect purity (all approved or all denied)</li>
<li>Gini = 0.5: Maximum impurity (50/50 mix)</li>
</ul></li>
<li><p><strong>Best Split Selection</strong>: CART chooses the split that creates the largest reduction in impurity—effectively asking “Which question best separates our data into distinct groups?”</p></li>
<li><p><strong>Recursive Splitting</strong>: The process repeats for each resulting branch until stopping criteria are met.</p></li>
</ol>
<p><strong>Why This Matters for Business</strong>: This systematic approach means trees automatically discover the income thresholds that matter most for loan decisions. In our example, the tree found that income around $50,187 is a critical decision point—not because we told it to look there, but because that’s where the data naturally splits between approvals and denials. Notice how the tree then makes additional splits at $47,215 (for lower incomes) and $58,021 (for higher incomes), creating distinct income bands with different approval patterns.</p>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Understanding Gini Impurity
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Gini impurity</strong> is CART’s way of measuring how “mixed up” or “messy” a group is in terms of the classes we’re trying to predict. Think of it as a messiness meter:</p>
<ul>
<li><strong>Perfect Organization (Gini = 0.0)</strong>: All loans in the group have the same outcome—either all approved or all denied. This is what we want! A perfectly pure group means we can make confident predictions.</li>
<li><strong>Maximum Mess (Gini = 0.5)</strong>: The group is a 50/50 mix of approved and denied loans. This is the worst case—we’re essentially flipping a coin to make predictions.</li>
<li><strong>In Between (Gini = 0.1 to 0.4)</strong>: Most groups fall somewhere in the middle, with one outcome being more common than the other.</li>
</ul>
<p><strong>Why CART Loves Lower Gini</strong>: The algorithm always seeks splits that minimize Gini impurity because more organized groups lead to more confident, accurate predictions. When CART compares potential splits, it calculates: “If I split here, how much will the overall messiness decrease?” The split that creates the biggest reduction in messiness wins.</p>
<p><strong>Business Translation</strong>: Lower Gini impurity means clearer business rules. A node with Gini = 0.1 represents a very reliable business segment, while Gini = 0.4 suggests you need more information to make confident decisions about that group.</p>
</div>
</div>
<section id="example-2-two-variable-decision-tree" class="level4">
<h4 class="anchored" data-anchor-id="example-2-two-variable-decision-tree">Example 2: Two-Variable Decision Tree</h4>
<p>Now let’s see how the tree handles two variables—income and credit score:</p>
<div id="5688dfe0" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show code for two-variable example</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dataset with two variables</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">300</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate income and credit score</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>income <span class="op">=</span> np.random.uniform(<span class="dv">30000</span>, <span class="dv">120000</span>, n_samples)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>credit_score <span class="op">=</span> np.random.uniform(<span class="dv">500</span>, <span class="dv">800</span>, n_samples)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create approval logic based on both variables</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Good income OR good credit = likely approval</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Both good = very likely approval</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>approval_prob <span class="op">=</span> (</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.3</span> <span class="op">*</span> (income <span class="op">&gt;</span> <span class="dv">60000</span>) <span class="op">+</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.4</span> <span class="op">*</span> (credit_score <span class="op">&gt;</span> <span class="dv">650</span>) <span class="op">+</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.2</span> <span class="op">*</span> ((income <span class="op">&gt;</span> <span class="dv">60000</span>) <span class="op">&amp;</span> (credit_score <span class="op">&gt;</span> <span class="dv">650</span>)) <span class="op">+</span>  <span class="co"># Bonus for both</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">0</span>, <span class="fl">0.1</span>, n_samples)  <span class="co"># Add noise</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>approved <span class="op">=</span> (approval_prob <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>two_var_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'income'</span>: income,</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'credit_score'</span>: credit_score,</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'approved'</span>: approved</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Two-variable dataset size: </span><span class="sc">{</span><span class="bu">len</span>(two_var_data)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Approval rate: </span><span class="sc">{</span>two_var_data[<span class="st">'approved'</span>]<span class="sc">.</span>mean()<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First few rows of our two-variable loan data:"</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(two_var_data.head())</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Build two-variable tree</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>X_two <span class="op">=</span> two_var_data[[<span class="st">'income'</span>, <span class="st">'credit_score'</span>]]</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>y_two <span class="op">=</span> two_var_data[<span class="st">'approved'</span>]</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>two_var_tree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">3</span>, min_samples_split<span class="op">=</span><span class="dv">30</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>two_var_tree.fit(X_two, y_two)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Two-variable tree accuracy: </span><span class="sc">{</span>two_var_tree<span class="sc">.</span>score(X_two, y_two)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Two-variable dataset size: 300
Approval rate: 37.3%

First few rows of our two-variable loan data:
         income  credit_score  approved
0  92682.226704    504.917744         0
1  55752.540146    716.355310         1
2  50416.630821    502.321254         0
3  79618.329217    525.446683         0
4  94752.207281    567.649523         0
Two-variable tree accuracy: 0.960</code></pre>
</div>
</div>
<div id="f76c80e6" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show code for visualizing two-variable tree</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the two-variable tree</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>tree.plot_tree(</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    two_var_tree,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    feature_names<span class="op">=</span>[<span class="st">'Income'</span>, <span class="st">'Credit Score'</span>],</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    class_names<span class="op">=</span>[<span class="st">'Denied'</span>, <span class="st">'Approved'</span>],</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    filled<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    rounded<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    fontsize<span class="op">=</span><span class="dv">10</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Decision Tree: Loan Approval Based on Income and Credit Score"</span>, fontsize<span class="op">=</span><span class="dv">16</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="25-decision-trees_files/figure-html/cell-7-output-1.png" width="950" height="567" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="how-cart-handles-multiple-variables" class="level3">
<h3 class="anchored" data-anchor-id="how-cart-handles-multiple-variables">How CART Handles Multiple Variables</h3>
<p>Now with two variables (income and credit score), CART faces a more complex decision: at each split, it must choose not only the best threshold but also the best variable to split on. This showcases the algorithm’s ability to automatically discover variable importance and interactions.</p>
<p><strong>Key Insights from the Two-Variable Tree:</strong></p>
<ul>
<li><p><strong>Variable Selection</strong>: CART automatically chose which variable to split on first by testing all possible splits for both income and credit score, then selecting the one that provides the greatest reduction in Gini impurity. Notice that different branches may prioritize different variables based on what matters most for that subset of applicants.</p></li>
<li><p><strong>Automatic Interaction Discovery</strong>: The tree naturally captures interactions between income and credit score without requiring us to manually create interaction terms. For example, a moderate income might be sufficient for approval if paired with an excellent credit score, but insufficient if paired with a poor credit score.</p></li>
<li><p><strong>Context-Dependent Rules</strong>: Each path through the tree represents a different business rule. Some paths might rely primarily on income thresholds, while others focus on credit score, depending on which combination best separates approved from denied applications in that segment.</p></li>
<li><p><strong>Feature Hierarchy</strong>: The tree structure reveals which factors matter most at different decision points, providing insights into the natural hierarchy of lending criteria that emerges from the data.</p></li>
</ul>
</section>
<section id="reading-through-the-two-variable-tree" class="level3">
<h3 class="anchored" data-anchor-id="reading-through-the-two-variable-tree">Reading Through the Two-Variable Tree</h3>
<p>Let’s walk through the actual tree above to understand how CART made its decisions and what business insights we can extract:</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Click to view decision tree
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="1965b825" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="25-decision-trees_files/figure-html/cell-8-output-1.png" width="758" height="374" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<ul>
<li><p><strong>Root Decision (Credit Score ≤ 649.56)</strong>: CART chose credit score, not income, as the most important first question. This tells us that credit score provides the best initial separation of approved vs.&nbsp;denied loans. Notice the Gini = 0.468, indicating this starting group is quite mixed.</p></li>
<li><p><strong>Left Branch - Low Credit Scores</strong>: If credit score ≤ 649.56, the decision is simple: <strong>automatic denial</strong> (Gini = 0.0, all 155 customers denied). This represents a clear business rule: “Below 650 credit score = automatic denial, regardless of income.”</p></li>
<li><p><strong>Right Branch - Higher Credit Scores</strong>: For credit scores &gt; 649.56, the algorithm now considers income (≤ $58,948). This shows <strong>context-dependent decision making</strong>: income only matters after passing the credit score threshold.</p></li>
<li><p><strong>Income-Based Refinement</strong>:</p>
<ul>
<li><strong>Lower income + decent credit</strong> (left sub-branch): Mixed outcomes (Gini = 0.391), requiring further credit score refinement at 719.86</li>
<li><strong>Higher income + decent credit</strong> (right sub-branch): <strong>automatic approval</strong> (Gini = 0.0, all 100 customers approved)</li>
</ul></li>
<li><p><strong>Business Translation</strong>: The tree discovered a natural lending hierarchy:</p>
<ol type="1">
<li>Credit score &lt; 650: Deny (no exceptions)</li>
<li>Credit score 650-719 + income ≤ $58,948: Needs case-by-case evaluation</li>
<li>Credit score &gt; 650 + income &gt; $58,948: Approve automatically</li>
<li>Credit score &gt; 719: Generally approve (even with lower income)</li>
</ol></li>
<li><p><strong>Key Insight</strong>: This demonstrates how CART automatically finds the business logic that human loan officers might use, but derived purely from data patterns.</p></li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>🎥 Video: Decision Trees Explained
</div>
</div>
<div class="callout-body-container callout-body">
<p>Watch this comprehensive video on decision trees that covers:</p>
<ul>
<li>Basic decision tree concepts</li>
<li>Building a tree with Gini Impurity</li>
<li>Numeric and continuous variables</li>
<li>And more</li>
</ul>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/_L39rN6gz7Y?si=OomCcU3l8OQD4WjS" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
</section>
<section id="building-your-first-decision-tree" class="level2" data-number="25.3">
<h2 data-number="25.3" class="anchored" data-anchor-id="building-your-first-decision-tree"><span class="header-section-number">25.3</span> Building Your First Decision Tree</h2>
<section id="classification-trees" class="level3">
<h3 class="anchored" data-anchor-id="classification-trees">Classification Trees</h3>
<p>Now let’s apply decision trees to a real medical problem: predicting heart disease based on patient health metrics. This classic dataset contains 303 patients with 13 clinical features including age, sex, chest pain type, resting blood pressure, cholesterol levels, and various cardiac measurements. The target variable indicates the presence (1) or absence (0) of heart disease, with approximately 46% of patients diagnosed with the condition.</p>
<p>The dataset includes both numerical features (age, blood pressure, cholesterol) and categorical features (sex, chest pain type, ECG results) that we’ll encode numerically for scikit-learn compatibility. This dataset demonstrates how decision trees excel at medical diagnosis tasks where interpretability is crucial for clinical decision-making.</p>
<p><strong>Dataset Source</strong>: <a href="https://github.com/bradleyboehmke/uc-bana-4080/blob/main/data/heart.csv">Heart Disease Dataset on GitHub</a></p>
<div id="3663ce5c" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Show code for loading heart disease dataset</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load heart disease dataset</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>heart_data <span class="op">=</span> pd.read_csv(<span class="st">'../data/heart.csv'</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode categorical variables to numeric</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: scikit-learn decision trees require all features to be numeric.</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># We're using LabelEncoder here to convert categorical strings to integers.</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># This is a simple approach that works well for tree-based models, though</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># it does imply an ordinal relationship between categories. We'll explore</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># this topic and other feature engineering approaches in more depth in the</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># next module on feature engineering and preprocessing.</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>heart_data_encoded <span class="op">=</span> heart_data.copy()</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify categorical columns (object dtype)</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> heart_data_encoded.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode each categorical column</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>label_encoders <span class="op">=</span> {}</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> categorical_cols:</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    le <span class="op">=</span> LabelEncoder()</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    heart_data_encoded[col] <span class="op">=</span> le.fit_transform(heart_data_encoded[col])</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    label_encoders[col] <span class="op">=</span> le</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Display first few rows</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>heart_data_encoded.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">Chest pain</th>
<th data-quarto-table-cell-role="th">rest BP</th>
<th data-quarto-table-cell-role="th">Chol</th>
<th data-quarto-table-cell-role="th">fbs</th>
<th data-quarto-table-cell-role="th">rest-ecg</th>
<th data-quarto-table-cell-role="th">max-hr</th>
<th data-quarto-table-cell-role="th">exang</th>
<th data-quarto-table-cell-role="th">old_peak</th>
<th data-quarto-table-cell-role="th">slope</th>
<th data-quarto-table-cell-role="th">ca</th>
<th data-quarto-table-cell-role="th">thal</th>
<th data-quarto-table-cell-role="th">disease</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>63</td>
<td>1</td>
<td>3</td>
<td>145</td>
<td>233</td>
<td>1</td>
<td>1</td>
<td>150</td>
<td>0</td>
<td>2.3</td>
<td>3</td>
<td>0.0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>67</td>
<td>1</td>
<td>0</td>
<td>160</td>
<td>286</td>
<td>0</td>
<td>1</td>
<td>108</td>
<td>1</td>
<td>1.5</td>
<td>2</td>
<td>3.0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>67</td>
<td>1</td>
<td>0</td>
<td>120</td>
<td>229</td>
<td>0</td>
<td>1</td>
<td>129</td>
<td>1</td>
<td>2.6</td>
<td>2</td>
<td>2.0</td>
<td>2</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>37</td>
<td>1</td>
<td>1</td>
<td>130</td>
<td>250</td>
<td>0</td>
<td>2</td>
<td>187</td>
<td>0</td>
<td>3.5</td>
<td>3</td>
<td>0.0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>41</td>
<td>0</td>
<td>2</td>
<td>130</td>
<td>204</td>
<td>0</td>
<td>1</td>
<td>172</td>
<td>0</td>
<td>1.4</td>
<td>1</td>
<td>0.0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The process of building a decision tree follows the same workflow you’ve seen with linear and logistic regression: prepare your features and target, split into training and test sets, fit the model, and evaluate performance. The main difference is that instead of <code>LinearRegression()</code> or <code>LogisticRegression()</code>, we use <code>DecisionTreeClassifier()</code> for classification tasks.</p>
<div id="11029e78" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build classification tree for heart disease prediction</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare features and target using the encoded data</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>X_heart <span class="op">=</span> heart_data_encoded.drop(<span class="st">'disease'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>y_heart <span class="op">=</span> heart_data_encoded[<span class="st">'disease'</span>]</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>X_train_heart, X_test_heart, y_train_heart, y_test_heart <span class="op">=</span> train_test_split(</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    X_heart, y_heart, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_heart</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Build decision tree with default settings</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>heart_tree <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>heart_tree.fit(X_train_heart, y_train_heart)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate performance</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>y_pred_heart <span class="op">=</span> heart_tree.predict(X_test_heart)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Detailed Classification Report:"</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_heart, y_pred_heart, target_names<span class="op">=</span>[<span class="st">'No Disease'</span>, <span class="st">'Disease'</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Detailed Classification Report:
              precision    recall  f1-score   support

  No Disease       0.73      0.84      0.78        49
     Disease       0.77      0.64      0.70        42

    accuracy                           0.75        91
   macro avg       0.75      0.74      0.74        91
weighted avg       0.75      0.75      0.74        91
</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Click here to see this decision tree plot
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The tree below shows the full structure learned from the training data. Notice how deep it grows and how many leaf nodes it creates—this complexity is why we’re seeing perfect training accuracy but lower test accuracy.</p>
<div id="81afb7cb" class="cell" data-fig-height="12" data-fig-width="20" data-execution_count="10">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="25-decision-trees_files/figure-html/cell-11-output-1.png" width="1905" height="1431" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Knowledge Check: Reading the Decision Tree
</div>
</div>
<div class="callout-body-container callout-body">
<p>Using the tree visualization above, practice tracing through the decision-making process:</p>
<ol type="1">
<li><strong>Understanding the Root Split</strong>:
<ul>
<li>What is the first (root) question the tree asks?</li>
<li>What does this tell you about which feature the algorithm found most important for the initial split?</li>
<li>How many samples went left vs.&nbsp;right from the root?</li>
</ul></li>
<li><strong>Tracing a Simple Path</strong>:
<ul>
<li>Find the path: Root → <code>ca &lt;= 0.5</code> (left) → <code>thal &lt;= 1.5</code> (left)</li>
<li>What is the final prediction at this leaf node?</li>
<li>How many training samples reached this leaf?</li>
<li>What is the gini impurity? What does this tell you about the purity of this prediction?</li>
</ul></li>
<li><strong>Finding Evidence of Overfitting</strong>:
<ul>
<li>Explore the tree and find at least two leaf nodes with very few samples (samples &lt; 5)</li>
<li>Look at the gini values for these sparse leaves. Are they pure (gini ≈ 0) or mixed?</li>
<li>What does it mean when a leaf has only 1-2 samples but gini = 0.0?</li>
<li>Why might these highly specific rules fail on new patients?</li>
</ul></li>
<li><strong>Comparing Leaf Depths</strong>:
<ul>
<li>Notice how some paths are much longer (deeper) than others</li>
<li>Find the shortest path from root to leaf (fewest splits)</li>
<li>Find one of the longest paths (most splits)</li>
<li>Which type of path (short vs.&nbsp;long) is more likely to generalize well? Why?</li>
</ul></li>
</ol>
<p><strong>Reflection</strong>: After exploring this tree, what problems do you anticipate with using it in a real clinical setting? Consider both the complexity and the reliance on very specific feature combinations.</p>
</div>
</div>
</section>
<section id="regression-trees" class="level3">
<h3 class="anchored" data-anchor-id="regression-trees">Regression Trees</h3>
<p>Decision trees aren’t limited to classification—they also work excellently for predicting continuous outcomes. Let’s predict house prices using the famous Ames Housing dataset, which contains detailed information about residential properties in Ames, Iowa. This dataset includes 2,930 homes with 80+ features describing various aspects of residential properties.</p>
<p>For our regression tree, we’ll focus on 8 key features that are intuitive and commonly used in real estate valuation: living area, overall quality, basement size, garage area, year built, lot size, bathrooms, and bedrooms. This demonstrates how regression trees handle numeric target variables while maintaining the same interpretable structure as classification trees.</p>
<p><strong>Dataset Source</strong>: <a href="https://github.com/bradleyboehmke/uc-bana-4080/blob/main/data/ames_clean.csv">Ames Housing Dataset on GitHub</a></p>
<div id="111b4597" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Show code for loading Ames housing dataset</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Ames housing dataset</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error, r2_score, mean_squared_error</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the cleaned Ames data</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>ames_data <span class="op">=</span> pd.read_csv(<span class="st">'../data/ames_clean.csv'</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Select a subset of interpretable features for our tree</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>features_to_use <span class="op">=</span> [</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'GrLivArea'</span>,        <span class="co"># Above ground living area</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'OverallQual'</span>,      <span class="co"># Overall material and finish quality</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'TotalBsmtSF'</span>,      <span class="co"># Total basement square feet</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'GarageArea'</span>,       <span class="co"># Size of garage in square feet</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'YearBuilt'</span>,        <span class="co"># Original construction date</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'LotArea'</span>,          <span class="co"># Lot size in square feet</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'FullBath'</span>,         <span class="co"># Full bathrooms above grade</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'BedroomAbvGr'</span>      <span class="co"># Bedrooms above grade</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subset with selected features</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>house_data <span class="op">=</span> ames_data[features_to_use <span class="op">+</span> [<span class="st">'SalePrice'</span>]].copy()</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove any rows with missing values</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>house_data <span class="op">=</span> house_data.dropna()</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Display first few rows</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>house_data.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">GrLivArea</th>
<th data-quarto-table-cell-role="th">OverallQual</th>
<th data-quarto-table-cell-role="th">TotalBsmtSF</th>
<th data-quarto-table-cell-role="th">GarageArea</th>
<th data-quarto-table-cell-role="th">YearBuilt</th>
<th data-quarto-table-cell-role="th">LotArea</th>
<th data-quarto-table-cell-role="th">FullBath</th>
<th data-quarto-table-cell-role="th">BedroomAbvGr</th>
<th data-quarto-table-cell-role="th">SalePrice</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1710</td>
<td>7</td>
<td>856</td>
<td>548</td>
<td>2003</td>
<td>8450</td>
<td>2</td>
<td>3</td>
<td>208500</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>1262</td>
<td>6</td>
<td>1262</td>
<td>460</td>
<td>1976</td>
<td>9600</td>
<td>2</td>
<td>3</td>
<td>181500</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>1786</td>
<td>7</td>
<td>920</td>
<td>608</td>
<td>2001</td>
<td>11250</td>
<td>2</td>
<td>3</td>
<td>223500</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>1717</td>
<td>7</td>
<td>756</td>
<td>642</td>
<td>1915</td>
<td>9550</td>
<td>1</td>
<td>3</td>
<td>140000</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>2198</td>
<td>8</td>
<td>1145</td>
<td>836</td>
<td>2000</td>
<td>14260</td>
<td>2</td>
<td>4</td>
<td>250000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Building a regression tree follows the same familiar workflow, but we use <code>DecisionTreeRegressor()</code> instead of <code>DecisionTreeClassifier()</code>. The tree will predict continuous sale prices rather than discrete classes.</p>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Regression Trees: SSE Instead of Gini
</div>
</div>
<div class="callout-body-container callout-body">
<p>While the tree structure and decision-making process are the same as classification trees, <strong>regression trees use a different splitting criterion</strong>:</p>
<ul>
<li><strong>Classification trees</strong> minimize <strong>Gini impurity</strong> (or entropy) to create pure class groupings</li>
<li><strong>Regression trees</strong> minimize <strong>Sum of Squared Errors (SSE)</strong> to create groups with similar numeric values</li>
</ul>
<p><strong>How SSE works</strong>: At each potential split, the algorithm calculates the sum of squared differences between each house’s actual price and the average price in that group. The split that produces the lowest total SSE across both resulting groups is chosen.</p>
<p><strong>Why this matters</strong>: Just like classification trees seek purity (all same class), regression trees seek homogeneity (all similar values). A leaf with houses priced at $180k, $182k, and $181k has low SSE. A leaf with houses priced at $100k, $200k, and $300k has high SSE and would benefit from further splitting.</p>
<p>The core principle remains the same: <strong>find splits that create the most homogeneous groups possible</strong>.</p>
</div>
</div>
<div id="0747ca30" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build regression tree for house prices</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare features and target</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>X_house <span class="op">=</span> house_data.drop(<span class="st">'SalePrice'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>y_house <span class="op">=</span> house_data[<span class="st">'SalePrice'</span>]</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>X_train_house, X_test_house, y_train_house, y_test_house <span class="op">=</span> train_test_split(</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    X_house, y_house, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Build regression tree with default settings</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>price_tree <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>price_tree.fit(X_train_house, y_train_house)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> price_tree.predict(X_train_house)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> price_tree.predict(X_test_house)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate performance</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>test_r2 <span class="op">=</span> r2_score(y_test_house, y_pred_test)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>test_mae <span class="op">=</span> mean_absolute_error(y_test_house, y_pred_test)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(y_test_house, y_pred_test))</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"House Price Prediction Results:"</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test R² Score: </span><span class="sc">{</span>test_r2<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Absolute Error: $</span><span class="sc">{</span>test_mae<span class="sc">:,.0f}</span><span class="ss">"</span>)</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Root Mean Squared Error: $</span><span class="sc">{</span>test_rmse<span class="sc">:,.0f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>House Price Prediction Results:
Test R² Score: 0.768
Mean Absolute Error: $27,112
Root Mean Squared Error: $40,215</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Click here to see this decision tree plot
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The visualization below shows only the first 3 levels of the regression tree. The actual tree is far too deep and complex to display in its entirety—it would be impossible to read. Unlike classification trees that predict discrete classes, each leaf node in a regression tree predicts a specific dollar amount (the average price of houses in that leaf).</p>
<div id="15ee5f21" class="cell" data-fig-height="12" data-fig-width="20" data-execution_count="13">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="25-decision-trees_files/figure-html/cell-14-output-1.png" width="1910" height="1431" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Knowledge Check: Understanding Regression Trees
</div>
</div>
<div class="callout-body-container callout-body">
<p>Using the tree visualization above, explore how regression trees differ from classification trees:</p>
<ol type="1">
<li><strong>Leaf Node Predictions</strong>:
<ul>
<li>Look at any leaf node. What does the “value” represent in a regression tree?</li>
<li>How is this different from classification trees where value showed class counts?</li>
</ul></li>
<li><strong>Splitting Decisions</strong>:
<ul>
<li>What feature did the tree choose for the root split?</li>
<li>Why might this feature be most important for predicting house prices?</li>
<li>Follow the left branch (lower values). What type of houses end up here?</li>
</ul></li>
<li><strong>Price Ranges</strong>:
<ul>
<li>Find a leaf node on the left side of the tree (typically lower-priced homes)</li>
<li>Find a leaf node on the right side (typically higher-priced homes)</li>
<li>What’s the price difference between these segments?</li>
<li>How many training samples reached each leaf?</li>
</ul></li>
</ol>
<p><strong>Reflection</strong>: Real estate agents price homes using “comps”—finding 3-5 similar recently sold properties and averaging their prices. How is this regression tree’s approach similar to and different from the comps method? Consider: How many houses does the tree use for each prediction? Does it always use the most relevant comparables? What makes a good comp vs.&nbsp;what makes the tree split?</p>
</div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>🎥 Video: Regression Trees Explained
</div>
</div>
<div class="callout-body-container callout-body">
<p>Watch this excellent video that compares regression trees to classification trees and clearly explains key concepts:</p>
<ul>
<li>How regression trees differ from classification trees</li>
<li>SSE (Sum of Squared Errors) as the splitting criterion</li>
<li>Building and interpreting regression trees</li>
<li>Practical applications and examples</li>
</ul>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/g9c66TUylZ4?si=1B03h8rzJTaGhIpH" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
<section id="tree-parameters-and-overfitting" class="level3">
<h3 class="anchored" data-anchor-id="tree-parameters-and-overfitting">Tree Parameters and Overfitting</h3>
<p>Decision trees have a natural tendency to overfit—they can keep splitting until each leaf contains just one data point, perfectly memorizing the training data but failing to generalize. Understanding and controlling tree complexity is crucial for business applications.</p>
<p><strong>What does “default” tree complexity look like?</strong> When we built our classification and regression trees earlier using default settings, the results were dramatic. Let’s examine exactly how complex these trees became:</p>
<div id="43da2918" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Show code for extracting tree complexity</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the complexity of our default trees</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Tree (Heart Disease) Complexity:"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Maximum depth: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>get_depth()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total number of nodes: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>tree_<span class="sc">.</span>node_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Number of leaves: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>get_n_leaves()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Training accuracy: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>score(X_train_heart, y_train_heart)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Test accuracy: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>score(X_test_heart, y_test_heart)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regression Tree (House Prices) Complexity:"</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Maximum depth: </span><span class="sc">{</span>price_tree<span class="sc">.</span>get_depth()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total number of nodes: </span><span class="sc">{</span>price_tree<span class="sc">.</span>tree_<span class="sc">.</span>node_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Number of leaves: </span><span class="sc">{</span>price_tree<span class="sc">.</span>get_n_leaves()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Training R²: </span><span class="sc">{</span>price_tree<span class="sc">.</span>score(X_train_house, y_train_house)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Test R²: </span><span class="sc">{</span>price_tree<span class="sc">.</span>score(X_test_house, y_test_house)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Classification Tree (Heart Disease) Complexity:
  Maximum depth: 9
  Total number of nodes: 73
  Number of leaves: 37
  Training accuracy: 1.000
  Test accuracy: 0.747

Regression Tree (House Prices) Complexity:
  Maximum depth: 24
  Total number of nodes: 1989
  Number of leaves: 995
  Training R²: 1.000
  Test R²: 0.768</code></pre>
</div>
</div>
<p>Notice the striking patterns:</p>
<ul>
<li><p><strong>Heart disease classification tree</strong>: With a depth of 9 levels, 73 total nodes, and 37 leaf nodes, this tree achieved perfect 1.000 training accuracy but only 0.747 test accuracy. The gap reveals classic overfitting—the tree learned highly specific rules that don’t generalize.</p></li>
<li><p><strong>House price regression tree</strong>: Even more extreme—depth of 24 levels with nearly 2,000 nodes and almost 1,000 leaf nodes! Perfect training R² of 1.000 but test R² dropped to 0.768. This tree literally created a separate leaf for almost every few training examples, memorizing individual houses rather than learning general pricing patterns.</p></li>
</ul>
<p>This illustrates a critical point: <strong>without parameter constraints, decision trees will grow until they perfectly fit (memorize) your training data</strong>. The algorithm has no inherent preference for simplicity—it will keep asking questions until it achieves perfect purity or runs out of data to split. The 1.000 training scores on both trees prove this memorization happened, while the lower test scores reveal the cost of overfitting.</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>🎥 Video: Overfitting in Decision Trees
</div>
</div>
<div class="callout-body-container callout-body">
<p>Watch this video that visualizes the overfitting problem as decision trees become more complex:</p>
<ul>
<li>How overfitting occurs with increasing tree depth</li>
<li>Training accuracy improves while test accuracy deteriorates</li>
<li>Visual demonstration of the bias-variance tradeoff</li>
<li>Why simpler trees often generalize better</li>
</ul>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/i_0-5rdxsfg?si=u5fPLvexp32kILjS" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
<p>The key to successful tree implementation lies in understanding and controlling the parameters that govern tree complexity. Without proper tuning, trees will default to memorizing every detail of your training data rather than learning generalizable patterns. Here are the most important parameters you can control:</p>
<ul>
<li><strong>max_depth</strong>: Maximum number of questions in any path
<ul>
<li><strong>Business impact</strong>: Deeper trees = more complex rules, harder to explain</li>
<li><strong>Typical values</strong>: 3-5 for interpretable models, 6-10 for better performance</li>
</ul></li>
<li><strong>min_samples_split</strong>: Minimum samples required to split a node
<ul>
<li><strong>Business impact</strong>: Prevents rules based on tiny groups</li>
<li><strong>Typical values</strong>: 20-100 depending on dataset size</li>
</ul></li>
<li><strong>min_samples_leaf</strong>: Minimum samples in final prediction groups
<ul>
<li><strong>Business impact</strong>: Ensures predictions based on substantial evidence</li>
<li><strong>Typical values</strong>: 10-50 for stable predictions</li>
</ul></li>
</ul>
<p>Let’s rebuild our heart disease tree with reasonable constraints and see how it impacts generalization:</p>
<div id="eed4b1a7" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a constrained tree with reasonable parameters</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>heart_tree_tuned <span class="op">=</span> DecisionTreeClassifier(</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">5</span>,           <span class="co"># Limit tree depth</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">20</span>,  <span class="co"># Require at least 20 samples to split</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">10</span>,   <span class="co"># Require at least 10 samples in each leaf</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>heart_tree_tuned.fit(X_train_heart, y_train_heart)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare default vs constrained tree</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model Comparison:"</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Default Tree (unconstrained):"</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Training accuracy: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>score(X_train_heart, y_train_heart)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Test accuracy: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>score(X_test_heart, y_test_heart)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Overfitting gap: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>score(X_train_heart, y_train_heart) <span class="op">-</span> heart_tree<span class="sc">.</span>score(X_test_heart, y_test_heart)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Tree depth: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>get_depth()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Number of leaves: </span><span class="sc">{</span>heart_tree<span class="sc">.</span>get_n_leaves()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Constrained Tree (tuned parameters):"</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Training accuracy: </span><span class="sc">{</span>heart_tree_tuned<span class="sc">.</span>score(X_train_heart, y_train_heart)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Test accuracy: </span><span class="sc">{</span>heart_tree_tuned<span class="sc">.</span>score(X_test_heart, y_test_heart)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Overfitting gap: </span><span class="sc">{</span>heart_tree_tuned<span class="sc">.</span>score(X_train_heart, y_train_heart) <span class="op">-</span> heart_tree_tuned<span class="sc">.</span>score(X_test_heart, y_test_heart)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Tree depth: </span><span class="sc">{</span>heart_tree_tuned<span class="sc">.</span>get_depth()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Number of leaves: </span><span class="sc">{</span>heart_tree_tuned<span class="sc">.</span>get_n_leaves()<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model Comparison:

Default Tree (unconstrained):
  Training accuracy: 1.000
  Test accuracy: 0.747
  Overfitting gap: 0.253
  Tree depth: 9
  Number of leaves: 37

Constrained Tree (tuned parameters):
  Training accuracy: 0.868
  Test accuracy: 0.780
  Overfitting gap: 0.088
  Tree depth: 4
  Number of leaves: 13</code></pre>
</div>
</div>
<p>The constrained tree demonstrates significant improvements across all metrics. While training accuracy dropped slightly from 1.000 to around 0.86, test accuracy actually improved to approximately 0.82—a clear sign that the model now generalizes better to unseen data. Most importantly, the overfitting gap shrunk dramatically from 0.253 to just 0.04, indicating the tree has learned true patterns rather than memorizing noise. The tree structure itself became much more interpretable, with depth reduced from 9 to 5 levels and leaf count dropping from 37 to just 13 nodes—making it practical for clinical decision-making.</p>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Looking Ahead: Systematic Hyperparameter Tuning
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this example, we manually specified parameter values based on general guidelines. In a future chapter on model optimization, you’ll learn systematic approaches like <strong>cross-validation</strong> and <strong>grid search</strong> that automatically find optimal parameter combinations by testing many values and selecting those that maximize generalization performance. These techniques remove the guesswork and ensure you’re getting the best possible model for your data.</p>
</div>
</div>
</section>
</section>
<section id="when-to-use-decision-trees" class="level2" data-number="25.4">
<h2 data-number="25.4" class="anchored" data-anchor-id="when-to-use-decision-trees"><span class="header-section-number">25.4</span> When to Use Decision Trees</h2>
<section id="advantages-over-linear-models" class="level3">
<h3 class="anchored" data-anchor-id="advantages-over-linear-models">Advantages Over Linear Models</h3>
<p>Decision trees offer several compelling advantages over linear models, particularly in business contexts where relationships are complex and stakeholder buy-in requires clear explanations. These advantages make trees especially valuable when moving beyond the assumptions of linear modeling.</p>
<ul>
<li><strong>Automatic handling of non-linear relationships</strong>: Trees naturally discover threshold effects, saturation points, and diminishing returns without manual feature engineering.</li>
<li><strong>No assumptions about data distribution</strong>: Unlike linear models, trees don’t assume your data follows normal distributions or has linear relationships.</li>
<li><strong>Natural handling of missing values</strong>: Trees can make decisions even when some features are missing—they simply use alternative splitting rules.</li>
<li><strong>Built-in feature interaction detection</strong>: Trees automatically find complex interactions like “high income AND young age” without requiring you to specify them upfront.</li>
<li><strong>Complete interpretability</strong>: Every prediction can be explained as a series of simple yes/no decisions that business stakeholders can understand and verify.</li>
<li><strong>Mixed data type handling</strong>: Trees conceptually work with numerical, categorical, and ordinal features, though sklearn requires encoding categorical variables.</li>
</ul>
</section>
<section id="limitations-to-consider" class="level3">
<h3 class="anchored" data-anchor-id="limitations-to-consider">Limitations to Consider</h3>
<p>While decision trees offer significant advantages, they also come with important limitations that can impact their effectiveness in certain business scenarios. Understanding these constraints helps you choose the right tool for each situation and avoid common pitfalls.</p>
<ul>
<li><strong>Tendency to overfit with complex trees</strong>: Without careful parameter tuning, trees can memorize training data rather than learning generalizable patterns.</li>
<li><strong>Instability</strong>: Small changes in training data can lead to completely different trees, making them less reliable for consistent rule generation.</li>
<li><strong>Bias toward features with more levels</strong>: Categorical features with many categories get artificially inflated importance scores.</li>
<li><strong>Difficulty capturing linear relationships efficiently</strong>: Simple linear trends might require many splits to approximate, making trees unnecessarily complex.</li>
<li><strong>Step-function predictions</strong>: Trees create abrupt decision boundaries that might not reflect gradual real-world changes.</li>
</ul>
<p><strong>Overcoming These Limitations</strong>: Many of these challenges—particularly overfitting, instability, and prediction variance—can be significantly mitigated using ensemble methods. In the next chapter, we’ll explore <strong>random forests</strong>, which combine predictions from many trees to create more robust, accurate models while reducing sensitivity to individual data points and improving generalization.</p>
</section>
<section id="business-scenarios-where-trees-excel" class="level3">
<h3 class="anchored" data-anchor-id="business-scenarios-where-trees-excel">Business Scenarios Where Trees Excel</h3>
<p>Certain business contexts particularly benefit from decision trees’ unique strengths. These scenarios typically involve complex decision-making, regulatory requirements for explainability, or situations where stakeholders need to understand and trust the model’s reasoning process. For example…</p>
<p><strong>Risk Assessment and Credit Scoring</strong></p>
<pre><code>Example rules:
- If credit_score ≤ 650 AND debt_to_income &gt; 0.4: High Risk
- If credit_score &gt; 750 AND employment_years &gt; 3: Low Risk</code></pre>
<p><strong>Customer Segmentation</strong></p>
<pre><code>Natural groupings:
- Premium customers: High spending + Long tenure
- At-risk customers: Recent complaints + Short contracts
- Growth opportunities: Medium spending + Young demographics</code></pre>
<p><strong>Medical Diagnosis and Triage</strong></p>
<pre><code>Clinical decision support:
- If fever &gt; 101°F AND age &lt; 2: Immediate attention
- If symptoms = [cough, fatigue] AND duration &gt; 14 days: Further testing</code></pre>
<p><strong>Product Recommendation Systems</strong></p>
<pre><code>Personalized suggestions:
- If purchase_history includes "electronics" AND budget &gt; $500: Recommend premium gadgets
- If browsing_time &gt; 10min AND cart_abandonment = True: Send discount offer</code></pre>
<p><strong>Quality Control and Manufacturing</strong></p>
<pre><code>Defect detection:
- If temperature &gt; 150°C AND pressure &lt; 20 PSI: Quality alert
- If machine_age &gt; 5 years AND vibration &gt; threshold: Maintenance required</code></pre>
</section>
</section>
<section id="summary" class="level2" data-number="25.5">
<h2 data-number="25.5" class="anchored" data-anchor-id="summary"><span class="header-section-number">25.5</span> Summary</h2>
<p>Decision trees represent a fundamental shift from linear thinking to rule-based reasoning. Throughout this chapter, we’ve seen how trees excel at capturing the complex, context-dependent patterns that characterize real business data.</p>
<p><strong>Key Concepts Mastered:</strong></p>
<ul>
<li><strong>Tree Fundamentals</strong>: Understanding how CART builds trees through recursive splitting, using Gini impurity (classification) or SSE (regression) to find optimal decision points</li>
<li><strong>Tree Anatomy</strong>: Recognizing the components—nodes, splits, leaves, and depth—and how they combine to create interpretable decision paths</li>
<li><strong>Building Trees</strong>: Constructing both classification and regression trees using scikit-learn’s <code>DecisionTreeClassifier</code> and <code>DecisionTreeRegressor</code></li>
<li><strong>Controlling Complexity</strong>: Managing overfitting through parameter constraints (<code>max_depth</code>, <code>min_samples_split</code>, <code>min_samples_leaf</code>) to improve generalization</li>
<li><strong>Business Application</strong>: Evaluating when trees excel versus when linear models remain more appropriate for the task at hand</li>
</ul>
<p><strong>When Trees Shine:</strong></p>
<ul>
<li>Non-linear relationships with threshold effects and saturation points</li>
<li>Business problems requiring transparent, explainable decision rules</li>
<li>Complex feature interactions that are unknown upfront</li>
<li>Mixed data types (though encoding is still needed for sklearn)</li>
<li>Regulatory environments requiring model interpretability</li>
</ul>
<p><strong>When to Consider Alternatives:</strong></p>
<ul>
<li>Relationships are primarily linear (use linear/logistic regression)</li>
<li>Model stability and consistency are critical requirements</li>
<li>Smooth, continuous decision boundaries are preferred</li>
<li>Small training datasets where overfitting risk is high</li>
</ul>
<p><strong>Looking Ahead:</strong> While individual decision trees provide excellent interpretability, they suffer from instability and overfitting tendencies. In the next chapter, we’ll explore <strong>random forests</strong>—an ensemble method that combines multiple trees to overcome these limitations while maintaining much of the interpretability advantage. Random forests address the key weaknesses of single trees by averaging predictions across many diverse trees, resulting in more robust and accurate models.</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>🎥 Video: Decision Trees in Python - Complete Walkthrough
</div>
</div>
<div class="callout-body-container callout-body">
<p>Watch this comprehensive end-to-end tutorial that walks through implementing decision trees in Python:</p>
<ul>
<li>Preparing data for decision trees</li>
<li>Building and training decision tree models</li>
<li>Understanding and interpreting tree structure</li>
<li>Validating model performance</li>
<li>Complete workflow with practical Python examples</li>
</ul>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/q90UDEgYqeI?si=v9asCR8131g1_KJ7" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
<section id="end-of-chapter-exercise" class="level2" data-number="25.6">
<h2 data-number="25.6" class="anchored" data-anchor-id="end-of-chapter-exercise"><span class="header-section-number">25.6</span> End of Chapter Exercise</h2>
<p>For these exercises, you’ll apply decision trees to real business scenarios using datasets from previous chapters. Each scenario mirrors decision contexts where decision trees can provide interpretable insights and accurate predictions.</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 1: Baseball Salary Prediction (Regression)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Company:</strong> Professional baseball team</li>
<li><strong>Goal:</strong> Understand what drives player salaries to inform contract negotiations and player evaluation</li>
<li><strong>Dataset:</strong> Hitters dataset from ISLP package</li>
</ul>
<div id="a856e64e" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ISLP <span class="im">import</span> load_data</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor, plot_tree</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error, r2_score, mean_squared_error</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and prepare the data</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>Hitters <span class="op">=</span> load_data(<span class="st">'Hitters'</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove missing salary values</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>Hitters_clean <span class="op">=</span> Hitters.dropna(subset<span class="op">=</span>[<span class="st">'Salary'</span>])</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Select numeric features for our regression tree</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [<span class="st">'Years'</span>, <span class="st">'Hits'</span>, <span class="st">'RBI'</span>, <span class="st">'Walks'</span>, <span class="st">'PutOuts'</span>]</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>X_hitters <span class="op">=</span> Hitters_clean[features]</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>y_hitters <span class="op">=</span> Hitters_clean[<span class="st">'Salary'</span>]</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataset size: </span><span class="sc">{</span><span class="bu">len</span>(Hitters_clean)<span class="sc">}</span><span class="ss"> players"</span>)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Features used: </span><span class="sc">{</span>features<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">First few rows:"</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Hitters_clean[features <span class="op">+</span> [<span class="st">'Salary'</span>]].head())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset size: 263 players
Features used: ['Years', 'Hits', 'RBI', 'Walks', 'PutOuts']

First few rows:
   Years  Hits  RBI  Walks  PutOuts  Salary
1     14    81   38     39      632   475.0
2      3   130   72     76      880   480.0
3     11   141   78     37      200   500.0
4      2    87   42     30      805    91.5
5     11   169   51     35      282   750.0</code></pre>
</div>
</div>
<p><strong>Your Tasks:</strong></p>
<ol type="1">
<li><p><strong>Build and visualize a decision tree</strong>: Create a <code>DecisionTreeRegressor</code> to predict <code>Salary</code> using the features provided above. Start with default parameters, then try constraining with <code>max_depth=4</code> to improve interpretability.</p></li>
<li><p><strong>Evaluate performance</strong>: Split your data into training (70%) and test (30%) sets. Calculate and compare:</p>
<ul>
<li>Training R² and test R²</li>
<li>Mean Absolute Error on test set</li>
<li>Root Mean Squared Error on test set</li>
</ul></li>
<li><p><strong>Interpret the tree</strong>: Visualize your constrained tree (max_depth=4) using <code>plot_tree()</code>. What are the most important features for predicting salary? What salary ranges do different paths lead to?</p></li>
<li><p><strong>Extract business rules</strong>: Trace through 2-3 different paths in your tree and write them out as if-then rules (e.g., “If Years &gt; 5 AND Hits &gt; 100, then predicted salary = $X”)</p></li>
<li><p><strong>Business reflection</strong>:</p>
<ul>
<li>How could a player agent use these rules to negotiate higher salaries?</li>
<li>What limitations might this model have for contract negotiations?</li>
<li>Would you trust this model for a $10M contract decision? Why or why not?</li>
</ul></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 2: Credit Default Classification
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Company:</strong> Regional bank</li>
<li><strong>Goal:</strong> Predict which customers will default on credit card payments to inform risk management strategies</li>
<li><strong>Dataset:</strong> Default dataset from ISLP package</li>
</ul>
<div id="d4f57953" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix, accuracy_score</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Default dataset</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>Default <span class="op">=</span> load_data(<span class="st">'Default'</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare features - encode student as binary (already done by get_dummies)</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>Default_encoded <span class="op">=</span> pd.get_dummies(Default, columns<span class="op">=</span>[<span class="st">'student'</span>], drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>Default_encoded[<span class="st">'default_binary'</span>] <span class="op">=</span> (Default_encoded[<span class="st">'default'</span>] <span class="op">==</span> <span class="st">'Yes'</span>).astype(<span class="bu">int</span>)</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Select features</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>X_default <span class="op">=</span> Default_encoded[[<span class="st">'balance'</span>, <span class="st">'income'</span>, <span class="st">'student_Yes'</span>]]</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>y_default <span class="op">=</span> Default_encoded[<span class="st">'default_binary'</span>]</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataset size: </span><span class="sc">{</span><span class="bu">len</span>(Default)<span class="sc">}</span><span class="ss"> customers"</span>)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Default rate: </span><span class="sc">{</span>y_default<span class="sc">.</span>mean()<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Features prepared:"</span>)</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_default.head())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset size: 10000 customers
Default rate: 3.3%

Features prepared:
       balance        income  student_Yes
0   729.526495  44361.625074        False
1   817.180407  12106.134700         True
2  1073.549164  31767.138947        False
3   529.250605  35704.493935        False
4   785.655883  38463.495879        False</code></pre>
</div>
</div>
<p><strong>Your Tasks:</strong></p>
<ol type="1">
<li><p><strong>Build classification trees</strong>: Create two <code>DecisionTreeClassifier</code> models:</p>
<ul>
<li>Model A: Default parameters</li>
<li>Model B: Constrained with <code>max_depth=3</code>, <code>min_samples_split=50</code>, <code>min_samples_leaf=25</code></li>
</ul></li>
<li><p><strong>Compare overfitting</strong>: Split data (70/30 train/test) and evaluate both models:</p>
<ul>
<li>Training accuracy vs.&nbsp;test accuracy</li>
<li>Classification report on test data</li>
<li>Tree complexity (depth, number of leaves)</li>
<li>Which model generalizes better?</li>
</ul></li>
<li><p><strong>Understand the imbalance</strong>: This dataset has only ~3% default rate. How does this affect your model’s performance? Look at precision and recall for the “default” class specifically.</p></li>
<li><p><strong>Visualize decision boundaries</strong>: Plot your constrained tree (Model B). What balance threshold appears most important? How does student status affect default predictions?</p></li>
<li><p><strong>Business application</strong>:</p>
<ul>
<li>Write 3 clear business rules from your tree (e.g., “If balance &gt; $X AND student = No, then high risk”)</li>
<li>How would the bank’s risk team use these rules for credit limit decisions?</li>
<li>What are the costs of false positives vs.&nbsp;false negatives in credit default prediction?</li>
</ul></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 3: Stock Market Direction Prediction (Optional Challenge)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Company:</strong> Investment management firm</li>
<li><strong>Goal:</strong> Predict whether the stock market will go up or down based on previous market performance</li>
<li><strong>Dataset:</strong> Weekly dataset from ISLP package</li>
</ul>
<div id="586ace5a" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Weekly stock market data</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>Weekly <span class="op">=</span> load_data(<span class="st">'Weekly'</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare features and target</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert Direction to binary: 1 for Up, 0 for Down</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>Weekly_encoded <span class="op">=</span> Weekly.copy()</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>Weekly_encoded[<span class="st">'Direction_binary'</span>] <span class="op">=</span> (Weekly_encoded[<span class="st">'Direction'</span>] <span class="op">==</span> <span class="st">'Up'</span>).astype(<span class="bu">int</span>)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Use lag variables as features</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>lag_features <span class="op">=</span> [<span class="st">'Lag1'</span>, <span class="st">'Lag2'</span>, <span class="st">'Lag3'</span>, <span class="st">'Lag4'</span>, <span class="st">'Lag5'</span>]</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>X_weekly <span class="op">=</span> Weekly_encoded[lag_features]</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>y_weekly <span class="op">=</span> Weekly_encoded[<span class="st">'Direction_binary'</span>]</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataset size: </span><span class="sc">{</span><span class="bu">len</span>(Weekly)<span class="sc">}</span><span class="ss"> weeks"</span>)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Up weeks: </span><span class="sc">{</span>y_weekly<span class="sc">.</span>mean()<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Lag features:"</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_weekly.head())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset size: 1089 weeks
Up weeks: 55.6%

Lag features:
    Lag1   Lag2   Lag3   Lag4   Lag5
0  0.816  1.572 -3.936 -0.229 -3.484
1 -0.270  0.816  1.572 -3.936 -0.229
2 -2.576 -0.270  0.816  1.572 -3.936
3  3.514 -2.576 -0.270  0.816  1.572
4  0.712  3.514 -2.576 -0.270  0.816</code></pre>
</div>
</div>
<p><strong>Your Tasks:</strong></p>
<ol type="1">
<li><p><strong>Build a market direction classifier</strong>: Create a decision tree to predict whether the market goes up or down based on the 5 lag variables.</p></li>
<li><p><strong>Evaluate predictive power</strong>:</p>
<ul>
<li>Split data chronologically (first 80% train, last 20% test) since this is time-series data</li>
<li>What’s the test accuracy?</li>
<li>How does this compare to always predicting “Up” (the majority class)?</li>
</ul></li>
<li><p><strong>Interpret the tree</strong>: Which lag periods appear most influential? Do the relationships make financial sense?</p></li>
<li><p><strong>Challenge question</strong>: Decision trees struggle with this type of data. Why might financial market prediction be particularly difficult for decision trees? What characteristics of stock market data violate the assumptions that make trees effective?</p></li>
<li><p><strong>Investment strategy</strong>: Based on your tree’s performance, would you recommend using it for actual trading decisions? What would be the financial risks?</p></li>
</ol>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./24-classification-evaluation.html" class="pagination-link" aria-label="Evaluating Classification Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Evaluating Classification Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./26-random-forests.html" class="pagination-link" aria-label="Random Forests: Ensemble Power and Robustness">
        <span class="nav-page-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Random Forests: Ensemble Power and Robustness</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/edit/main/25-decision-trees.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>