{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/bradleyboehmke/uc-bana-4080/blob/main/example-notebooks/26_random_forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests: Ensemble Power and Robustness\n",
    "\n",
    "This notebook contains code examples from the **Random Forests: Ensemble Power and Robustness** chapter (Chapter 26) of the BANA 4080 textbook. Follow along to practice building and tuning random forest models using scikit-learn.\n",
    "\n",
    "## 📚 Chapter Overview\n",
    "\n",
    "Random forests apply the \"wisdom of crowds\" principle to machine learning by combining hundreds of decision trees trained on different samples of data. Through bootstrap sampling and feature randomness, random forests create diverse trees whose errors cancel out when averaged, resulting in models that are more accurate, stable, and robust than individual trees.\n",
    "\n",
    "## 🎯 What You'll Practice\n",
    "\n",
    "- Understand how bootstrap aggregating (bagging) creates diverse decision trees\n",
    "- Implement feature randomness to decorrelate trees and improve performance\n",
    "- Build classification and regression models using `RandomForestClassifier` and `RandomForestRegressor`\n",
    "- Tune key hyperparameters (`n_estimators`, `max_features`, `max_depth`, `min_samples_split/leaf`)\n",
    "- Compare single decision trees vs. bagged trees vs. random forests\n",
    "- Apply random forests to real business problems\n",
    "\n",
    "## 💡 How to Use This Notebook\n",
    "\n",
    "1. **Read the chapter first** - This notebook supplements the textbook, not replaces it\n",
    "2. **Run cells sequentially** - Code builds on previous examples\n",
    "3. **Experiment freely** - Modify code to test your understanding\n",
    "4. **Practice variations** - Try different parameters and datasets to reinforce learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score\n",
    ")\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Instability and the Ensemble Solution\n",
    "\n",
    "Decision trees suffer from **high variance** - small changes in training data can produce dramatically different trees. Random forests solve this problem by combining multiple trees trained on different samples of data. Let's see this instability in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris dataset for demonstration\n",
    "iris = load_iris()\n",
    "X_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y_iris = pd.Series(iris.target)\n",
    "\n",
    "print(f\"Dataset loaded: {len(X_iris)} samples, {len(X_iris.columns)} features\")\n",
    "print(f\"Classes: {', '.join(iris.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate tree instability by training trees on different bootstrap samples\n",
    "n_samples = len(X_iris)\n",
    "n_trees = 3\n",
    "\n",
    "print(\"Training 3 decision trees on different bootstrap samples...\\n\")\n",
    "\n",
    "for i in range(n_trees):\n",
    "    # Create bootstrap sample (random sample WITH replacement)\n",
    "    bootstrap_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    X_bootstrap = X_iris.iloc[bootstrap_indices]\n",
    "    y_bootstrap = y_iris.iloc[bootstrap_indices]\n",
    "    \n",
    "    # Train decision tree on this bootstrap sample\n",
    "    dt = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "    dt.fit(X_bootstrap, y_bootstrap)\n",
    "    \n",
    "    # Get the first split feature\n",
    "    first_split_feature = X_iris.columns[dt.tree_.feature[0]]\n",
    "    first_split_threshold = dt.tree_.threshold[0]\n",
    "    \n",
    "    print(f\"Tree {i+1}:\")\n",
    "    print(f\"  First split: {first_split_feature} <= {first_split_threshold:.2f}\")\n",
    "    print(f\"  Training accuracy: {dt.score(X_bootstrap, y_bootstrap):.3f}\")\n",
    "    print(f\"  Number of unique samples: {len(np.unique(bootstrap_indices))} out of {n_samples}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Observation**: Even though all three trees were trained on the same underlying dataset, they make different first splits because each saw a different bootstrap sample. This instability is a weakness of individual trees that random forests address through averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏃‍♂️ Try It Yourself\n",
    "\n",
    "Modify the code above to:\n",
    "1. Increase `n_trees` to 5 and observe how diverse the first splits become\n",
    "2. Change `max_depth=3` to `max_depth=5` and see if trees become more or less similar\n",
    "3. Set `replace=False` in the bootstrap sampling (creating subsamples instead) - how does this affect tree diversity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experimental code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Ensemble Solution: Combining Multiple Trees\n",
    "\n",
    "The key insight of random forests: while individual trees are unstable and make errors, their **collective wisdom** tends to be more reliable. Let's compare a single tree to an ensemble of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split iris data for fair comparison\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train a single decision tree\n",
    "single_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "single_tree.fit(X_train, y_train)\n",
    "\n",
    "# Train a random forest (ensemble of trees)\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Compare performance\n",
    "print(\"Performance Comparison:\\n\")\n",
    "print(f\"Single Decision Tree:\")\n",
    "print(f\"  Training accuracy: {single_tree.score(X_train, y_train):.3f}\")\n",
    "print(f\"  Test accuracy:     {single_tree.score(X_test, y_test):.3f}\")\n",
    "print()\n",
    "print(f\"Random Forest (100 trees):\")\n",
    "print(f\"  Training accuracy: {random_forest.score(X_train, y_train):.3f}\")\n",
    "print(f\"  Test accuracy:     {random_forest.score(X_test, y_test):.3f}\")\n",
    "print()\n",
    "print(f\"Improvement in test accuracy: {(random_forest.score(X_test, y_test) - single_tree.score(X_test, y_test)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why does this work?** When one tree makes an error, other trees are likely to get it right. By averaging predictions (or voting in classification), individual errors cancel out while the true signal reinforces across all trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏃‍♂️ Try It Yourself\n",
    "\n",
    "Experiment with the number of trees:\n",
    "1. Try `n_estimators=10, 50, 100, 200, 500` and plot how test accuracy changes\n",
    "2. Calculate the overfitting gap (training accuracy - test accuracy) for both models\n",
    "3. Which model generalizes better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Aggregating (Bagging)\n",
    "\n",
    "**Bagging** is the foundation of random forests. It combines **bootstrap sampling** (creating random samples with replacement) with **aggregation** (averaging predictions). Let's understand each component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Bootstrap Sampling\n",
    "\n",
    "Bootstrap sampling creates new datasets by randomly selecting observations **with replacement**. This means:\n",
    "- Some observations appear multiple times\n",
    "- Some observations don't appear at all (~37% are left out)\n",
    "- Each sample has the same size as the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate bootstrap sampling with a simple example\n",
    "original_data = np.arange(1, 21)  # 20 observations numbered 1-20\n",
    "\n",
    "print(\"Original data (20 observations):\")\n",
    "print(original_data)\n",
    "print()\n",
    "\n",
    "# Create 3 bootstrap samples\n",
    "for i in range(3):\n",
    "    bootstrap_sample = np.random.choice(original_data, size=len(original_data), replace=True)\n",
    "    unique_values = np.unique(bootstrap_sample)\n",
    "    missing_values = set(original_data) - set(unique_values)\n",
    "    \n",
    "    print(f\"Bootstrap Sample {i+1}:\")\n",
    "    print(f\"  Unique observations: {len(unique_values)} out of 20\")\n",
    "    print(f\"  Missing observations: {len(missing_values)}\")\n",
    "    print(f\"  Sample: {bootstrap_sample[:10]}... (showing first 10)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight**: Each bootstrap sample is different, which creates the diversity we need for random forests. About 63% of the original observations appear in each sample (some multiple times)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging in Practice: Regression Example\n",
    "\n",
    "Let's build a simple regression example to see how bagging reduces prediction error by averaging multiple trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic regression data (sin wave with noise)\n",
    "np.random.seed(42)\n",
    "X_sin = np.linspace(0, 4*np.pi, 100).reshape(-1, 1)\n",
    "y_sin_true = np.sin(X_sin).ravel()\n",
    "y_sin = y_sin_true + np.random.normal(0, 0.3, len(X_sin))  # Add noise\n",
    "\n",
    "# Create test grid for smooth predictions\n",
    "X_grid = np.linspace(0, 4*np.pi, 300).reshape(-1, 1)\n",
    "y_grid_true = np.sin(X_grid).ravel()\n",
    "\n",
    "print(f\"Training data: {len(X_sin)} points\")\n",
    "print(f\"Test grid: {len(X_grid)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 10 trees on bootstrap samples and average their predictions\n",
    "n_trees = 10\n",
    "predictions = []\n",
    "\n",
    "for i in range(n_trees):\n",
    "    # Create bootstrap sample\n",
    "    indices = np.random.choice(len(X_sin), size=len(X_sin), replace=True)\n",
    "    X_bootstrap = X_sin[indices]\n",
    "    y_bootstrap = y_sin[indices]\n",
    "    \n",
    "    # Train tree on bootstrap sample\n",
    "    tree_model = DecisionTreeRegressor(max_depth=5, random_state=i)\n",
    "    tree_model.fit(X_bootstrap, y_bootstrap)\n",
    "    \n",
    "    # Predict on test grid\n",
    "    y_pred = tree_model.predict(X_grid)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "# Calculate bagged prediction (average of all trees)\n",
    "bagged_prediction = np.mean(predictions, axis=0)\n",
    "\n",
    "# Calculate errors\n",
    "single_tree_mse = mean_squared_error(y_grid_true, predictions[0])\n",
    "bagged_mse = mean_squared_error(y_grid_true, bagged_prediction)\n",
    "\n",
    "print(f\"Single tree MSE: {single_tree_mse:.4f}\")\n",
    "print(f\"Bagged prediction MSE: {bagged_mse:.4f}\")\n",
    "print(f\"Error reduction: {((single_tree_mse - bagged_mse) / single_tree_mse * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why averaging helps**: Individual trees overfit to noise in their specific bootstrap sample. When we average predictions, the noise cancels out while the true signal reinforces!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Power of More Trees\n",
    "\n",
    "As we add more trees, error typically decreases sharply at first, then levels off. Let's visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track error as we add more trees\n",
    "max_trees = 50\n",
    "errors = []\n",
    "all_predictions = []\n",
    "\n",
    "for i in range(max_trees):\n",
    "    # Create bootstrap sample and train tree\n",
    "    indices = np.random.choice(len(X_sin), size=len(X_sin), replace=True)\n",
    "    X_bootstrap = X_sin[indices]\n",
    "    y_bootstrap = y_sin[indices]\n",
    "    \n",
    "    tree_model = DecisionTreeRegressor(max_depth=5, random_state=i)\n",
    "    tree_model.fit(X_bootstrap, y_bootstrap)\n",
    "    \n",
    "    y_pred = tree_model.predict(X_grid)\n",
    "    all_predictions.append(y_pred)\n",
    "    \n",
    "    # Calculate error using average of all trees so far\n",
    "    avg_prediction = np.mean(all_predictions, axis=0)\n",
    "    mse = mean_squared_error(y_grid_true, avg_prediction)\n",
    "    errors.append(mse)\n",
    "\n",
    "# Plot error vs number of trees\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, max_trees + 1), errors, linewidth=2, color='darkblue')\n",
    "plt.axhline(y=errors[-1], color='red', linestyle='--', alpha=0.5, \n",
    "            label=f'Final error with {max_trees} trees')\n",
    "plt.xlabel('Number of Trees', fontsize=11)\n",
    "plt.ylabel('Mean Squared Error', fontsize=11)\n",
    "plt.title('Error Decreases as More Trees Are Added', fontsize=13, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Error with 1 tree:  {errors[0]:.4f}\")\n",
    "print(f\"Error with 10 trees: {errors[9]:.4f} (reduction: {(1 - errors[9]/errors[0])*100:.1f}%)\")\n",
    "print(f\"Error with 50 trees: {errors[49]:.4f} (reduction: {(1 - errors[49]/errors[0])*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Observation**: \n",
    "- Sharp decrease in error with the first 10-15 trees\n",
    "- Diminishing returns after ~20 trees\n",
    "- More trees = more diverse perspectives = better collective wisdom!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏃‍♂️ Try It Yourself\n",
    "\n",
    "Experiment with bagging:\n",
    "1. Modify `max_depth` in the trees (try 3, 7, 10) - how does tree complexity affect bagging benefits?\n",
    "2. Change the noise level in the data (modify `0.3` to `0.1` or `0.5`) - does bagging help more with noisier data?\n",
    "3. Track how many unique training samples each bootstrap contains on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experimental code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Randomness: The Key Innovation\n",
    "\n",
    "Bagging alone creates diversity through bootstrap sampling. But random forests add **one more crucial source of randomness**: at each split, only consider a random subset of features. This simple change dramatically improves performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Feature Randomness Works\n",
    "\n",
    "For a dataset with *p* features, at each node:\n",
    "1. Randomly select a subset of features (typically √p for classification, p/3 for regression)\n",
    "2. Find the best split using **only** these randomly selected features\n",
    "3. Repeat this at every node in every tree\n",
    "\n",
    "This means different trees split on different features, making their predictions more independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset to demonstrate feature randomness\n",
    "# We'll use the iris dataset which has 4 features\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X_iris_demo = iris.data\n",
    "y_iris_demo = iris.target\n",
    "\n",
    "n_features = X_iris_demo.shape[1]\n",
    "print(f\"Dataset has {n_features} features\")\n",
    "print(f\"Feature names: {iris.feature_names}\")\n",
    "print()\n",
    "print(f\"For classification, typical max_features = √{n_features} = {int(np.sqrt(n_features))}\")\n",
    "print(f\"For regression, typical max_features = {n_features}/3 = {n_features // 3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Bagged Trees vs. Random Forests\n",
    "\n",
    "Let's compare:\n",
    "- **Bagged Trees**: Bootstrap sampling + ALL features at each split\n",
    "- **Random Forest**: Bootstrap sampling + RANDOM SUBSET of features at each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual implementation to show the difference\n",
    "# We'll use a regression example for clearer error metrics\n",
    "\n",
    "# Create regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "X_reg, y_reg = make_regression(n_samples=200, n_features=10, n_informative=8, \n",
    "                               noise=10, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train_reg)}\")\n",
    "print(f\"Features: {X_train_reg.shape[1]}\")\n",
    "print(f\"\\nWe'll compare bagging with all features vs. random forests with feature randomness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build bagged trees (all features at each split)\n",
    "n_trees = 100\n",
    "bagged_predictions = []\n",
    "\n",
    "for i in range(n_trees):\n",
    "    # Bootstrap sample\n",
    "    indices = np.random.choice(len(X_train_reg), size=len(X_train_reg), replace=True)\n",
    "    X_bootstrap = X_train_reg[indices]\n",
    "    y_bootstrap = y_train_reg[indices]\n",
    "    \n",
    "    # Train tree with ALL features (max_features=None)\n",
    "    tree = DecisionTreeRegressor(max_features=None, min_samples_split=10, \n",
    "                                 min_samples_leaf=4, random_state=i)\n",
    "    tree.fit(X_bootstrap, y_bootstrap)\n",
    "    \n",
    "    # Predict\n",
    "    bagged_predictions.append(tree.predict(X_test_reg))\n",
    "\n",
    "# Average predictions\n",
    "bagged_avg = np.mean(bagged_predictions, axis=0)\n",
    "bagged_mse = mean_squared_error(y_test_reg, bagged_avg)\n",
    "\n",
    "print(f\"Bagged Trees (all features):\")\n",
    "print(f\"  Test MSE: {bagged_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build random forest (random subset of features at each split)\n",
    "rf_predictions = []\n",
    "max_features = X_train_reg.shape[1] // 3  # p/3 for regression\n",
    "\n",
    "for i in range(n_trees):\n",
    "    # Bootstrap sample\n",
    "    indices = np.random.choice(len(X_train_reg), size=len(X_train_reg), replace=True)\n",
    "    X_bootstrap = X_train_reg[indices]\n",
    "    y_bootstrap = y_train_reg[indices]\n",
    "    \n",
    "    # Train tree with RANDOM SUBSET of features\n",
    "    tree = DecisionTreeRegressor(max_features=max_features, min_samples_split=10,\n",
    "                                 min_samples_leaf=4, random_state=i)\n",
    "    tree.fit(X_bootstrap, y_bootstrap)\n",
    "    \n",
    "    # Predict\n",
    "    rf_predictions.append(tree.predict(X_test_reg))\n",
    "\n",
    "# Average predictions\n",
    "rf_avg = np.mean(rf_predictions, axis=0)\n",
    "rf_mse = mean_squared_error(y_test_reg, rf_avg)\n",
    "\n",
    "print(f\"Random Forest (max_features={max_features}):\")\n",
    "print(f\"  Test MSE: {rf_mse:.2f}\")\n",
    "print()\n",
    "print(f\"Improvement from feature randomness: {((bagged_mse - rf_mse) / bagged_mse * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why does feature randomness help?**\n",
    "\n",
    "- **Decorrelates trees**: Forces trees to explore different feature combinations\n",
    "- **Prevents feature dominance**: Strong features don't control every tree\n",
    "- **Discovers hidden patterns**: Weaker features get a chance to contribute\n",
    "- **More independent errors**: When averaged, errors cancel out more effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Scikit-learn's Built-in Random Forest\n",
    "\n",
    "In practice, we use scikit-learn's `RandomForestClassifier` and `RandomForestRegressor` which handle all the bootstrapping and feature randomness automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare using scikit-learn's implementations\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Bagged trees using BaggingRegressor (all features)\n",
    "bagging_model = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(min_samples_split=10, min_samples_leaf=4),\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "bagging_model.fit(X_train_reg, y_train_reg)\n",
    "bagging_score = bagging_model.score(X_test_reg, y_test_reg)\n",
    "\n",
    "# Random forest (feature randomness)\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_features=X_train_reg.shape[1] // 3,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_reg, y_train_reg)\n",
    "rf_score = rf_model.score(X_test_reg, y_test_reg)\n",
    "\n",
    "print(\"Scikit-learn Comparison:\")\n",
    "print(f\"Bagging (all features):     R² = {bagging_score:.4f}\")\n",
    "print(f\"Random Forest (p/3 features): R² = {rf_score:.4f}\")\n",
    "print(f\"\\nRandom forest performs better by decorrelating the trees!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏃‍♂️ Try It Yourself\n",
    "\n",
    "Experiment with feature randomness:\n",
    "1. Try different `max_features` values (1, 3, 5, 10, None) and see how performance changes\n",
    "2. Create a dataset where one feature is much stronger than others - does feature randomness help more?\n",
    "3. Compare the predictions from bagged trees vs random forests - are they more different than you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experimental code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Random Forest Models\n",
    "\n",
    "Now that we understand how random forests work conceptually, let's build models for real problems. We'll use scikit-learn's `RandomForestClassifier` for classification and `RandomForestRegressor` for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Random Forests\n",
    "\n",
    "Let's build a credit default classifier using a real dataset. We'll predict whether customers will default on their credit card payments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Default dataset from ISLP\n",
    "try:\n",
    "    from ISLP import load_data\n",
    "    Default = load_data('Default')\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_default = pd.get_dummies(Default[['balance', 'income', 'student']], drop_first=True)\n",
    "    y_default = (Default['default'] == 'Yes').astype(int)\n",
    "    \n",
    "    print(\"✅ ISLP dataset loaded successfully!\")\n",
    "    print(f\"Dataset size: {len(Default)} customers\")\n",
    "    print(f\"Default rate: {y_default.mean():.1%}\")\n",
    "    print(f\"\\nFeatures: {list(X_default.columns)}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠️ ISLP package not available. Using synthetic data instead.\")\n",
    "    print(\"To install ISLP: pip install ISLP\")\n",
    "    \n",
    "    # Create synthetic default data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "    \n",
    "    balance = np.random.gamma(2, 500, n_samples)\n",
    "    income = np.random.normal(45000, 15000, n_samples)\n",
    "    student = np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
    "    \n",
    "    # Default probability increases with balance\n",
    "    default_prob = 1 / (1 + np.exp(-(balance/1000 - 2)))\n",
    "    y_default = (np.random.random(n_samples) < default_prob).astype(int)\n",
    "    \n",
    "    X_default = pd.DataFrame({\n",
    "        'balance': balance,\n",
    "        'income': income,\n",
    "        'student_Yes': student\n",
    "    })\n",
    "    \n",
    "    print(f\"Synthetic dataset created: {len(X_default)} samples\")\n",
    "    print(f\"Default rate: {y_default.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_default, X_test_default, y_train_default, y_test_default = train_test_split(\n",
    "    X_default, y_default, test_size=0.3, random_state=42, stratify=y_default\n",
    ")\n",
    "\n",
    "# Build random forest classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    max_features='sqrt',   # √p features at each split (good for classification)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_classifier.fit(X_train_default, y_train_default)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_default = rf_classifier.predict(X_test_default)\n",
    "y_pred_proba = rf_classifier.predict_proba(X_test_default)[:, 1]  # Probability of default\n",
    "\n",
    "print(\"Random Forest Classifier trained successfully!\")\n",
    "print(f\"\\nModel contains {rf_classifier.n_estimators} trees\")\n",
    "print(f\"Each tree considers {rf_classifier.max_features} features at each split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classification performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_accuracy = rf_classifier.score(X_train_default, y_train_default)\n",
    "test_accuracy = rf_classifier.score(X_test_default, y_test_default)\n",
    "\n",
    "print(\"Classification Performance:\")\n",
    "print(f\"Training accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Test accuracy:     {test_accuracy:.3f}\")\n",
    "print(f\"Overfitting gap:   {(train_accuracy - test_accuracy):.3f}\")\n",
    "print()\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test_default, y_pred_default)\n",
    "print(cm)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_default, y_pred_default, \n",
    "                          target_names=['No Default', 'Default']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How Classification Predictions Work: Majority Voting**\n",
    "\n",
    "Random forests make classification predictions through **majority voting**:\n",
    "1. Each of the 100 trees independently predicts a class (0 or 1)\n",
    "2. Count how many trees predict each class\n",
    "3. The class with the most votes wins\n",
    "4. Predicted probability = proportion of votes (e.g., 73/100 = 0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate voting mechanism for a single prediction\n",
    "sample_idx = 0\n",
    "sample_features = X_test_default.iloc[sample_idx:sample_idx+1]\n",
    "\n",
    "# Get predictions from all individual trees\n",
    "tree_predictions = []\n",
    "for tree in rf_classifier.estimators_:\n",
    "    pred = tree.predict(sample_features)[0]\n",
    "    tree_predictions.append(pred)\n",
    "\n",
    "# Count votes\n",
    "votes_for_default = sum(tree_predictions)\n",
    "votes_for_no_default = len(tree_predictions) - votes_for_default\n",
    "\n",
    "print(f\"Example prediction for sample {sample_idx}:\")\n",
    "print(f\"  Votes for 'No Default' (0): {votes_for_no_default}\")\n",
    "print(f\"  Votes for 'Default' (1):    {votes_for_default}\")\n",
    "print(f\"  Final prediction: {rf_classifier.predict(sample_features)[0]}\")\n",
    "print(f\"  Predicted probability of default: {votes_for_default/len(tree_predictions):.3f}\")\n",
    "print(f\"  Actual label: {y_test_default.iloc[sample_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with Random Forests\n",
    "\n",
    "Now let's build a regression model to predict house prices using the Ames housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Ames housing data\n",
    "try:\n",
    "    ames = pd.read_csv('https://raw.githubusercontent.com/bradleyboehmke/uc-bana-4080/main/data/ames_clean.csv')\n",
    "    \n",
    "    # Select numeric features\n",
    "    numeric_features = ames.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_features.remove('SalePrice')\n",
    "    \n",
    "    X_ames = ames[numeric_features]\n",
    "    y_ames = ames['SalePrice']\n",
    "    \n",
    "    print(\"✅ Ames housing data loaded successfully!\")\n",
    "    print(f\"Dataset size: {len(ames)} homes\")\n",
    "    print(f\"Number of features: {len(numeric_features)}\")\n",
    "    print(f\"Price range: ${y_ames.min():,.0f} - ${y_ames.max():,.0f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not load Ames data: {e}\")\n",
    "    print(\"Using synthetic housing data instead.\")\n",
    "    \n",
    "    # Create synthetic housing data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    X_ames = pd.DataFrame({\n",
    "        'GrLivArea': np.random.normal(1500, 500, n_samples),\n",
    "        'OverallQual': np.random.randint(1, 11, n_samples),\n",
    "        'YearBuilt': np.random.randint(1900, 2020, n_samples),\n",
    "        'TotalBsmtSF': np.random.normal(1000, 400, n_samples),\n",
    "        'GarageArea': np.random.normal(500, 200, n_samples)\n",
    "    })\n",
    "    \n",
    "    # Price based on features\n",
    "    y_ames = (100 * X_ames['GrLivArea'] + \n",
    "              10000 * X_ames['OverallQual'] + \n",
    "              50 * X_ames['YearBuilt'] +\n",
    "              np.random.normal(0, 20000, n_samples))\n",
    "    \n",
    "    print(f\"Synthetic dataset created: {len(X_ames)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_ames, X_test_ames, y_train_ames, y_test_ames = train_test_split(\n",
    "    X_ames, y_ames, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Build random forest regressor\n",
    "rf_regressor = RandomForestRegressor(\n",
    "    n_estimators=100,                    # Number of trees\n",
    "    max_features=X_train_ames.shape[1]//3,  # p/3 features at each split (good for regression)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_regressor.fit(X_train_ames, y_train_ames)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = rf_regressor.predict(X_train_ames)\n",
    "y_pred_test = rf_regressor.predict(X_test_ames)\n",
    "\n",
    "print(\"Random Forest Regressor trained successfully!\")\n",
    "print(f\"\\nModel contains {rf_regressor.n_estimators} trees\")\n",
    "print(f\"Each tree considers {rf_regressor.max_features} features at each split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate regression performance\n",
    "train_r2 = r2_score(y_train_ames, y_pred_train)\n",
    "test_r2 = r2_score(y_test_ames, y_pred_test)\n",
    "test_mae = mean_absolute_error(y_test_ames, y_pred_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_ames, y_pred_test))\n",
    "\n",
    "print(\"Regression Performance:\")\n",
    "print(f\"Training R²: {train_r2:.3f}\")\n",
    "print(f\"Test R²:     {test_r2:.3f}\")\n",
    "print(f\"Overfitting gap: {(train_r2 - test_r2):.3f}\")\n",
    "print()\n",
    "print(f\"Test MAE:  ${test_mae:,.0f}\")\n",
    "print(f\"Test RMSE: ${test_rmse:,.0f}\")\n",
    "print(f\"RMSE as % of mean price: {(test_rmse / y_test_ames.mean() * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How Regression Predictions Work: Averaging**\n",
    "\n",
    "Random forests make regression predictions through **averaging**:\n",
    "1. Each of the 100 trees independently predicts a numeric value\n",
    "2. Calculate the mean: (tree₁ + tree₂ + ... + tree₁₀₀) / 100\n",
    "3. This average becomes the final prediction\n",
    "\n",
    "This averaging smooths out individual tree errors and produces more stable predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate averaging mechanism for a single prediction\n",
    "sample_idx = 0\n",
    "sample_features = X_test_ames.iloc[sample_idx:sample_idx+1]\n",
    "\n",
    "# Get predictions from all individual trees\n",
    "tree_predictions = []\n",
    "for tree in rf_regressor.estimators_:\n",
    "    pred = tree.predict(sample_features)[0]\n",
    "    tree_predictions.append(pred)\n",
    "\n",
    "print(f\"Example prediction for house {sample_idx}:\")\n",
    "print(f\"  Individual tree predictions range: ${min(tree_predictions):,.0f} - ${max(tree_predictions):,.0f}\")\n",
    "print(f\"  Standard deviation of predictions: ${np.std(tree_predictions):,.0f}\")\n",
    "print(f\"  Average (final prediction): ${np.mean(tree_predictions):,.0f}\")\n",
    "print(f\"  Actual price: ${y_test_ames.iloc[sample_idx]:,.0f}\")\n",
    "print(f\"  Prediction error: ${abs(np.mean(tree_predictions) - y_test_ames.iloc[sample_idx]):,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏃‍♂️ Try It Yourself\n",
    "\n",
    "Experiment with random forest models:\n",
    "1. **Classification**: Change `max_features` to different values ('sqrt', 'log2', None) - how does it affect accuracy?\n",
    "2. **Regression**: Try different numbers of trees (10, 50, 100, 200) - plot how RMSE changes\n",
    "3. **Compare**: Build a single decision tree and compare its performance to the random forest\n",
    "4. **Prediction variance**: For the regression example, examine how much individual tree predictions vary for different houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experimental code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Random forests have several important hyperparameters that control model complexity and performance. Let's explore the most critical ones and see how they impact results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Hyperparameters Overview\n",
    "\n",
    "| Parameter | Purpose | Typical Values |\n",
    "|-----------|---------|----------------|\n",
    "| `n_estimators` | Number of trees | 100-500 |\n",
    "| `max_features` | Features per split | 'sqrt' (classification), p/3 (regression) |\n",
    "| `max_depth` | Maximum tree depth | None (no limit) or 10-20 |\n",
    "| `min_samples_split` | Min samples to split node | 2-20 |\n",
    "| `min_samples_leaf` | Min samples in leaf | 1-10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. n_estimators: Number of Trees\n",
    "\n",
    "More trees generally improve performance, but with diminishing returns. Let's visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different numbers of trees\n",
    "tree_counts = [1, 5, 10, 25, 50, 100, 200, 300]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for n_trees in tree_counts:\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees, max_features='sqrt', random_state=42)\n",
    "    rf.fit(X_train_ames, y_train_ames)\n",
    "    \n",
    "    train_scores.append(rf.score(X_train_ames, y_train_ames))\n",
    "    test_scores.append(rf.score(X_test_ames, y_test_ames))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(tree_counts, train_scores, 'o-', label='Training R²', linewidth=2)\n",
    "plt.plot(tree_counts, test_scores, 's-', label='Test R²', linewidth=2)\n",
    "plt.xlabel('Number of Trees (n_estimators)', fontsize=11)\n",
    "plt.ylabel('R² Score', fontsize=11)\n",
    "plt.title('Impact of Number of Trees on Performance', fontsize=13, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Test R² with 10 trees:  {test_scores[2]:.4f}\")\n",
    "print(f\"Test R² with 100 trees: {test_scores[5]:.4f}\")\n",
    "print(f\"Test R² with 300 trees: {test_scores[7]:.4f}\")\n",
    "print(f\"\\nImprovement from 10 to 100: {((test_scores[5] - test_scores[2])/test_scores[2]*100):.1f}%\")\n",
    "print(f\"Improvement from 100 to 300: {((test_scores[7] - test_scores[5])/test_scores[5]*100):.1f}%\")\n",
    "print(\"\\n📊 Notice: Sharp improvement initially, then diminishing returns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. max_features: Features Considered at Each Split\n",
    "\n",
    "This parameter controls tree diversity! Lower values = more diverse trees = better averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different max_features settings\n",
    "n_features = X_train_ames.shape[1]\n",
    "max_features_options = [1, int(np.sqrt(n_features)), n_features // 3, \n",
    "                       n_features // 2, n_features]\n",
    "feature_labels = ['1', f'√p ({int(np.sqrt(n_features))})', \n",
    "                 f'p/3 ({n_features // 3})',\n",
    "                 f'p/2 ({n_features // 2})', \n",
    "                 f'All ({n_features})']\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for max_feat in max_features_options:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_features=max_feat, random_state=42)\n",
    "    rf.fit(X_train_ames, y_train_ames)\n",
    "    \n",
    "    train_scores.append(rf.score(X_train_ames, y_train_ames))\n",
    "    test_scores.append(rf.score(X_test_ames, y_test_ames))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "x_pos = np.arange(len(max_features_options))\n",
    "plt.plot(x_pos, train_scores, 'o-', label='Training R²', linewidth=2, markersize=8)\n",
    "plt.plot(x_pos, test_scores, 's-', label='Test R²', linewidth=2, markersize=8)\n",
    "plt.xticks(x_pos, feature_labels, rotation=15)\n",
    "plt.xlabel('Features per Split (max_features)', fontsize=11)\n",
    "plt.ylabel('R² Score', fontsize=11)\n",
    "plt.title('Impact of Feature Randomness on Performance', fontsize=13, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_idx = np.argmax(test_scores)\n",
    "print(f\"Best test R² achieved with max_features = {feature_labels[best_idx]}\")\n",
    "print(f\"Best R²: {test_scores[best_idx]:.4f}\")\n",
    "print(\"\\n📊 Notice: Too few features = underfitting, all features = less diversity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. max_depth: Maximum Tree Depth\n",
    "\n",
    "Controls how deep individual trees can grow. Random forests can handle deeper trees than single trees because ensemble averaging reduces overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different maximum depths\n",
    "depths = [3, 5, 10, 15, 20, None]  # None = no limit\n",
    "depth_labels = ['3', '5', '10', '15', '20', 'No Limit']\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=depth, \n",
    "                               max_features='sqrt', random_state=42)\n",
    "    rf.fit(X_train_ames, y_train_ames)\n",
    "    \n",
    "    train_scores.append(rf.score(X_train_ames, y_train_ames))\n",
    "    test_scores.append(rf.score(X_test_ames, y_test_ames))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "x_pos = np.arange(len(depths))\n",
    "plt.plot(x_pos, train_scores, 'o-', label='Training R²', linewidth=2, markersize=8)\n",
    "plt.plot(x_pos, test_scores, 's-', label='Test R²', linewidth=2, markersize=8)\n",
    "plt.xticks(x_pos, depth_labels)\n",
    "plt.xlabel('Maximum Tree Depth (max_depth)', fontsize=11)\n",
    "plt.ylabel('R² Score', fontsize=11)\n",
    "plt.title('Impact of Tree Depth on Performance', fontsize=13, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_idx = np.argmax(test_scores)\n",
    "print(f\"Best test R² with max_depth = {depth_labels[best_idx]}\")\n",
    "print(f\"Best R²: {test_scores[best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Default vs. Tuned Models\n",
    "\n",
    "Let's compare a random forest with default parameters to one with carefully tuned hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default random forest\n",
    "rf_default = RandomForestRegressor(random_state=42)\n",
    "rf_default.fit(X_train_ames, y_train_ames)\n",
    "\n",
    "y_pred_default = rf_default.predict(X_test_ames)\n",
    "default_r2 = r2_score(y_test_ames, y_pred_default)\n",
    "default_rmse = np.sqrt(mean_squared_error(y_test_ames, y_pred_default))\n",
    "\n",
    "print(\"Default Random Forest:\")\n",
    "print(f\"  n_estimators: {rf_default.n_estimators}\")\n",
    "print(f\"  max_features: {rf_default.max_features}\")\n",
    "print(f\"  max_depth: {rf_default.max_depth}\")\n",
    "print(f\"  Test R²: {default_r2:.4f}\")\n",
    "print(f\"  Test RMSE: ${default_rmse:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned random forest\n",
    "rf_tuned = RandomForestRegressor(\n",
    "    n_estimators=200,                      # More trees\n",
    "    max_features=X_train_ames.shape[1]//3, # p/3 for regression\n",
    "    max_depth=20,                          # Limit depth\n",
    "    min_samples_split=5,                   # Require more samples to split\n",
    "    min_samples_leaf=2,                    # Require more samples in leaves\n",
    "    random_state=42\n",
    ")\n",
    "rf_tuned.fit(X_train_ames, y_train_ames)\n",
    "\n",
    "y_pred_tuned = rf_tuned.predict(X_test_ames)\n",
    "tuned_r2 = r2_score(y_test_ames, y_pred_tuned)\n",
    "tuned_rmse = np.sqrt(mean_squared_error(y_test_ames, y_pred_tuned))\n",
    "\n",
    "print(\"\\nTuned Random Forest:\")\n",
    "print(f\"  n_estimators: {rf_tuned.n_estimators}\")\n",
    "print(f\"  max_features: {rf_tuned.max_features}\")\n",
    "print(f\"  max_depth: {rf_tuned.max_depth}\")\n",
    "print(f\"  Test R²: {tuned_r2:.4f}\")\n",
    "print(f\"  Test RMSE: ${tuned_rmse:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two models\n",
    "improvement_r2 = ((tuned_r2 - default_r2) / default_r2) * 100\n",
    "improvement_rmse = ((default_rmse - tuned_rmse) / default_rmse) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Performance Comparison\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Default R²:  {default_r2:.4f}\")\n",
    "print(f\"Tuned R²:    {tuned_r2:.4f}\")\n",
    "print(f\"R² improvement: {improvement_r2:.1f}%\")\n",
    "print()\n",
    "print(f\"Default RMSE:  ${default_rmse:,.0f}\")\n",
    "print(f\"Tuned RMSE:    ${tuned_rmse:,.0f}\")\n",
    "print(f\"RMSE improvement: {improvement_rmse:.1f}%\")\n",
    "print(\"\\n💡 Key Insight: Random forests work well out-of-the-box,\")\n",
    "print(\"   but tuning can squeeze out additional performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏃‍♂️ Try It Yourself\n",
    "\n",
    "Experiment with hyperparameter tuning:\n",
    "1. Test `min_samples_split` values (2, 5, 10, 20, 50) - how does it affect overfitting?\n",
    "2. Try combining different parameters - what's your best combination?\n",
    "3. Use the classification dataset (Default) and tune hyperparameters for best precision/recall balance\n",
    "4. Create a small grid search: test all combinations of `n_estimators=[50, 100, 200]` and `max_depth=[10, 20, None]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experimental code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Chapter Exercises\n",
    "\n",
    "For these exercises, you'll compare decision trees to random forests across real business scenarios. Each exercise will help you understand how ensemble methods improve upon individual trees and how hyperparameter tuning can further enhance performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Baseball Salary Prediction (Regression)\n",
    "\n",
    "**Company:** Professional baseball team  \n",
    "**Goal:** Improve salary predictions by comparing individual decision trees to random forest ensembles  \n",
    "**Dataset:** Hitters dataset from ISLP package\n",
    "\n",
    "**Your Tasks:**\n",
    "\n",
    "1. **Build three models and compare performance:**\n",
    "   - **Model A:** `DecisionTreeRegressor` with `max_depth=4`\n",
    "   - **Model B:** `RandomForestRegressor` with default parameters\n",
    "   - **Model C:** `RandomForestRegressor` with tuned parameters (try `n_estimators=200`, `max_depth=6`, `min_samples_split=10`)\n",
    "\n",
    "2. **Evaluate and compare:** Split data (70/30 train/test) and for each model calculate:\n",
    "   - Training R² and test R²\n",
    "   - Mean Absolute Error on test set\n",
    "   - Root Mean Squared Error on test set\n",
    "   - Overfitting gap (training R² - test R²)\n",
    "\n",
    "3. **Performance analysis:**\n",
    "   - Which model generalizes best to the test set?\n",
    "   - How much improvement did the default random forest provide over the single tree?\n",
    "   - Did tuning the hyperparameters further improve performance?\n",
    "\n",
    "4. **Trade-offs:**\n",
    "   - Compare model interpretability: Can you still extract clear business rules from the random forest?\n",
    "   - Consider computational cost: How much longer did the random forest take to train?\n",
    "   - Which model would you recommend to the team's management? Why?\n",
    "\n",
    "5. **Business reflection:**\n",
    "   - How confident would you be using each model for actual salary negotiations?\n",
    "   - What are the risks of relying on the more complex random forest vs. the simpler tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the Hitters data\n",
    "from ISLP import load_data\n",
    "\n",
    "Hitters = load_data('Hitters')\n",
    "\n",
    "# Remove missing salary values\n",
    "Hitters_clean = Hitters.dropna(subset=['Salary'])\n",
    "\n",
    "# Select numeric features for our models\n",
    "features = ['Years', 'Hits', 'RBI', 'Walks', 'PutOuts']\n",
    "X_hitters = Hitters_clean[features]\n",
    "y_hitters = Hitters_clean['Salary']\n",
    "\n",
    "print(f\"Dataset size: {len(Hitters_clean)} players\")\n",
    "print(f\"Features used: {features}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(Hitters_clean[features + ['Salary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 1 here\n",
    "# Build Model A: DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Build Model B: RandomForestRegressor with default parameters\n",
    "\n",
    "\n",
    "# Build Model C: RandomForestRegressor with tuned parameters\n",
    "\n",
    "\n",
    "# Evaluate and compare all three models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Credit Default Classification\n",
    "\n",
    "**Company:** Regional bank  \n",
    "**Goal:** Improve default prediction accuracy while understanding the performance gains from ensemble methods  \n",
    "**Dataset:** Default dataset from ISLP package\n",
    "\n",
    "**Your Tasks:**\n",
    "\n",
    "1. **Build and compare three classification models:**\n",
    "   - **Model A:** `DecisionTreeClassifier` with `max_depth=3`, `min_samples_split=50`\n",
    "   - **Model B:** `RandomForestClassifier` with default parameters\n",
    "   - **Model C:** `RandomForestClassifier` with tuned parameters (try `n_estimators=200`, `max_depth=10`, `min_samples_split=20`, `max_features='sqrt'`)\n",
    "\n",
    "2. **Evaluate on the imbalanced data:** Split data (70/30) and for each model examine:\n",
    "   - Training vs. test accuracy\n",
    "   - Precision and recall for the \"default\" class specifically\n",
    "   - Confusion matrix on test set\n",
    "   - Which model has the best balance of precision and recall?\n",
    "\n",
    "3. **Understand the ensemble advantage:**\n",
    "   - Calculate the overfitting gap for each model\n",
    "   - How did random forests reduce overfitting compared to the single tree?\n",
    "   - Did the tuned random forest improve further on precision/recall for defaults?\n",
    "\n",
    "4. **Feature importance (Random Forest only):**\n",
    "   - Use `.feature_importances_` on your best random forest model\n",
    "   - Which feature is most important for predicting defaults?\n",
    "   - How does this align with business intuition?\n",
    "\n",
    "5. **Business application:**\n",
    "   - The bank loses $10,000 on each default but gains $500 in interest from good customers\n",
    "   - Using the confusion matrices, calculate the expected profit/loss for each model\n",
    "   - Which model would you deploy in production? Why?\n",
    "   - What threshold adjustments might you make given the cost structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the Default dataset\n",
    "Default = load_data('Default')\n",
    "\n",
    "# Prepare features - encode student as binary\n",
    "Default_encoded = pd.get_dummies(Default, columns=['student'], drop_first=True)\n",
    "Default_encoded['default_binary'] = (Default_encoded['default'] == 'Yes').astype(int)\n",
    "\n",
    "# Select features\n",
    "X_default = Default_encoded[['balance', 'income', 'student_Yes']]\n",
    "y_default = Default_encoded['default_binary']\n",
    "\n",
    "print(f\"Dataset size: {len(Default)} customers\")\n",
    "print(f\"Default rate: {y_default.mean():.1%}\")\n",
    "print(f\"\\nFeatures prepared:\")\n",
    "print(X_default.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 2 here\n",
    "# Build Model A: DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Build Model B: RandomForestClassifier with default parameters\n",
    "\n",
    "\n",
    "# Build Model C: RandomForestClassifier with tuned parameters\n",
    "\n",
    "\n",
    "# Evaluate and compare all three models\n",
    "\n",
    "\n",
    "# Calculate feature importance for best model\n",
    "\n",
    "\n",
    "# Calculate expected profit/loss for each model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Stock Market Direction Prediction (Optional Challenge)\n",
    "\n",
    "**Company:** Investment management firm  \n",
    "**Goal:** Test whether random forests can capture market patterns better than single decision trees  \n",
    "**Dataset:** Weekly dataset from ISLP package\n",
    "\n",
    "**Your Tasks:**\n",
    "\n",
    "1. **Build three models for market prediction:**\n",
    "   - **Model A:** `DecisionTreeClassifier` with `max_depth=3`\n",
    "   - **Model B:** `RandomForestClassifier` with default parameters\n",
    "   - **Model C:** `RandomForestClassifier` with tuned parameters of your choice\n",
    "\n",
    "2. **Time-series evaluation:**\n",
    "   - Split data chronologically (first 80% train, last 20% test)\n",
    "   - Calculate test accuracy for each model\n",
    "   - Compare to baseline: what's the accuracy of always predicting \"Up\"?\n",
    "\n",
    "3. **Performance comparison:**\n",
    "   - Did random forests improve over the single tree?\n",
    "   - Are any of the models beating the baseline?\n",
    "   - What does this tell you about market predictability?\n",
    "\n",
    "4. **Feature importance analysis:**\n",
    "   - Examine feature importance from your best random forest\n",
    "   - Which lag periods matter most?\n",
    "   - Do these patterns make financial sense?\n",
    "\n",
    "5. **Challenge questions:**\n",
    "   - Why might even random forests struggle with financial market prediction?\n",
    "   - What characteristics of stock market data make it fundamentally difficult for tree-based methods?\n",
    "   - Would you recommend using any of these models for actual trading? What would be the risks?\n",
    "   - How might you modify the approach to make it more suitable for financial prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the Weekly stock market data\n",
    "Weekly = load_data('Weekly')\n",
    "\n",
    "# Prepare features and target\n",
    "Weekly_encoded = Weekly.copy()\n",
    "Weekly_encoded['Direction_binary'] = (Weekly_encoded['Direction'] == 'Up').astype(int)\n",
    "\n",
    "# Use lag variables as features\n",
    "lag_features = ['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5']\n",
    "X_weekly = Weekly_encoded[lag_features]\n",
    "y_weekly = Weekly_encoded['Direction_binary']\n",
    "\n",
    "print(f\"Dataset size: {len(Weekly)} weeks\")\n",
    "print(f\"Up weeks: {y_weekly.mean():.1%}\")\n",
    "print(f\"\\nLag features:\")\n",
    "print(X_weekly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 3 here\n",
    "# Build Model A: DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Build Model B: RandomForestClassifier with default parameters\n",
    "\n",
    "\n",
    "# Build Model C: RandomForestClassifier with tuned parameters\n",
    "\n",
    "\n",
    "# Perform time-series split and evaluation\n",
    "\n",
    "\n",
    "# Calculate baseline accuracy\n",
    "\n",
    "\n",
    "# Feature importance analysis\n",
    "\n",
    "\n",
    "# Answer challenge questions in markdown cell below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📝 Chapter Summary\n",
    "\n",
    "Congratulations on completing the Random Forests chapter! Here's what you've learned:\n",
    "\n",
    "### 🎯 Core Concepts\n",
    "\n",
    "**Random forests transform the instability of individual decision trees into a strength** by combining hundreds of trees trained on different data samples. The key insight: while any single tree might overfit or make errors, the collective wisdom of diverse trees averages out mistakes, producing accurate and stable predictions.\n",
    "\n",
    "### 🔑 Key Mechanisms\n",
    "\n",
    "Random forests create diversity through two mechanisms:\n",
    "\n",
    "1. **Bootstrap Aggregating (Bagging)**: Each tree trains on a random sample with replacement\n",
    "2. **Feature Randomness**: Each split considers only a random subset of features\n",
    "   - Typically √p for classification\n",
    "   - Typically p/3 for regression\n",
    "\n",
    "These mechanisms decorrelate trees and prevent dominant features from controlling the forest.\n",
    "\n",
    "### 🤖 How Predictions Work\n",
    "\n",
    "- **Classification**: Majority voting across all trees\n",
    "  - Each tree votes for a class\n",
    "  - The class with most votes wins\n",
    "  - Predicted probability = proportion of votes\n",
    "  \n",
    "- **Regression**: Averaging across all trees\n",
    "  - Each tree predicts a numeric value\n",
    "  - Average becomes the final prediction\n",
    "  - Smooths out individual tree errors\n",
    "\n",
    "### ⚙️ Key Hyperparameters\n",
    "\n",
    "| Parameter | Purpose | Typical Values |\n",
    "|-----------|---------|----------------|\n",
    "| `n_estimators` | Number of trees | 100-500 |\n",
    "| `max_features` | Features per split | 'sqrt' (classification), p/3 (regression) |\n",
    "| `max_depth` | Maximum tree depth | None (no limit) or 10-20 |\n",
    "| `min_samples_split` | Min samples to split | 2-20 |\n",
    "| `min_samples_leaf` | Min samples in leaf | 1-10 |\n",
    "\n",
    "### 💡 Important Insights\n",
    "\n",
    "- **Out-of-the-box effectiveness**: Random forests work remarkably well with default settings, requiring minimal tuning\n",
    "- **Robust to overfitting**: Ensemble averaging makes them more stable than single trees\n",
    "- **Business applications**: Credit risk, fraud detection, customer churn, predictive maintenance, and more\n",
    "- **Trade-offs**: Better performance but less interpretable than single trees\n",
    "\n",
    "### 🚀 Next Steps\n",
    "\n",
    "In the next chapter, you'll explore **feature importance**—a built-in mechanism for quantifying each feature's contribution to predictions and identifying the key drivers behind your outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎓 Key Takeaways for Practice\n",
    "\n",
    "1. **Start with defaults**: Random forests perform well without extensive tuning\n",
    "2. **More trees ≈ better performance**: But with diminishing returns after 100-200 trees\n",
    "3. **Feature randomness matters**: Don't skip `max_features` tuning for best results\n",
    "4. **Balance interpretability vs. accuracy**: Consider your stakeholders when choosing between single trees and forests\n",
    "5. **Use for tabular data**: Random forests excel with structured, tabular datasets\n",
    "\n",
    "**Great work!** You now have a solid understanding of one of the most powerful and widely-used machine learning algorithms in practice. 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
