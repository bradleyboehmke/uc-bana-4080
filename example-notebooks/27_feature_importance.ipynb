{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b540ff1c",
   "metadata": {},
   "source": [
    "# Understanding Feature Importance: Peeking Inside the Black Box\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bradleyboehmke/uc-bana-4080/blob/main/example-notebooks/27_feature_importance.ipynb)\n",
    "\n",
    "This companion notebook provides hands-on exercises for the **Feature Importance** chapter. You'll compute impurity-based and permutation importance, compare their rankings, and use partial dependence plots (PDPs) to understand how features influence predictions.\n",
    "\n",
    "**What you'll practice**\n",
    "- Train Random Forests for classification and regression\n",
    "- Extract impurity-based importance (`.feature_importances_`)\n",
    "- Compute permutation importance on a held-out test set\n",
    "- Visualize and compare importance rankings\n",
    "- Create PDPs to explore feature effects\n",
    "- Translate findings into business insights\n",
    "\n",
    "**How to use**\n",
    "- Run from top to bottom. When you see **üèÉ‚Äç‚ôÇÔ∏è Try It Yourself**, add your code beneath the prompt.\n",
    "- In Colab: `Runtime ‚Üí Restart and run all` to test from a clean environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c85fc",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "Install and import the required packages. In local environments where these libraries are already installed, you can skip the install cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecc82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using Colab/a fresh env, uncomment to install\n",
    "# !pip -q install scikit-learn pandas numpy matplotlib ISLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ISLP import load_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53f0f9",
   "metadata": {},
   "source": [
    "## 1) Warm‚Äëup: Build a Random Forest and Extract Impurity-Based Importance\n",
    "\n",
    "We‚Äôll start with the **Default** dataset (classification). Features: `balance`, `income`, and `student` (binary). Target: `default` (1 = Yes, 0 = No).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea706970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare Default dataset\n",
    "Default = load_data('Default')\n",
    "\n",
    "# Convert to numeric (student/default as binary; cast features to float for PDPs)\n",
    "Default = Default.copy()\n",
    "Default['default'] = (Default['default'] == 'Yes').astype(int)\n",
    "Default['student'] = (Default['student'] == 'Yes').astype(float)\n",
    "\n",
    "X = Default[['student', 'balance', 'income']].astype(float)\n",
    "y = Default['default']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Default', 'Default']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437dfa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impurity-based importance (from training)\n",
    "impurity_df = (pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'impurity_importance': rf_clf.feature_importances_\n",
    "})\n",
    "                .sort_values('impurity_importance', ascending=False)\n",
    "                .reset_index(drop=True))\n",
    "\n",
    "impurity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd894638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot impurity-based importance (sorted horizontal bar)\n",
    "ordered = impurity_df.sort_values('impurity_importance')\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "plt.barh(ordered['feature'], ordered['impurity_importance'])\n",
    "plt.xlabel(\"Impurity-based importance\")\n",
    "plt.title(\"Random Forest Feature Importance (Training)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877efde8",
   "metadata": {},
   "source": [
    "### üèÉ‚Äç‚ôÇÔ∏è Try It Yourself\n",
    "- Change the number of trees (`n_estimators`) or set a `max_depth` and re-run. Do rankings change?\n",
    "- Add a noisy feature (e.g., a random normal column) and see where it ranks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a0f259",
   "metadata": {},
   "source": [
    "## 2) Permutation Importance (Model‚ÄëAgnostic)\n",
    "\n",
    "Compute importance as the **drop in test performance** when a feature is shuffled (relationship to target broken).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = permutation_importance(\n",
    "    rf_clf, X_test, y_test,\n",
    "    n_repeats=10, random_state=42, scoring='accuracy'\n",
    ")\n",
    "\n",
    "perm_df = (pd.DataFrame({\n",
    "    'feature': X_test.columns,\n",
    "    'perm_importance_mean': perm.importances_mean,\n",
    "    'perm_importance_std': perm.importances_std\n",
    "})\n",
    "           .sort_values('perm_importance_mean', ascending=False)\n",
    "           .reset_index(drop=True))\n",
    "\n",
    "perm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot permutation importance with error bars\n",
    "ordered = perm_df.sort_values('perm_importance_mean')\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "plt.barh(ordered['feature'], ordered['perm_importance_mean'], xerr=ordered['perm_importance_std'])\n",
    "plt.xlabel(\"Permutation importance (Œî accuracy)\")\n",
    "plt.title(\"Permutation Importance (Test Set)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54a013",
   "metadata": {},
   "source": [
    "### Compare methods side‚Äëby‚Äëside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = (impurity_df\n",
    "           .merge(perm_df, on='feature', how='inner')\n",
    "           .sort_values('perm_importance_mean', ascending=False)\n",
    "           .reset_index(drop=True))\n",
    "compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015e195",
   "metadata": {},
   "source": [
    "### üèÉ‚Äç‚ôÇÔ∏è Try It Yourself\n",
    "- Do impurity and permutation rankings agree? Where do they disagree?\n",
    "- If they disagree strongly for a continuous vs. binary feature, why might that be?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5001bf",
   "metadata": {},
   "source": [
    "## 3) Partial Dependence Plots (PDPs)\n",
    "\n",
    "PDPs reveal **how** predictions change as a feature varies (marginal effect), averaging over other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c99cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-feature PDP for the most important feature (by permutation importance)\n",
    "top_feat = perm_df.iloc[0]['feature']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3.5))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    rf_clf, X_train, features=[top_feat], grid_resolution=60, ax=ax\n",
    ")\n",
    "ax.set_title(f\"Partial Dependence: {top_feat}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDPs for all features (side-by-side)\n",
    "fig, ax = plt.subplots(1, len(X.columns), figsize=(12, 3.5))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    rf_clf, X_train, features=list(X.columns), grid_resolution=50, ax=ax\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54aba30",
   "metadata": {},
   "source": [
    "### üèÉ‚Äç‚ôÇÔ∏è Try It Yourself\n",
    "- Identify any threshold or saturation effects in the PDPs.\n",
    "- Do PDP insights align with the importance rankings and your domain intuition?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519cfa9",
   "metadata": {},
   "source": [
    "## 4) (Optional) Regression Example: Ames Housing\n",
    "\n",
    "Repeat the workflow for a regression task to compute **MSE-based importance** and **permutation importance (R¬≤)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prep a subset of Ames features (via raw URL for Colab friendliness)\n",
    "ames_url = \"https://raw.githubusercontent.com/bradleyboehmke/uc-bana-4080/main/data/ames_clean.csv\"\n",
    "\n",
    "try:\n",
    "    ames = pd.read_csv(ames_url)\n",
    "    feats = ['GrLivArea','OverallQual','TotalBsmtSF','GarageArea','YearBuilt','LotArea','FullBath','BedroomAbvGr']\n",
    "    df_house = ames[feats + ['SalePrice']].dropna().copy()\n",
    "\n",
    "    Xr = df_house[feats]\n",
    "    yr = df_house['SalePrice']\n",
    "\n",
    "    Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.3, random_state=42)\n",
    "\n",
    "    rf_reg = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "    rf_reg.fit(Xr_train, yr_train)\n",
    "\n",
    "    pred = rf_reg.predict(Xr_test)\n",
    "    r2 = r2_score(yr_test, pred)\n",
    "    mae = mean_absolute_error(yr_test, pred)\n",
    "    rmse = mean_squared_error(yr_test, pred) ** 0.5\n",
    "\n",
    "    print(f\"Test R^2: {r2:.3f} | MAE: ${mae:,.0f} | RMSE: ${rmse:,.0f}\")\n",
    "\n",
    "    imp_reg = (pd.DataFrame({'feature': Xr.columns, 'impurity_importance': rf_reg.feature_importances_})\n",
    "               .sort_values('impurity_importance', ascending=False).reset_index(drop=True))\n",
    "    imp_reg\n",
    "except Exception as e:\n",
    "    print(\"Ames dataset could not be loaded. If offline, skip this section.\\n\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regression impurity-based importance (if computed above)\n",
    "try:\n",
    "    ordered = imp_reg.sort_values('impurity_importance')\n",
    "    plt.figure(figsize=(6, 3.5))\n",
    "    plt.barh(ordered['feature'], ordered['impurity_importance'])\n",
    "    plt.xlabel(\"Impurity-based importance (regression)\")\n",
    "    plt.title(\"Random Forest Regressor Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0765d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance for regression (R^2 drop)\n",
    "try:\n",
    "    perm_r = permutation_importance(\n",
    "        rf_reg, Xr_test, yr_test,\n",
    "        n_repeats=10, random_state=42, scoring='r2'\n",
    "    )\n",
    "    perm_reg = (pd.DataFrame({\n",
    "        'feature': Xr_test.columns,\n",
    "        'perm_importance_mean': perm_r.importances_mean,\n",
    "        'perm_importance_std': perm_r.importances_std\n",
    "    })\n",
    "                .sort_values('perm_importance_mean', ascending=False)\n",
    "                .reset_index(drop=True))\n",
    "    perm_reg\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDPs for top regression feature\n",
    "try:\n",
    "    top_r = perm_reg.iloc[0]['feature']\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 3.5))\n",
    "    PartialDependenceDisplay.from_estimator(rf_reg, Xr_train, features=[top_r], grid_resolution=50, ax=ax)\n",
    "    ax.set_title(f\"Partial Dependence (Regression): {top_r}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8153c6f",
   "metadata": {},
   "source": [
    "## 5) Quick Checklist for Trustworthy Feature Importance\n",
    "\n",
    "- Use **permutation importance on a held-out test set** for reliable rankings\n",
    "- Compare with **impurity-based importance** for tree models (fast signal; validate later)\n",
    "- Watch for **high-cardinality bias** and **correlated features** splitting importance\n",
    "- Remember: **importance ‚â† causation**; pair with domain expertise\n",
    "- Use **PDPs** (and, later, SHAP/LIME) to understand *how* features influence predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b820e48b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ End‚Äëof‚ÄëChapter Exercises\n",
    "\n",
    "These extend your Chapter 26 models with feature importance analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37421464",
   "metadata": {},
   "source": [
    "### Exercise 1 ‚Äî Baseball Salary (Regression)\n",
    "\n",
    "Use your **Hitters** random forest from Chapter 26.\n",
    "\n",
    "**Tasks**\n",
    "1. Extract and plot impurity-based importance\n",
    "2. Compute permutation importance (`scoring='r2'`); compare to impurity\n",
    "3. Create PDPs for the top 3‚Äì5 features\n",
    "4. Write 3 business insights + 2 caveats (importance ‚â† causation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter\n",
    "Hitters = load_data('Hitters')\n",
    "Hitters_clean = Hitters.dropna(subset=['Salary']).copy()\n",
    "\n",
    "features = ['Years','Hits','RBI','Walks','PutOuts']\n",
    "Xb = Hitters_clean[features]\n",
    "yb = Hitters_clean['Salary']\n",
    "\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(Xb, yb, test_size=0.3, random_state=42)\n",
    "\n",
    "# TODO: Fit RandomForestRegressor; compute impurity and permutation importance; make PDPs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e82781",
   "metadata": {},
   "source": [
    "### Exercise 2 ‚Äî Credit Default (Classification)\n",
    "\n",
    "Re-use your **Default** random forest.\n",
    "\n",
    "**Tasks**\n",
    "1. Plot impurity-based importance\n",
    "2. Compute permutation importance (`scoring='accuracy'`); compare\n",
    "3. Discuss high-cardinality bias (continuous vs. binary)\n",
    "4. Create PDPs for `balance`, `income`, `student`\n",
    "5. Draft a 1-page memo with thresholds and actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter (you already trained rf_clf above)\n",
    "# TODO: Recreate charts/tables here as your final deliverables for Exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f560ff6",
   "metadata": {},
   "source": [
    "### Exercise 3 ‚Äî Market Direction (Optional)\n",
    "\n",
    "Work with **Weekly** data (lags 1‚Äì5).\n",
    "\n",
    "**Tasks**\n",
    "1. Compare impurity vs. permutation importance\n",
    "2. Examine correlations among lags\n",
    "3. Create PDPs for top lags\n",
    "4. Compare model accuracy to baseline (always \"Up\"); reflect on limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter\n",
    "Weekly = load_data('Weekly').copy()\n",
    "Weekly['Direction_binary'] = (Weekly['Direction'] == 'Up').astype(int)\n",
    "lag_features = ['Lag1','Lag2','Lag3','Lag4','Lag5']\n",
    "\n",
    "Xw = Weekly[lag_features]\n",
    "yw = Weekly['Direction_binary']\n",
    "\n",
    "split_idx = int(0.8 * len(Weekly))\n",
    "Xw_train, Xw_test = Xw.iloc[:split_idx], Xw.iloc[split_idx:]\n",
    "yw_train, yw_test = yw.iloc[:split_idx], yw.iloc[split_idx:]\n",
    "\n",
    "# TODO: Fit RandomForestClassifier; compute and compare importances; PDPs; baseline comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a02786",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "- Use **impurity-based importance** for fast, model-specific signals\n",
    "- Validate with **permutation importance** on test data\n",
    "- Use **PDPs** to understand *how* important features affect predictions\n",
    "- Always communicate **insights + caveats** to stakeholders\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
