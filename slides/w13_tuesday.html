<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="w13_tuesday_files/libs/clipboard/clipboard.min.js"></script>
<script src="w13_tuesday_files/libs/quarto-html/tabby.min.js"></script>
<script src="w13_tuesday_files/libs/quarto-html/popper.min.js"></script>
<script src="w13_tuesday_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="w13_tuesday_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="w13_tuesday_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="w13_tuesday_files/libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="w13_tuesday_files/libs/quarto-contrib/quarto-timer-1.0.0/timer.js"></script>
<link href="w13_tuesday_files/libs/quarto-contrib/quarto-timer-1.0.0/timer.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <title>Week 13 ‚Äì Unsupervised Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="w13_tuesday_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="w13_tuesday_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="w13_tuesday_files/libs/revealjs/dist/theme/quarto-534cd8e3a96973385dffff3f4709048d.css">
  <link rel="stylesheet" href="styles.css">
  <link href="w13_tuesday_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="w13_tuesday_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="w13_tuesday_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="w13_tuesday_files/libs/revealjs/plugin/appearance/appearance.css" rel="stylesheet">
  <link href="w13_tuesday_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <meta name="mermaid-theme" content="neutral">
  <script src="w13_tuesday_files/libs/quarto-diagram/mermaid.min.js"></script>
  <script src="w13_tuesday_files/libs/quarto-diagram/mermaid-init.js"></script>
  <link href="w13_tuesday_files/libs/quarto-diagram/mermaid.css" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
  <script type="text/javascript">
  window.PlotlyConfig = {MathJaxConfig: 'local'};
  if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
  </script>
  <script type="module">import "https://cdn.plot.ly/plotly-3.2.0.min"</script>

</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="images/unsupervised_learning_background.jpg" data-background-opacity="1.0" data-background-size="cover" class="quarto-title-block center">
  <h1 class="title">Week 13 ‚Äì Unsupervised Learning</h1>
  <p class="subtitle">Clustering and Dimension Reduction with PCA</p>

<div class="quarto-title-authors">
</div>

</section>
<section id="welcome-to-week-13" class="slide level2">
<h2>Welcome to Week 13</h2>
<ul>
<li><p>Quick overview of today‚Äôs plan:</p>
<ul>
<li>Introduction to unsupervised learning concepts</li>
<li>Clustering: Finding natural groups in data</li>
<li>Dimension reduction: Simplifying complex datasets</li>
<li>Hands-on demonstrations with real data</li>
</ul></li>
</ul>
</section>
<section>
<section id="discussion-homework-questions" class="title-slide slide level1 center" data-background="#43464B">
<h1>Discussion: Homework &amp; Questions</h1>

</section>
<section id="questions-from-week-12" class="slide level2 smaller">
<h2>Questions from Week 12?</h2>
<ul>
<li>Decision trees and ensemble methods?</li>
<li>Random forests and feature importance?</li>
<li>Model evaluation, comparison?</li>
<li>Hyperparameter tuning?</li>
<li>Anything confusing in the quiz or class lab?</li>
<li>Time to ask!</li>
</ul>
<div class="fragment">
<div class="columns">
<div class="column" style="width:70%;">
<div class="callout callout-none no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Activity</strong></p>
</div>
<div class="callout-content">
<p>Converse with your neighbor and identify‚Ä¶</p>
<ul>
<li>1 new thing you learned last week that you that you thought was well explained</li>
<li>1 thing we covered last week that is still confusing</li>
</ul>
</div>
</div>
</div>
</div><div class="column" style="width:30%;">
<center>
<div id="3minWaiting">

</div>
<script src="_extensions/produnis/timer/timer.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        initializeTimer("3minWaiting", 180, "slide");
    });
</script>
</center>
</div></div>
</div>
</section></section>
<section>
<section id="what-is-unsupervised-learning" class="title-slide slide level1 center" data-background="#43464B">
<h1>What is Unsupervised Learning?</h1>

</section>
<section id="supervised-vs.-unsupervised-learning" class="slide level2 smaller">
<h2>Supervised vs.&nbsp;Unsupervised Learning</h2>
<p><strong>Everything we‚Äôve done so far has been supervised learning:</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Supervised Learning</strong></p>
<ul>
<li>You have a target variable (labels)</li>
<li>Goal: Predict the outcome</li>
<li>Examples:
<ul>
<li>Predict house prices</li>
<li>Classify loan defaults</li>
<li>Diagnose diseases</li>
</ul></li>
<li>Success metric: Accuracy, RMSE, etc.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Unsupervised Learning</strong></p>
<ul>
<li>No target variable (no labels)</li>
<li>Goal: Discover hidden patterns</li>
<li>Examples:
<ul>
<li>Find customer segments</li>
<li>Group similar documents</li>
<li>Reduce feature complexity</li>
</ul></li>
<li>Success metric: Interpretability, business value</li>
</ul>
</div></div>
<aside class="notes">
<p>Emphasize that this is a major shift in thinking. We‚Äôre no longer trying to predict something‚Äîwe‚Äôre trying to understand the natural structure in our data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="think-pair-share" class="slide level2 smaller">
<h2>Think-Pair-Share</h2>
<p>Let‚Äôs think about when you might need unsupervised learning in business contexts.</p>
<div class="columns">
<div class="column" style="width:70%;">
<p><strong>Discuss with your neighbor:</strong></p>
<ul>
<li>Think of a business problem where you have lots of data but NO labels</li>
<li>What would you want to discover about that data?</li>
<li>How might finding patterns (without predicting) be valuable?</li>
</ul>
<p><strong>Example to get you started:</strong> A retailer has millions of transaction records but no predetermined customer segments‚Ä¶</p>
</div><div class="column" style="width:30%;">
<center>
<div id="4minDiscuss1">

</div>
<script src="_extensions/produnis/timer/timer.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        initializeTimer("4minDiscuss1", 240, "slide");
    });
</script>
</center>
</div></div>
<p>Then we‚Äôll take a few responses‚Ä¶</p>
</section>
<section id="two-main-types-of-unsupervised-learning" class="slide level2 smaller">
<h2>Two Main Types of Unsupervised Learning</h2>
<div class="cell" data-reveal="true" data-fig-width="12" data-fig-height="6" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">graph TB
    A[Unsupervised Learning&lt;br/&gt;Discover patterns without labels] --&gt; B[Clustering&lt;br/&gt;Group similar observations]
    A --&gt; C[Dimension Reduction&lt;br/&gt;Reduce number of features]

    B --&gt; B1[K-Means: Customer segmentation]
    B --&gt; B2[Hierarchical: Organize documents]
    B --&gt; B3[DBSCAN: Anomaly detection]

    C --&gt; C1[PCA: Compress features]
    C --&gt; C2[t-SNE: Visualize high-D data]
    C --&gt; C3[Autoencoders: Deep learning compression]

    style A fill:#43464B,stroke:#fff,stroke-width:2px,color:#fff
    style B fill:#4ECDC4,stroke:#fff,stroke-width:2px
    style C fill:#FF6B6B,stroke:#fff,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<div class="fragment">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Key Distinction</strong></p>
</div>
<div class="callout-content">
<p><strong>Clustering</strong> is focused on finding groupings amongst the <strong>rows</strong> (observations) ‚Äî grouping similar customers, products, or data points together.</p>
<p><strong>Dimension Reduction</strong> is focused on finding groupings amongst the <strong>columns</strong> (features) ‚Äî combining correlated features into composite components.</p>
</div>
</div>
</div>
<aside class="notes">
<p>Today we‚Äôll focus on K-Means clustering (most common clustering method) and PCA (most common dimension reduction method). These are the workhorses of unsupervised learning in business.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="clustering-groups-rows-observations" class="slide level2 smaller scrollable">
<h2>Clustering: Groups ROWS (observations)</h2>
<div id="c68131a4" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w13_tuesday_files/figure-revealjs/cell-2-output-1.png" width="871" height="439"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Key Takeaway</strong></p>
</div>
<div class="callout-content">
<p><strong>Clustering finds groupings amongst the ROWS</strong> ‚Äî it identifies which observations (customers, products, patients) are similar to each other and groups them together.</p>
<p><em>‚ÄúThese customers behave similarly‚Äù</em></p>
</div>
</div>
</div>
</section>
<section id="dimension-reduction-combines-columns-features" class="slide level2 smaller scrollable">
<h2>Dimension Reduction: Combines COLUMNS (features)</h2>
<div id="2096a079" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w13_tuesday_files/figure-revealjs/cell-3-output-1.png" width="1805" height="513"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Key Takeaway</strong></p>
</div>
<div class="callout-content">
<p><strong>Dimension Reduction finds groupings amongst the COLUMNS</strong> ‚Äî it identifies which features are correlated and combines them into composite components.</p>
<p><em>‚ÄúThese features capture similar information‚Äù</em></p>
</div>
</div>
</div>
</section></section>
<section>
<section id="clustering-finding-natural-groups" class="title-slide slide level1 center" data-background="#43464B">
<h1>Clustering: Finding Natural Groups</h1>

</section>
<section id="what-is-clustering" class="slide level2 smaller">
<h2>What is Clustering?</h2>
<p><strong>Clustering</strong> automatically groups similar observations together without being told what the groups should be.</p>
<div class="columns">
<div class="column" style="width:55%;">
<p><strong>Real-world applications:</strong></p>
<ul>
<li><strong>Marketing</strong>: Segment customers by behavior</li>
<li><strong>Retail</strong>: Group products by purchase patterns</li>
<li><strong>Healthcare</strong>: Identify patient subtypes</li>
<li><strong>Fraud detection</strong>: Find unusual transaction patterns</li>
<li><strong>Document analysis</strong>: Organize similar articles</li>
<li><strong>Image compression</strong>: Group similar pixels</li>
</ul>
</div><div class="column" style="width:45%;">
<div class="cell" data-reveal="true" data-fig-width="5" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    A[1000 Customers&lt;br/&gt;Many features] --&gt; B{Clustering&lt;br/&gt;Algorithm}
    B --&gt; C1[Segment 1:&lt;br/&gt;Budget Shoppers]
    B --&gt; C2[Segment 2:&lt;br/&gt;Premium Buyers]
    B --&gt; C3[Segment 3:&lt;br/&gt;Occasional Visitors]

    style A fill:#f0f0f0
    style B fill:#43464B,color:#fff
    style C1 fill:#FF6B6B
    style C2 fill:#4ECDC4
    style C3 fill:#45B7D1
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Emphasize that clustering finds groups that exist naturally in the data‚Äîwe don‚Äôt tell it what the groups should look like ahead of time.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-k-means-works-the-algorithm" class="slide level2 smaller scrollable">
<h2>How K-Means Works: The Algorithm</h2>
<p><strong>K-Means</strong> is an iterative algorithm that finds clusters by repeatedly assigning points and updating centers:</p>
<div id="62a105cc" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w13_tuesday_files/figure-revealjs/cell-4-output-1.png" width="1045" height="662"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>This visualization shows how K-Means iteratively improves cluster assignments. Notice how the centroids move from their random initial positions toward the natural cluster centers. Usually converges in 5-10 iterations.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="think-pair-share-identify-clustering-problems" class="slide level2 smaller">
<h2>Think-Pair-Share: Identify Clustering Problems</h2>
<p>Which of these business problems would benefit from clustering?</p>
<div class="columns">
<div class="column" style="width:70%;">
<p><strong>Discuss with your neighbor:</strong></p>
<ol type="1">
<li><strong>Problem A</strong>: You have customer purchase history and want to create targeted marketing campaigns</li>
<li><strong>Problem B</strong>: You want to predict which customers will churn next month</li>
<li><strong>Problem C</strong>: You have 10,000 products and want to organize them into logical groups</li>
<li><strong>Problem D</strong>: You want to predict house prices based on square footage and location</li>
</ol>
<p>Which are clustering problems? Which are supervised learning? Why?</p>
</div><div class="column" style="width:30%;">
<center>
<div id="4minClustering">

</div>
<script src="_extensions/produnis/timer/timer.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        initializeTimer("4minClustering", 240, "slide");
    });
</script>
</center>
</div></div>
<p>Then we‚Äôll take a few responses‚Ä¶</p>
<aside class="notes">
<p>Answer: A and C are clustering (no labels, finding groups). B and D are supervised learning (predicting specific outcomes).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="hands-on-demo-k-means-in-action" class="slide level2 smaller">
<h2>Hands-On Demo: K-Means in Action</h2>
<p>Let‚Äôs see K-Means clustering with a simple customer dataset:</p>
<div id="a77a43e9" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display" data-execution_count="207">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">annual_spending</th>
<th data-quarto-table-cell-role="th">visits_per_year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>2248.357077</td>
<td>5.194155</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>1930.867849</td>
<td>6.937290</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>2323.844269</td>
<td>3.595894</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>2761.514928</td>
<td>4.344676</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>1882.923313</td>
<td>4.215784</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">...</th>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">85</th>
<td>8148.770069</td>
<td>39.135916</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">86</th>
<td>9140.781482</td>
<td>35.065009</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">87</th>
<td>8730.125777</td>
<td>42.267670</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">88</th>
<td>8129.167857</td>
<td>33.676716</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">89</th>
<td>8859.287203</td>
<td>48.600846</td>
</tr>
</tbody>
</table>

<p>90 rows √ó 2 columns</p>
</div>
</div>
</div>
</section>
<section id="demo-fitting-k-means" class="slide level2 smaller">
<h2>Demo: Fitting K-Means</h2>
<div id="2e91da35" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="co"># Standardize features (important for K-Means!)</span></span>
<span id="cb1-2"><a href=""></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-3"><a href=""></a>customers_scaled <span class="op">=</span> scaler.fit_transform(customers)</span>
<span id="cb1-4"><a href=""></a></span>
<span id="cb1-5"><a href=""></a><span class="co"># Fit K-Means with K=3 clusters</span></span>
<span id="cb1-6"><a href=""></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb1-7"><a href=""></a>customers[<span class="st">'cluster'</span>] <span class="op">=</span> kmeans.fit_predict(customers_scaled)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fcd7ee3f" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w13_tuesday_files/figure-revealjs/cell-7-output-1.png" width="471" height="470"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>Point out how the algorithm found three natural groups: budget shoppers, regular customers, and premium high-frequency buyers.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-big-question-how-many-clusters-k" class="slide level2 smaller">
<h2>The Big Question: How Many Clusters (K)?</h2>
<p><strong>Problem</strong>: K-Means requires you to specify the number of clusters upfront. But how do you know what K should be?</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Elbow Method</strong></p>
<ol type="1">
<li>Try different values of K (e.g., 2, 3, 4, 5, 6‚Ä¶)</li>
<li>Measure ‚Äúinertia‚Äù (within-cluster sum of squares)</li>
<li>Plot inertia vs.&nbsp;K</li>
<li>Look for the ‚Äúelbow‚Äù where adding more clusters doesn‚Äôt help much</li>
</ol>
<p><strong>Lower inertia = tighter clusters = better fit</strong></p>
</div><div class="column" style="width:50%;">
<p><strong>Silhouette Score</strong></p>
<ul>
<li>Measures how similar each point is to its own cluster vs.&nbsp;other clusters</li>
<li>Ranges from -1 (wrong cluster) to +1 (perfect cluster)</li>
<li><strong>Higher is better</strong></li>
<li>Typical good score: 0.5-0.7</li>
</ul>
<p><strong>Silhouette score balances cluster tightness with separation</strong></p>
</div></div>
<aside class="notes">
<p>Emphasize that there‚Äôs often no ‚Äúcorrect‚Äù answer‚Äîit depends on business needs. Sometimes 3 segments are actionable, sometimes you need 5.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="demo-finding-the-right-k" class="slide level2 smaller">
<h2>Demo: Finding the Right K</h2>
<div id="3f9d1577" class="cell columns column-output-location" data-fig-height="8" data-fig-width="6" data-execution_count="7">
<div class="column">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb2-2"><a href=""></a></span>
<span id="cb2-3"><a href=""></a><span class="co"># Try K from 2 to 8</span></span>
<span id="cb2-4"><a href=""></a>K_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">9</span>)</span>
<span id="cb2-5"><a href=""></a>inertias <span class="op">=</span> []</span>
<span id="cb2-6"><a href=""></a>silhouettes <span class="op">=</span> []</span>
<span id="cb2-7"><a href=""></a></span>
<span id="cb2-8"><a href=""></a><span class="cf">for</span> k <span class="kw">in</span> K_range:</span>
<span id="cb2-9"><a href=""></a>    km <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb2-10"><a href=""></a>    km.fit(customers_scaled)</span>
<span id="cb2-11"><a href=""></a>    inertias.append(km.inertia_)</span>
<span id="cb2-12"><a href=""></a>    silhouettes.append(silhouette_score(customers_scaled, km.labels_))</span>
<span id="cb2-13"><a href=""></a></span>
<span id="cb2-14"><a href=""></a><span class="co"># Plot both metrics</span></span>
<span id="cb2-15"><a href=""></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb2-16"><a href=""></a></span>
<span id="cb2-17"><a href=""></a><span class="co"># Elbow plot</span></span>
<span id="cb2-18"><a href=""></a>ax1.plot(K_range, inertias, <span class="st">'bo-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb2-19"><a href=""></a>ax1.set_xlabel(<span class="st">'Number of Clusters (K)'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb2-20"><a href=""></a>ax1.set_ylabel(<span class="st">'Inertia (Within-cluster SS)'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb2-21"><a href=""></a>ax1.set_title(<span class="st">'Elbow Method'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb2-22"><a href=""></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-23"><a href=""></a>ax1.axvline(x<span class="op">=</span><span class="dv">3</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Elbow at K=3'</span>)</span>
<span id="cb2-24"><a href=""></a>ax1.legend()</span>
<span id="cb2-25"><a href=""></a></span>
<span id="cb2-26"><a href=""></a><span class="co"># Silhouette plot</span></span>
<span id="cb2-27"><a href=""></a>ax2.plot(K_range, silhouettes, <span class="st">'ro-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb2-28"><a href=""></a>ax2.set_xlabel(<span class="st">'Number of Clusters (K)'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb2-29"><a href=""></a>ax2.set_ylabel(<span class="st">'Silhouette Score'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb2-30"><a href=""></a>ax2.set_title(<span class="st">'Silhouette Score by K'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb2-31"><a href=""></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-32"><a href=""></a>ax2.axvline(x<span class="op">=</span><span class="dv">3</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Peak at K=3'</span>)</span>
<span id="cb2-33"><a href=""></a>ax2.legend()</span>
<span id="cb2-34"><a href=""></a></span>
<span id="cb2-35"><a href=""></a>plt.tight_layout()</span>
<span id="cb2-36"><a href=""></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div><div class="column">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w13_tuesday_files/figure-revealjs/cell-8-output-1.png" width="566" height="566"></p>
</figure>
</div>
</div>
</div></div>
<aside class="notes">
<p>The elbow occurs at K=3 (inertia stops dropping dramatically), and silhouette score peaks at K=3. This confirms 3 is a good choice for this data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="interactive-activity-interpret-elbow-plots" class="slide level2 smaller">
<h2>Interactive Activity: Interpret Elbow Plots</h2>
<div class="columns">
<div class="column" style="width:70%;">
<div class="callout callout-none no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Your Turn</strong></p>
</div>
<div class="callout-content">
<p>Imagine you‚Äôre analyzing shopping behavior and get this elbow plot:</p>
<ul>
<li>K=2: Inertia = 10,000</li>
<li>K=3: Inertia = 7,000</li>
<li>K=4: Inertia = 5,200</li>
<li>K=5: Inertia = 4,800</li>
<li>K=6: Inertia = 4,600</li>
</ul>
<p><strong>Discuss with your neighbor:</strong></p>
<ol type="1">
<li>Where is the ‚Äúelbow‚Äù in this data?</li>
<li>What K would you recommend? Why?</li>
<li>What if your marketing team says they can only handle 3 customer segments? Does that change your answer?</li>
</ol>
</div>
</div>
</div>
</div><div class="column" style="width:30%;">
<center>
<div id="3minElbow">

</div>
<script src="_extensions/produnis/timer/timer.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        initializeTimer("3minElbow", 180, "slide");
    });
</script>
</center>
</div></div>
<p>Then we‚Äôll take a few responses‚Ä¶</p>
<aside class="notes">
<p>The elbow is around K=3 (biggest drop). But business constraints matter! If the team can only manage 3 segments, that‚Äôs your answer regardless of statistics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="reality-check-real-data-is-messy" class="slide level2 smaller">
<h2>Reality Check: Real Data is Messy</h2>
<p><strong>The examples so far have been clean and simple‚Ä¶</strong></p>
<p>But real business data rarely has such clear clusters!</p>
<p>Let‚Äôs look at a real-world example: <strong>grocery store customer segmentation</strong> with:</p>
<ul>
<li>801 actual households</li>
<li>Transaction history over 1 year</li>
<li>14 features combining:
<ul>
<li><strong>Behavioral</strong>: spending, visit frequency, discount usage, recency</li>
<li><strong>Demographic</strong>: age, income, household size, marital status, homeownership</li>
</ul></li>
</ul>
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Coming Up</strong></p>
</div>
<div class="callout-content">
<p>We‚Äôll see that real data doesn‚Äôt give us clean, obvious answers. This is completely normal and expected in industry!</p>
</div>
</div>
</div>
</section>
<section id="real-data-customer-features" class="slide level2 smaller scrollable">
<h2>Real Data: Customer Features</h2>
<div id="2b8898ce" class="cell" data-execution_count="8">
<div class="cell-output cell-output-stdout">
<pre><code>Real customer data shape: (801, 14)

First few customers:</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="211">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">total_spending</th>
<th data-quarto-table-cell-role="th">avg_basket_value</th>
<th data-quarto-table-cell-role="th">num_trips</th>
<th data-quarto-table-cell-role="th">num_unique_products</th>
<th data-quarto-table-cell-role="th">avg_days_between_trips</th>
<th data-quarto-table-cell-role="th">recency_days</th>
<th data-quarto-table-cell-role="th">discount_rate</th>
<th data-quarto-table-cell-role="th">coupon_usage_rate</th>
<th data-quarto-table-cell-role="th">age_encoded</th>
<th data-quarto-table-cell-role="th">income_encoded</th>
<th data-quarto-table-cell-role="th">household_size_num</th>
<th data-quarto-table-cell-role="th">num_kids</th>
<th data-quarto-table-cell-role="th">is_married</th>
<th data-quarto-table-cell-role="th">is_homeowner</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>2415.56</td>
<td>2.459837</td>
<td>51</td>
<td>437</td>
<td>7.039216</td>
<td>0</td>
<td>0.176862</td>
<td>0.023001</td>
<td>6</td>
<td>4</td>
<td>2.0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>1952.37</td>
<td>2.555458</td>
<td>32</td>
<td>556</td>
<td>10.750000</td>
<td>5</td>
<td>0.151821</td>
<td>0.007043</td>
<td>4</td>
<td>5</td>
<td>2.0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>3080.81</td>
<td>2.808396</td>
<td>65</td>
<td>790</td>
<td>5.523077</td>
<td>3</td>
<td>0.198656</td>
<td>0.004658</td>
<td>2</td>
<td>3</td>
<td>3.0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>7448.22</td>
<td>5.659742</td>
<td>157</td>
<td>656</td>
<td>2.305732</td>
<td>0</td>
<td>0.143786</td>
<td>0.023471</td>
<td>2</td>
<td>6</td>
<td>4.0</td>
<td>2</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>646.87</td>
<td>2.967294</td>
<td>49</td>
<td>129</td>
<td>7.387755</td>
<td>1</td>
<td>0.112758</td>
<td>0.000000</td>
<td>4</td>
<td>5</td>
<td>1.0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">5</th>
<td>2291.09</td>
<td>4.457374</td>
<td>54</td>
<td>282</td>
<td>6.574074</td>
<td>9</td>
<td>0.254634</td>
<td>0.000655</td>
<td>6</td>
<td>1</td>
<td>2.0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">6</th>
<td>4094.36</td>
<td>3.712022</td>
<td>100</td>
<td>467</td>
<td>3.610000</td>
<td>0</td>
<td>0.135643</td>
<td>0.008605</td>
<td>4</td>
<td>7</td>
<td>2.0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">7</th>
<td>7739.37</td>
<td>2.479773</td>
<td>298</td>
<td>1363</td>
<td>1.204698</td>
<td>0</td>
<td>0.254389</td>
<td>0.001917</td>
<td>3</td>
<td>2</td>
<td>1.0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">8</th>
<td>5525.98</td>
<td>3.728731</td>
<td>289</td>
<td>344</td>
<td>1.256055</td>
<td>1</td>
<td>0.105570</td>
<td>0.001276</td>
<td>2</td>
<td>6</td>
<td>2.0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">9</th>
<td>3453.31</td>
<td>3.933155</td>
<td>79</td>
<td>443</td>
<td>4.544304</td>
<td>0</td>
<td>0.145976</td>
<td>0.014780</td>
<td>4</td>
<td>6</td>
<td>2.0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<aside class="notes">
<p>Point out the diversity of features - both behavioral and demographic. Real customers are complex!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-data-elbow-silhouette-analysis" class="slide level2 smaller scrollable">
<h2>Real Data: Elbow &amp; Silhouette Analysis</h2>
<p>Let‚Äôs apply the same methods we used before:</p>
<div id="ad057cd2" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w13_tuesday_files/figure-revealjs/cell-10-output-1.png" width="1141" height="374"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Results for different K values:
  K=2: Inertia=   9,663, Silhouette=0.173
  K=3: Inertia=   8,618, Silhouette=0.150
  K=4: Inertia=   7,898, Silhouette=0.140
  K=5: Inertia=   7,425, Silhouette=0.144
  K=6: Inertia=   6,991, Silhouette=0.146
  K=7: Inertia=   6,616, Silhouette=0.140
  K=8: Inertia=   6,338, Silhouette=0.135
  K=9: Inertia=   6,106, Silhouette=0.127
  K=10: Inertia=   5,911, Silhouette=0.125</code></pre>
</div>
</div>
</section>
<section id="what-do-you-notice" class="slide level2 smaller">
<h2>What Do You Notice?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Observations:</strong></p>
<ol type="1">
<li><strong>No clear elbow!</strong> üìâ
<ul>
<li>WCSS decreases gradually</li>
<li>No obvious ‚Äúbend‚Äù like our simple examples</li>
</ul></li>
<li><strong>Low silhouette scores</strong> üìä
<ul>
<li>All scores around 0.14-0.17</li>
<li>K=2 is highest, but barely</li>
<li>Small differences between K values</li>
</ul></li>
</ol>
</div><div class="column" style="width:50%;">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>This is COMPLETELY NORMAL!</strong></p>
</div>
<div class="callout-content">
<p>Real customer data:</p>
<ul>
<li>Lives on a <strong>spectrum</strong>, not in neat boxes</li>
<li>Has <strong>overlapping patterns</strong> (customers share behaviors)</li>
<li>Shows <strong>fuzzy boundaries</strong> between segments</li>
<li>Rarely has one ‚Äúcorrect‚Äù K</li>
</ul>
<p><strong>Low silhouette scores (0.15-0.20) are expected and acceptable for behavioral data!</strong></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Emphasize that students shouldn‚Äôt be discouraged when they see this in their own work. It‚Äôs the reality of messy, real-world data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="when-metrics-dont-give-clear-answers" class="slide level2 smaller scrollable">
<h2>When Metrics Don‚Äôt Give Clear Answers</h2>
<p><strong>What should you do when there‚Äôs no obvious ‚Äúwinner‚Äù?</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Statistical considerations:</strong></p>
<ul>
<li>K=2 has highest silhouette (0.166)</li>
<li>K=3-4 show similar performance</li>
<li>K=5+ continue declining gradually</li>
</ul>
<p><strong>But statistics alone aren‚Äôt enough!</strong></p>
</div><div class="column" style="width:50%;">
<p><strong>Business considerations:</strong></p>
<ul>
<li>Can marketing handle 2 segments? 4? 6?</li>
<li>What‚Äôs the ROI of personalization?</li>
<li>Are segments actionable?</li>
<li>Can you describe each segment clearly?</li>
<li>Do stakeholders understand the segmentation?</li>
</ul>
</div></div>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Work with Stakeholders!</strong></p>
</div>
<div class="callout-content">
<p>When metrics are ambiguous:</p>
<ol type="1">
<li><strong>Try multiple K values</strong> (e.g., K=3, 4, 5)</li>
<li><strong>Profile each segmentation</strong> - what do the clusters mean?</li>
<li><strong>Present options to business stakeholders</strong></li>
<li><strong>Choose based on</strong>: interpretability + actionability + resource constraints</li>
<li><strong>Validate</strong> with domain experts (‚ÄúDo these segments make sense?‚Äù)</li>
</ol>
</div>
</div>
</div>
</section>
<section id="example-choosing-k-for-this-dataset" class="slide level2 smaller">
<h2>Example: Choosing K for This Dataset</h2>
<p>Let‚Äôs walk through the decision process:</p>
<table class="caption-top">
<colgroup>
<col style="width: 17%">
<col style="width: 24%">
<col style="width: 24%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th><strong>K</strong></th>
<th><strong>Pros</strong></th>
<th><strong>Cons</strong></th>
<th><strong>Decision</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>K=2</strong></td>
<td>Highest silhouette (0.166)<br>Simple to explain</td>
<td>Too coarse? Miss nuances<br>Only ‚Äúhigh‚Äù vs ‚Äúlow‚Äù spenders</td>
<td>Maybe too simple</td>
</tr>
<tr class="even">
<td><strong>K=3</strong></td>
<td>Good silhouette (0.158)<br>Aligns with classic RFM</td>
<td>Still quite broad segments</td>
<td><strong>Good choice</strong></td>
</tr>
<tr class="odd">
<td><strong>K=4</strong></td>
<td>Moderate silhouette (0.148)<br>More granular insights</td>
<td>Marketing can handle 4 segments</td>
<td><strong>Good choice</strong></td>
</tr>
<tr class="even">
<td><strong>K=5</strong></td>
<td>Lower silhouette (0.144)<br>Very specific segments</td>
<td>Complex for marketing<br>Harder to operationalize</td>
<td>Probably too many</td>
</tr>
</tbody>
</table>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Real-World Choice</strong></p>
</div>
<div class="callout-content">
<p>For this grocery retailer, <strong>K=4 might be ideal</strong>:</p>
<ul>
<li>Statistical performance is reasonable (silhouette = 0.148)</li>
<li>Creates actionable segments (e.g., ‚Äúbudget shoppers,‚Äù ‚Äúloyal regulars,‚Äù ‚Äúpremium buyers,‚Äù ‚Äúinfrequent visitors‚Äù)</li>
<li>Marketing team can manage 4 distinct campaigns</li>
<li>Provides meaningful differentiation without overwhelming complexity</li>
</ul>
</div>
</div>
</div>
</section></section>
<section>
<section id="dimension-reduction-with-pca" class="title-slide slide level1 center" data-background="#43464B">
<h1>Dimension Reduction with PCA</h1>

</section>
<section id="the-problem-too-many-features" class="slide level2 smaller">
<h2>The Problem: Too Many Features</h2>
<p>Modern datasets are getting <strong>wider and wider</strong>‚Äîhundreds or thousands of features:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Challenges of high dimensionality:</strong></p>
<ul>
<li><strong>Curse of dimensionality</strong>: Data becomes sparse in high-D space</li>
<li><strong>Computational cost</strong>: Training takes forever</li>
<li><strong>Overfitting risk</strong>: More features = more noise</li>
<li><strong>Multicollinearity</strong>: Correlated features confuse models</li>
<li><strong>Visualization</strong>: Can‚Äôt plot 100 dimensions!</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Examples:</strong></p>
<ul>
<li><strong>Healthcare</strong>: 20,000+ genes measured per patient</li>
<li><strong>Computer vision</strong>: Images with millions of pixels</li>
<li><strong>E-commerce</strong>: 500+ features per customer</li>
<li><strong>Text analysis</strong>: Thousands of word counts per document</li>
</ul>
<p><strong>Question</strong>: Do we really need ALL these features?</p>
</div></div>
<aside class="notes">
<p>The good news: often 10-20 carefully constructed features capture 90%+ of the information in 100 original features.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="think-pair-share-when-are-features-a-problem" class="slide level2 smaller scrollable">
<h2>Think-Pair-Share: When Are Features a Problem?</h2>
<p>Let‚Äôs think about when having many features becomes problematic.</p>
<div class="columns">
<div class="column" style="width:70%;">
<p><strong>Discuss with your neighbor:</strong></p>
<ul>
<li>You‚Äôre predicting house prices with 100 features (sq ft, bedrooms, bathrooms, neighborhood, school ratings, crime rates, etc.)</li>
<li>Many features are correlated (e.g., sq ft correlates with bedrooms)</li>
<li>Your model takes 30 minutes to train</li>
<li>Test accuracy is worse than training accuracy</li>
</ul>
<p><strong>Questions:</strong></p>
<ol type="1">
<li>Which of the problems above suggest you have too many features?</li>
<li>What might you gain by reducing from 100 to 10 features?</li>
<li>What might you lose?</li>
</ol>
</div><div class="column" style="width:30%;">
<center>
<div id="4minFeatures">

</div>
<script src="_extensions/produnis/timer/timer.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        initializeTimer("4minFeatures", 240, "slide");
    });
</script>
</center>
</div></div>
<p>Then we‚Äôll take a few responses‚Ä¶</p>
</section>
<section id="what-is-dimension-reduction" class="slide level2 smaller scrollable">
<h2>What is Dimension Reduction?</h2>
<p><strong>Dimension reduction</strong> transforms your data from high-dimensional space to lower-dimensional space while preserving most of the important information.</p>
<div class="cell" data-reveal="true" data-fig-width="10" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A["Original Data&lt;br/&gt;1000 observations&lt;br/&gt;50 features"] --&gt; B{PCA&lt;br/&gt;Dimension Reduction}
    B --&gt; C["Transformed Data&lt;br/&gt;1000 observations&lt;br/&gt;10 components&lt;br/&gt;&lt;br/&gt;Retains 90% of variance"]

    style A fill:#f0f0f0
    style B fill:#43464B,color:#fff
    style C fill:#4ECDC4
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><strong>Two main approaches:</strong></p>
<ul>
<li><strong>Feature Selection</strong>: Pick a subset of original features (e.g., select the 10 most important)</li>
<li><strong>Feature Extraction</strong>: Create NEW features by combining originals (e.g., PCA creates ‚Äúprincipal components‚Äù)</li>
</ul>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p><strong>Today we focus on PCA (Principal Component Analysis)</strong> ‚Äî the most widely-used feature extraction method.</p>
</div>
</div>
</div>
<aside class="notes">
<p>Think of PCA like image compression: a 10MB photo can compress to 500KB while still looking nearly identical. PCA does the same for tabular data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="principal-component-analysis-pca-visual-overview" class="slide level2 smaller">
<h2>Principal Component Analysis (PCA): Visual Overview</h2>
<p><strong>How PCA transforms many correlated features into fewer uncorrelated components:</strong></p>
<div class="cell" data-reveal="true" data-fig-width="8" data-fig-height="6" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    A[50 Original Features&lt;br/&gt;All correlated] --&gt; B[PCA Transformation]
    B --&gt; PC1[PC1: 45% variance&lt;br/&gt;Overall Size]
    B --&gt; PC2[PC2: 20% variance&lt;br/&gt;Location Quality]
    B --&gt; PC3[PC3: 10% variance&lt;br/&gt;Age/Condition]
    B --&gt; PC4[PC4: 8% variance&lt;br/&gt;Luxury Features]
    B --&gt; PC5[PC5: 5% variance&lt;br/&gt;...]
    B --&gt; Rest[PC6-PC50: 12% variance&lt;br/&gt;Mostly noise]

    style PC1 fill:#FF6B6B
    style PC2 fill:#4ECDC4
    style PC3 fill:#45B7D1
    style Rest fill:#f0f0f0
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<aside class="notes">
<p>This diagram shows how PCA takes 50 correlated features and creates new uncorrelated components, with the first few capturing most of the variance.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="pca-the-intuition" class="slide level2 smaller">
<h2>PCA: The Intuition</h2>
<p><strong>PCA finds new coordinate axes (principal components) that capture maximum variance:</strong></p>
<p><strong>The idea:</strong></p>
<ol type="1">
<li><strong>PC1</strong> points in the direction where data varies the MOST</li>
<li><strong>PC2</strong> points in the next-most variation direction (perpendicular to PC1)</li>
<li><strong>PC3</strong> points in the next direction (perpendicular to both)</li>
<li>And so on‚Ä¶</li>
</ol>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Key Insight</strong></p>
</div>
<div class="callout-content">
<p>Often the first 5-10 components capture 90%+ of the total variation! This means you can reduce from 50 features to just 5-10 components while retaining most of the information.</p>
</div>
</div>
</div>
<aside class="notes">
<p>Analogy: Imagine taking photos at a concert. One angle (PC1) captures most of the action. Adding a second angle (PC2) adds some new perspective. A third angle (PC3) adds a bit more. After that, additional angles don‚Äôt reveal much new information.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="visualizing-pca-in-3d-house-features" class="slide level2 smaller scrollable">
<h2>Visualizing PCA in 3D: House Features</h2>
<p>Let‚Äôs see how PCA works with 3 house features: square feet, bedrooms, and bathrooms.</p>
<p><strong>Rotate the plot to see how PC1 aligns with the direction of maximum spread!</strong></p>
<div id="3fc47630" class="cell" data-execution_count="10">
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.2.0.min.js" integrity="sha256-iZ2u/oU2wf/vDbl/ChcX93WgbBRSBvUO6N413hDz7xM=" crossorigin="anonymous"></script>                <div id="c4c9ded2-6590-4e5e-907e-7ace3f2f96c8" class="plotly-graph-div" style="height:600px; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("c4c9ded2-6590-4e5e-907e-7ace3f2f96c8")) {                    Plotly.newPlot(                        "c4c9ded2-6590-4e5e-907e-7ace3f2f96c8",                        [{"hovertemplate":"Sq Ft (std): %{x:.2f}\u003cbr\u003eBedrooms (std): %{y:.2f}\u003cbr\u003eBathrooms (std): %{z:.2f}\u003cextra\u003e\u003c\u002fextra\u003e","marker":{"color":"lightblue","line":{"color":"navy","width":0.5},"opacity":0.7,"size":5},"mode":"markers","name":"Houses","x":{"dtype":"f8","bdata":"J9j2gY9E5T82K\u002fzMZICjv1JzG3lDneo\u002fKL3C+HbO\u002fD9RfnJyV3XCvwQ+4gi\u002fdMK\u002fgqZn6CLN\u002fT9ycJGt29ruP83Euldq5dm\u002fYSWUqDDk5j9HeLoQmXfZv5rM2O2Eodm\u002fMkznXRB+2D97h+NC\u002fQQAwDM1jacmtPy\u002fcuO7+iE84L+WQLKjVRjwv\u002fUVvwm1nN0\u002fETu1f4J67L\u002f+gOFeGiv3v+BdgbNcyvs\u002foKGD7I9Fwb9AUBHYl0bIP7U5MTmDY\u002fe\u002f7HHpcp8z378bN5czNmzOP9I8XGGcivK\u002fxtJE9nP74D8csmkI0ZfhvwXnclbwm8q\u002fnSCEg3+h4b+yyJL4dFEBQMbsv8O0mLk\u002fXrz2JsXj8L8W3fTmPGfwP6jdJe87x\u002fO\u002fQZt7pu4l1j9wlFotIW4AwJ8BlWfOrfW\u002fFnjjck9M1T8cW\u002fAgPdTtP2eNAh4VftM\u002fUL0AZoO\u002fir9z5yNlLPHLv47p+oVDV\u002fi\u002fwkHTa4LQ5b92n6EtNkXZv9Au+I2NjvQ\u002fUoJD2D+x3z99Y\u002f6h9GD9v9ksE6IPT94\u002fanSdjUDr079CxUOuYkvkv1mF7qrIVuk\u002fQfp0MiQY9D+GmByeH1TyP4XTFz25Cuq\u002fTCP4UDgXzb+bIu9zPNHeP8tDybPFHPM\u002fAZpmBkqV2r9GFJKCjy23v2gCFY8twPG\u002fla78lo5X87\u002f8y\u002fOH0jnwP\u002fv0JGds2vk\u002fm4Mq1PQJoj\u002fvOgxTo5vzP4CupEX4e+A\u002f+fbQohIr47+1p7xLynngPwWjMhZ9Ev0\u002fAhbgPUdFsz9ipS6JGIv9PxflhegnRgbAcG4scFNk8D9ITBnHaArLPypTnDwnpcu\u002fNH2B5le1yz\u002fK+2tcXK0AwO969F4yaMC\u002fBDL\u002fCvZS4D9Y0y1j3gH8P6hZO1opWt2\u002f7raU0S\u002f06L+lpLRawC7cvzZ5428mDPI\u002fDsdJCq+j3j\u002fGi49GfirevwspzBWh2uU\u002fmlJMfyV2zD92f\u002fehfv3yP84G\u002fQU4L+W\u002fyevbdUS0z790OZ11pGrUvzIf3QU9E\u002fi\u002fsLrD6AhU3D9Cw2ccQNjZPwi38qN43r4\u002fBIT9MBKFwr8="},"y":{"dtype":"f8","bdata":"I2eeb7vHWj\u002fHva4QZPXNvxb0EmucgOQ\u002f3HRGwSny9T+q62Pu5UrMvxXq4WMVfZ8\u002f+KxYPhwIBUDmyUQUTPjvP\u002f6DpldCTtK\u002feKrmfta65D9Q787N7vrzv0C2Uy1cJdq\u002f8N\u002f1HWS82D8f6Uco5Bnrv\u002fbWRH93QP2\u002fm18S2Ipm178u0Cc85ubvv7pqfRsNYrW\u002fpX4VcpMS1784GejAXC3xv9okB9asKABAPmIOsKNy4b\u002fx1nJk5YjpP24TusZOXgDAOlHWiXkWzL+59WqoNx\u002fzPxcNXuvaH\u002fm\u002fLZ+JN9sG0D9HDVpfRMffvwYNn+fc1du\u002fZlPzjd+4879lt5IADeQAQFTbAXWvu9i\u002f\u002fXJb028x6r9Xfn0Xo0PiPw3Mt3AHb+C\u002f8a5jIi4bmb8wYRO8YxgBwINGalWIme6\u002fKJXCer9Lzr9AtMzFlbvvP2JpNGsjues\u002f1VjUdTWh579AW58qtbvBvwlHQSDS0PW\u002fPzRBBEh91L9mWHjpFCbuv9PBEZ97kuQ\u002fUdQG47Zs5j8bOucVvGr6v3fFLtxc4+E\u002fa3ATvoz\u002fw7807yhVApztv0+uGFbsdus\u002fEzRvhyhW9T\u002f6em2u2+foP5b54CTY6qE\u002fhPmGa1Xbkr+iOVc0e06zv1ffM25r+vY\u002fqLIeIo0L679A4oEmjTPQPwJlrbAdGOK\u002ft1eSWPWv+L8WHPSGa2D2Pw3JPW9kwPs\u002fOK1io+z42D9HneVXpiUAQDzOtDYgNtg\u002f7Zf2B3mS7b8OzOYAMFi3P5IB\u002f9EsG\u002fY\u002fwrn1jkUdnT8sx7RDGs7+P9aOBVIpmwTA8PZwjQmR9T\u002f6pI6e85XJP\u002fJMfahjcds\u002frvDdAlXOtD8ePgSHA\u002fvpv8nG7IBMjMI\u002fbwfkVIvcuT9Uplc6k0LzP+99II03d86\u002fw2sRHV+a67+Xk8t0XQS+vzsADmi6pPQ\u002feeEqNVbh2j8SYMaY5\u002fPqvwXiC23Pkpm\u002f17kHNaZweD\u002fCteoUwUj4P11pYV8VuuG\u002fZX4CZNO56b9kTLnFG9bOv4M+OSNQqvS\u002fTFLJZ\u002fWDmD\u002fs04UD7bTcPxM31rgT9MA\u002fZFo7QvQT5b8="},"z":{"dtype":"f8","bdata":"a5G74O1m5T8lUEw54o3DP4eGiGMHR\u002fE\u002f2vfIkHkn\u002fj9SKKnTqBflvxE\u002f1lPpsN+\u002fG8mcilnH+z9yORIC6VXvPxMUugBbIsa\u002f9AN8IjUdAEAyDz1ZV7\u002fCvyQtWcxJrK8\u002fUWArpsHq5D8rNh9FA3v3v3uaGObpb\u002fq\u002f+CbGTCWRxb8FKY5DhYzyv64wh8a4vNE\u002fqzYsXjCL7r\u002f0ZtT0WGjzv+3Vv4q+aAJA2Tpa3rSu6r9xTarqMgvZP4pl\u002f74Ws\u002f2\u002frIhWATOK47\u002flnnUUfp7iP+Ricl+fO++\u002fVjc8gnR1lT8akN2Jyh7ovy1c4JxEsKs\u002fJtOPSPBU6L+cuwaewhH+P7wxf1SgtbM\u002fGBqEsL1+8r\u002ffNM\u002fmLDb6Pz6WL3tvheq\u002fCDS0wqU1378VP9i\u002f7fH6v5G6WFCslva\u002fSUtbDFJc4j97nU0M2cfdP9YG7r22Qcg\u002f\u002frhK0vSWwz8f4Quk9ly9P7vpucSrCvy\u002fK58CTP4h5795UkcqHRThv5UgsBSDDeo\u002fDRRpzUnQ8D+HNALVxLX2v4gxERqCbLi\u002fBVb5Um6arD\u002fKKmNhl8zNP5dhHxtXcPA\u002fzzLuATrj3T8EjKU+MVHoP9TPGDQ5Xc6\u002fSMZBCZCt3r+oFZ\u002fBm37hPxpLP22MU\u002fQ\u002fCgNF58IF578\u002fxGaJvWO\u002fv5D3BSATVQHAjM5hp4bI9r+ciSymCornP377iQK+4es\u002fImjZaH2l4z+TTFDYzGDePyH8lOo+bs8\u002feZ2extu13r+9RwqNY0ruP5dcX6I9D+8\u002f3wajo7NB3j8UJymfBo34Pz7cIsBK4AXAtFYTZ\u002fIr8D+TaJ88ryvNPzALyj+Jgdu\u002fLem3tdmQxz8P0d0hX8X+v99BZLnM\u002fba\u002fpa75eY7e5D8SR\u002fyb4VMAQDxb1LCC5eu\u002fbLf8nrs\u002fvT9IZRuXQPbxv3WC4TMgz+s\u002fN5cthagk4z+xjD2U\u002fj7Uv+b\u002fJYSxZtQ\u002fJZBetzHhtT+\u002fTzPUqFPpP4cLzqtppOm\u002fkNvyJ258tT+ArCetLXLEv4QDQsi6yvi\u002fjo8FTRLi5T9BoR0xkYvbP6ixpBdwV9g\u002fGSbIkgSztj8="},"type":"scatter3d"},{"hovertemplate":"PC1: 92.5% variance\u003cextra\u003e\u003c\u002fextra\u003e","line":{"color":"rgb(255, 107, 107)","width":8},"mode":"lines","name":"PC1 (92.5% var)","x":[0,1.7662896177898082],"y":[0,1.7110677685029807],"z":[0,1.718274738706872],"type":"scatter3d"},{"colorscale":[[0,"rgb(255, 107, 107)"],[1,"rgb(255, 107, 107)"]],"hoverinfo":"skip","name":"PC1 direction","showlegend":false,"showscale":false,"u":[0.35325792355796165],"v":[0.34221355370059614],"w":[0.3436549477413744],"x":[1.7662896177898082],"y":[1.7110677685029807],"z":[1.718274738706872],"type":"cone"},{"hovertemplate":"PC2: 5.6% variance\u003cextra\u003e\u003c\u002fextra\u003e","line":{"color":"rgb(78, 205, 196)","width":8},"mode":"lines","name":"PC2 (5.6% var)","x":[0,-0.13239086565695762],"y":[0,2.190647764792686],"z":[0,-2.045369166996366],"type":"scatter3d"},{"colorscale":[[0,"rgb(78, 205, 196)"],[1,"rgb(78, 205, 196)"]],"hoverinfo":"skip","name":"PC2 direction","showlegend":false,"showscale":false,"u":[-0.026478173131391527],"v":[0.43812955295853717],"w":[-0.4090738333992732],"x":[-0.13239086565695762],"y":[2.190647764792686],"z":[-2.045369166996366],"type":"cone"},{"hovertemplate":"PC3: 2.0% variance\u003cextra\u003e\u003c\u002fextra\u003e","line":{"color":"rgb(69, 183, 209)","width":8},"mode":"lines","name":"PC3 (2.0% var)","x":[0,2.4212999906617387],"y":[0,-1.1284101480397286],"z":[0,-1.3652827154191998],"type":"scatter3d"},{"colorscale":[[0,"rgb(69, 183, 209)"],[1,"rgb(69, 183, 209)"]],"hoverinfo":"skip","name":"PC3 direction","showlegend":false,"showscale":false,"u":[0.48425999813234777],"v":[-0.22568202960794573],"w":[-0.27305654308384],"x":[2.4212999906617387],"y":[-1.1284101480397286],"z":[-1.3652827154191998],"type":"cone"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"title":{"font":{"size":16},"text":"\u003cb\u003eInteractive 3D PCA Visualization\u003c\u002fb\u003e\u003cbr\u003e\u003csub\u003eRotate to see principal component directions!\u003c\u002fsub\u003e"},"scene":{"camera":{"eye":{"x":1.5,"y":1.5,"z":1.2}},"xaxis":{"title":{"text":"Square Feet (standardized)"}},"yaxis":{"title":{"text":"Bedrooms (standardized)"}},"zaxis":{"title":{"text":"Bathrooms (standardized)"}},"aspectmode":"cube"},"margin":{"l":0,"r":0,"t":60,"b":0},"legend":{"yanchor":"top","y":0.99,"xanchor":"left","x":0.01,"bgcolor":"rgba(255, 255, 255, 0.8)"},"height":600},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('c4c9ded2-6590-4e5e-907e-7ace3f2f96c8');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Variance explained by each component:
  PC1: 92.5%
  PC2: 5.6%
  PC3: 2.0%

PC1 captures most variance because sq ft, bedrooms, and bathrooms are all correlated!</code></pre>
</div>
</div>
<aside class="notes">
<p><strong>Interpreting the Principal Components:</strong></p>
<p><strong>PC1 (Red arrow - ~80-85% of variance):</strong> - Points in the direction where houses vary the MOST - Represents ‚ÄúOverall House Size‚Äù - a composite measure combining all three features - High PC1 score = large house with many bedrooms and bathrooms - Low PC1 score = small house with few bedrooms and bathrooms - This makes sense because sq ft, bedrooms, and bathrooms are all highly correlated - they increase together - Notice how PC1 points diagonally through the data cloud in the direction of maximum spread</p>
<p><strong>PC2 (Teal arrow - ~10-15% of variance):</strong> - Perpendicular to PC1, captures the next-most variation - Might represent ‚ÄúLayout efficiency‚Äù or deviations from the typical size relationship - Example: A house with more bedrooms than expected for its square footage (positive PC2) vs.&nbsp;fewer bedrooms (negative PC2) - This captures residual variation NOT explained by overall size</p>
<p><strong>PC3 (Blue arrow - ~5-10% of variance):</strong> - Perpendicular to both PC1 and PC2 - Captures very small remaining variations - Might represent specific bathroom/bedroom trade-offs - Often this component is mostly noise and could be dropped</p>
<p><strong>Teaching points:</strong> - Rotate the plot to show students how PC1 aligns with the ‚Äúlongest‚Äù dimension of the data cloud - Show how PC2 and PC3 are at right angles to PC1 (orthogonal/uncorrelated) - Emphasize that PC1 alone captures 80%+ of the variation, so we could reduce from 3 features to 1 component with minimal information loss - Ask: ‚ÄúIf we only kept PC1, what information would we lose?‚Äù (Answer: The ability to distinguish houses with unusual bedroom/bathroom configurations for their size)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-apartment-finding-analogy" class="slide level2 smaller">
<h2>The Apartment-Finding Analogy</h2>
<p>Imagine tracking 10 apartment features: rent, sq ft, distance from downtown, bedrooms, building age, floor number, etc.</p>
<p><strong>You might notice correlations:</strong></p>
<ul>
<li>Larger apartments ‚Üí more bedrooms, more bathrooms</li>
<li>Newer buildings ‚Üí farther from downtown, higher rent</li>
<li>Higher floors ‚Üí better views, cost more</li>
</ul>
<p><strong>PCA would identify underlying factors:</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><strong>PC1: ‚ÄúSize &amp; Space‚Äù</strong></p>
<ul>
<li>Square footage: ‚úì</li>
<li>Bedrooms: ‚úì</li>
<li>Bathrooms: ‚úì</li>
<li>Closet space: ‚úì</li>
</ul>
<p><em>Captures 50% of variance</em></p>
</div><div class="column" style="width:33%;">
<p><strong>PC2: ‚ÄúLocation &amp; Age‚Äù</strong></p>
<ul>
<li>Distance to downtown: ‚úì</li>
<li>Building age: ‚úì</li>
<li>Neighborhood rating: ‚úì</li>
</ul>
<p><em>Captures 25% of variance</em></p>
</div><div class="column" style="width:33%;">
<p><strong>PC3: ‚ÄúLuxury &amp; Amenities‚Äù</strong></p>
<ul>
<li>Floor number: ‚úì</li>
<li>Building finishes: ‚úì</li>
<li>Gym/pool access: ‚úì</li>
</ul>
<p><em>Captures 15% of variance</em></p>
</div></div>
<p><strong>Result</strong>: Instead of tracking 10 correlated features, you have 3 uncorrelated components capturing 90% of information!</p>
</section>
<section id="step-1-the-original-data" class="slide level2 smaller">
<h2>Step 1: The Original Data</h2>
<p>Let‚Äôs apply PCA to a medical dataset with <strong>569 patients</strong> and <strong>30 features</strong> measuring tumor characteristics:</p>
<div id="19d21ff2" class="cell" data-execution_count="11">
<div class="cell-output cell-output-display" data-execution_count="214">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">radius_mean</th>
<th data-quarto-table-cell-role="th">texture_mean</th>
<th data-quarto-table-cell-role="th">perimeter_mean</th>
<th data-quarto-table-cell-role="th">area_mean</th>
<th data-quarto-table-cell-role="th">smoothness_mean</th>
<th data-quarto-table-cell-role="th">compactness_mean</th>
<th data-quarto-table-cell-role="th">concavity_mean</th>
<th data-quarto-table-cell-role="th">concave points_mean</th>
<th data-quarto-table-cell-role="th">symmetry_mean</th>
<th data-quarto-table-cell-role="th">fractal_dimension_mean</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">radius_worst</th>
<th data-quarto-table-cell-role="th">texture_worst</th>
<th data-quarto-table-cell-role="th">perimeter_worst</th>
<th data-quarto-table-cell-role="th">area_worst</th>
<th data-quarto-table-cell-role="th">smoothness_worst</th>
<th data-quarto-table-cell-role="th">compactness_worst</th>
<th data-quarto-table-cell-role="th">concavity_worst</th>
<th data-quarto-table-cell-role="th">concave points_worst</th>
<th data-quarto-table-cell-role="th">symmetry_worst</th>
<th data-quarto-table-cell-role="th">fractal_dimension_worst</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>17.99</td>
<td>10.38</td>
<td>122.80</td>
<td>1001.0</td>
<td>0.11840</td>
<td>0.27760</td>
<td>0.30010</td>
<td>0.14710</td>
<td>0.2419</td>
<td>0.07871</td>
<td>...</td>
<td>25.380</td>
<td>17.33</td>
<td>184.60</td>
<td>2019.0</td>
<td>0.16220</td>
<td>0.66560</td>
<td>0.7119</td>
<td>0.2654</td>
<td>0.4601</td>
<td>0.11890</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>20.57</td>
<td>17.77</td>
<td>132.90</td>
<td>1326.0</td>
<td>0.08474</td>
<td>0.07864</td>
<td>0.08690</td>
<td>0.07017</td>
<td>0.1812</td>
<td>0.05667</td>
<td>...</td>
<td>24.990</td>
<td>23.41</td>
<td>158.80</td>
<td>1956.0</td>
<td>0.12380</td>
<td>0.18660</td>
<td>0.2416</td>
<td>0.1860</td>
<td>0.2750</td>
<td>0.08902</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>19.69</td>
<td>21.25</td>
<td>130.00</td>
<td>1203.0</td>
<td>0.10960</td>
<td>0.15990</td>
<td>0.19740</td>
<td>0.12790</td>
<td>0.2069</td>
<td>0.05999</td>
<td>...</td>
<td>23.570</td>
<td>25.53</td>
<td>152.50</td>
<td>1709.0</td>
<td>0.14440</td>
<td>0.42450</td>
<td>0.4504</td>
<td>0.2430</td>
<td>0.3613</td>
<td>0.08758</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>11.42</td>
<td>20.38</td>
<td>77.58</td>
<td>386.1</td>
<td>0.14250</td>
<td>0.28390</td>
<td>0.24140</td>
<td>0.10520</td>
<td>0.2597</td>
<td>0.09744</td>
<td>...</td>
<td>14.910</td>
<td>26.50</td>
<td>98.87</td>
<td>567.7</td>
<td>0.20980</td>
<td>0.86630</td>
<td>0.6869</td>
<td>0.2575</td>
<td>0.6638</td>
<td>0.17300</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>20.29</td>
<td>14.34</td>
<td>135.10</td>
<td>1297.0</td>
<td>0.10030</td>
<td>0.13280</td>
<td>0.19800</td>
<td>0.10430</td>
<td>0.1809</td>
<td>0.05883</td>
<td>...</td>
<td>22.540</td>
<td>16.67</td>
<td>152.20</td>
<td>1575.0</td>
<td>0.13740</td>
<td>0.20500</td>
<td>0.4000</td>
<td>0.1625</td>
<td>0.2364</td>
<td>0.07678</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">...</th>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">564</th>
<td>21.56</td>
<td>22.39</td>
<td>142.00</td>
<td>1479.0</td>
<td>0.11100</td>
<td>0.11590</td>
<td>0.24390</td>
<td>0.13890</td>
<td>0.1726</td>
<td>0.05623</td>
<td>...</td>
<td>25.450</td>
<td>26.40</td>
<td>166.10</td>
<td>2027.0</td>
<td>0.14100</td>
<td>0.21130</td>
<td>0.4107</td>
<td>0.2216</td>
<td>0.2060</td>
<td>0.07115</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">565</th>
<td>20.13</td>
<td>28.25</td>
<td>131.20</td>
<td>1261.0</td>
<td>0.09780</td>
<td>0.10340</td>
<td>0.14400</td>
<td>0.09791</td>
<td>0.1752</td>
<td>0.05533</td>
<td>...</td>
<td>23.690</td>
<td>38.25</td>
<td>155.00</td>
<td>1731.0</td>
<td>0.11660</td>
<td>0.19220</td>
<td>0.3215</td>
<td>0.1628</td>
<td>0.2572</td>
<td>0.06637</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">566</th>
<td>16.60</td>
<td>28.08</td>
<td>108.30</td>
<td>858.1</td>
<td>0.08455</td>
<td>0.10230</td>
<td>0.09251</td>
<td>0.05302</td>
<td>0.1590</td>
<td>0.05648</td>
<td>...</td>
<td>18.980</td>
<td>34.12</td>
<td>126.70</td>
<td>1124.0</td>
<td>0.11390</td>
<td>0.30940</td>
<td>0.3403</td>
<td>0.1418</td>
<td>0.2218</td>
<td>0.07820</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">567</th>
<td>20.60</td>
<td>29.33</td>
<td>140.10</td>
<td>1265.0</td>
<td>0.11780</td>
<td>0.27700</td>
<td>0.35140</td>
<td>0.15200</td>
<td>0.2397</td>
<td>0.07016</td>
<td>...</td>
<td>25.740</td>
<td>39.42</td>
<td>184.60</td>
<td>1821.0</td>
<td>0.16500</td>
<td>0.86810</td>
<td>0.9387</td>
<td>0.2650</td>
<td>0.4087</td>
<td>0.12400</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">568</th>
<td>7.76</td>
<td>24.54</td>
<td>47.92</td>
<td>181.0</td>
<td>0.05263</td>
<td>0.04362</td>
<td>0.00000</td>
<td>0.00000</td>
<td>0.1587</td>
<td>0.05884</td>
<td>...</td>
<td>9.456</td>
<td>30.37</td>
<td>59.16</td>
<td>268.6</td>
<td>0.08996</td>
<td>0.06444</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.2871</td>
<td>0.07039</td>
</tr>
</tbody>
</table>

<p>569 rows √ó 30 columns</p>
</div>
</div>
</div>
<aside class="notes">
<p>Point out that we have 30 features per patient - way too many to visualize or easily interpret. This is a perfect use case for PCA to reduce dimensionality.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="step-2-standardize-and-apply-pca" class="slide level2 smaller scrollable">
<h2>Step 2: Standardize and Apply PCA</h2>
<div id="5bf9de4f" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6" data-code-line-numbers="1-7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href=""></a><span class="co"># Step 1: Standardize (critical for PCA!)</span></span>
<span id="cb6-2"><a href=""></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb6-3"><a href=""></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb6-4"><a href=""></a></span>
<span id="cb6-5"><a href=""></a><span class="co"># Step 2: Fit PCA to create all 30 principal components</span></span>
<span id="cb6-6"><a href=""></a>pca_full <span class="op">=</span> PCA()</span>
<span id="cb6-7"><a href=""></a>X_pca <span class="op">=</span> pca_full.fit_transform(X_scaled)</span>
<span id="cb6-8"><a href=""></a></span>
<span id="cb6-9"><a href=""></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Original data: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-10"><a href=""></a><span class="bu">print</span>(<span class="ss">f"PCA-transformed data: </span><span class="sc">{</span>X_pca<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-11"><a href=""></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">First few patients in PC space:"</span>)</span>
<span id="cb6-12"><a href=""></a>pd.DataFrame(X_pca[:<span class="dv">5</span>, :<span class="dv">5</span>],</span>
<span id="cb6-13"><a href=""></a>             columns<span class="op">=</span>[<span class="ss">f'PC</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>)]).<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Original data: (569, 30)
PCA-transformed data: (569, 30)

First few patients in PC space:</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="215">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">PC1</th>
<th data-quarto-table-cell-role="th">PC2</th>
<th data-quarto-table-cell-role="th">PC3</th>
<th data-quarto-table-cell-role="th">PC4</th>
<th data-quarto-table-cell-role="th">PC5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>9.193</td>
<td>1.949</td>
<td>-1.123</td>
<td>-3.634</td>
<td>1.195</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>2.388</td>
<td>-3.768</td>
<td>-0.529</td>
<td>-1.118</td>
<td>-0.622</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>5.734</td>
<td>-1.075</td>
<td>-0.552</td>
<td>-0.912</td>
<td>0.177</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>7.123</td>
<td>10.276</td>
<td>-3.233</td>
<td>-0.153</td>
<td>2.961</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>3.935</td>
<td>-1.948</td>
<td>1.390</td>
<td>-2.941</td>
<td>-0.547</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<aside class="notes">
<p>Emphasize that standardization is CRITICAL for PCA‚Äîotherwise features with large values will dominate. After PCA, we still have 30 components (same as features), but now they‚Äôre uncorrelated and ordered by variance. Show how the data looks completely different in PC space.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="step-3-how-many-components-should-we-keep" class="slide level2 smaller">
<h2>Step 3: How Many Components Should We Keep?</h2>
<div id="4670855b" class="cell columns column-output-location" data-execution_count="13">
<div class="column">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" data-code-line-numbers="4-5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href=""></a><span class="co"># Create scree plot</span></span>
<span id="cb8-2"><a href=""></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb8-3"><a href=""></a></span>
<span id="cb8-4"><a href=""></a><span class="co"># Individual variance explained</span></span>
<span id="cb8-5"><a href=""></a>variance_explained <span class="op">=</span> pca_full.explained_variance_ratio_</span>
<span id="cb8-6"><a href=""></a>ax1.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(variance_explained) <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb8-7"><a href=""></a>         variance_explained, <span class="st">'bo-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb8-8"><a href=""></a>ax1.set_xlabel(<span class="st">'Principal Component'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-9"><a href=""></a>ax1.set_ylabel(<span class="st">'Variance Explained'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-10"><a href=""></a>ax1.set_title(<span class="st">'Scree Plot: Variance per Component'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb8-11"><a href=""></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-12"><a href=""></a>ax1.axvline(x<span class="op">=</span><span class="dv">7</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Elbow around PC7'</span>)</span>
<span id="cb8-13"><a href=""></a>ax1.legend()</span>
<span id="cb8-14"><a href=""></a></span>
<span id="cb8-15"><a href=""></a><span class="co"># Cumulative variance explained</span></span>
<span id="cb8-16"><a href=""></a>cumsum <span class="op">=</span> np.cumsum(variance_explained)</span>
<span id="cb8-17"><a href=""></a>ax2.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(cumsum) <span class="op">+</span> <span class="dv">1</span>), cumsum, <span class="st">'ro-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb8-18"><a href=""></a>ax2.axhline(y<span class="op">=</span><span class="fl">0.95</span>, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'95% threshold'</span>)</span>
<span id="cb8-19"><a href=""></a>ax2.axhline(y<span class="op">=</span><span class="fl">0.90</span>, color<span class="op">=</span><span class="st">'orange'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'90% threshold'</span>)</span>
<span id="cb8-20"><a href=""></a>ax2.set_xlabel(<span class="st">'Number of Components'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-21"><a href=""></a>ax2.set_ylabel(<span class="st">'Cumulative Variance'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb8-22"><a href=""></a>ax2.set_title(<span class="st">'Cumulative Variance Explained'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb8-23"><a href=""></a>ax2.legend()</span>
<span id="cb8-24"><a href=""></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-25"><a href=""></a></span>
<span id="cb8-26"><a href=""></a><span class="co"># Find components needed for 95%</span></span>
<span id="cb8-27"><a href=""></a>n_95 <span class="op">=</span> np.argmax(cumsum <span class="op">&gt;=</span> <span class="fl">0.95</span>) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb8-28"><a href=""></a>ax2.axvline(x<span class="op">=</span>n_95, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb8-29"><a href=""></a>ax2.text(n_95 <span class="op">+</span> <span class="dv">1</span>, <span class="fl">0.5</span>, <span class="ss">f'</span><span class="sc">{</span>n_95<span class="sc">}</span><span class="ss"> components</span><span class="ch">\n</span><span class="ss">for 95% variance'</span>,</span>
<span id="cb8-30"><a href=""></a>         fontsize<span class="op">=</span><span class="dv">10</span>, bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">'round'</span>, facecolor<span class="op">=</span><span class="st">'lightgreen'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>))</span>
<span id="cb8-31"><a href=""></a></span>
<span id="cb8-32"><a href=""></a>plt.tight_layout()</span>
<span id="cb8-33"><a href=""></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div><div class="column">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w13_tuesday_files/figure-revealjs/cell-14-output-1.png" width="565" height="565"></p>
</figure>
</div>
</div>
</div></div>
<aside class="notes">
<p>The elbow is around PC6-7. We can reduce from 30 features to just 7 components while keeping 95% of the information!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="interactive-activity-reading-scree-plots" class="slide level2 smaller">
<h2>Interactive Activity: Reading Scree Plots</h2>
<div class="columns">
<div class="column" style="width:70%;">
<div class="callout callout-none no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Your Turn</strong></p>
</div>
<div class="callout-content">
<p>You‚Äôre analyzing customer behavior with 50 features. After running PCA, you get:</p>
<ul>
<li>PC1: 35% variance</li>
<li>PC2: 20% variance</li>
<li>PC3: 12% variance</li>
<li>PC4: 8% variance</li>
<li>PC5: 6% variance</li>
<li>PC6-50: 19% variance (combined)</li>
</ul>
<p><strong>Discuss with your neighbor:</strong></p>
<ol type="1">
<li>How many components would you keep? Why?</li>
<li>If you keep just PC1 and PC2, what percentage of information do you retain?</li>
<li>What are you trading off when you reduce from 50 to 5 features?</li>
</ol>
</div>
</div>
</div>
</div><div class="column" style="width:30%;">
<center>
<div id="3minScree">

</div>
<script src="_extensions/produnis/timer/timer.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        initializeTimer("3minScree", 180, "slide");
    });
</script>
</center>
</div></div>
<p>Then we‚Äôll take a few responses‚Ä¶</p>
<aside class="notes">
<p>Answer: PC1-4 capture 75%, PC1-5 capture 81%. Good tradeoff depends on use case. Trading simplicity for some information loss.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-do-principal-components-mean" class="slide level2 smaller scrollable">
<h2>What Do Principal Components Mean?</h2>
<p><strong>Principal components are weighted combinations of original features.</strong></p>
<p>Let‚Äôs look at what contributes to PC1 in our breast cancer data:</p>
<div id="b2f2ff70" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href=""></a><span class="co"># Refit with more components to examine</span></span>
<span id="cb9-2"><a href=""></a>pca_7 <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb9-3"><a href=""></a>pca_7.fit(X_scaled)</span>
<span id="cb9-4"><a href=""></a></span>
<span id="cb9-5"><a href=""></a><span class="co"># Look at loadings (weights) for PC1</span></span>
<span id="cb9-6"><a href=""></a>pc1_loadings <span class="op">=</span> pd.DataFrame({</span>
<span id="cb9-7"><a href=""></a>    <span class="st">'feature'</span>: X.columns,</span>
<span id="cb9-8"><a href=""></a>    <span class="st">'loading'</span>: pca_7.components_[<span class="dv">0</span>]</span>
<span id="cb9-9"><a href=""></a>}).sort_values(<span class="st">'loading'</span>, key<span class="op">=</span><span class="bu">abs</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-10"><a href=""></a></span>
<span id="cb9-11"><a href=""></a><span class="bu">print</span>(<span class="st">"Top 10 features contributing to PC1:"</span>)</span>
<span id="cb9-12"><a href=""></a><span class="bu">print</span>(pc1_loadings.head(<span class="dv">10</span>).to_string(index<span class="op">=</span><span class="va">False</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 10 features contributing to PC1:
             feature  loading
 concave points_mean 0.260854
      concavity_mean 0.258400
concave points_worst 0.250886
    compactness_mean 0.239285
     perimeter_worst 0.236640
     concavity_worst 0.228768
        radius_worst 0.227997
      perimeter_mean 0.227537
          area_worst 0.224871
           area_mean 0.220995</code></pre>
</div>
</div>
<p><strong>Interpretation</strong>: PC1 loads heavily on features related to tumor size, texture, and shape irregularity. It represents <strong>‚Äúoverall tumor severity‚Äù</strong>‚Äîhigh PC1 means larger, more irregular tumors.</p>
<aside class="notes">
<p>This is how you interpret principal components: look at which original features have the highest loadings (positive or negative). Group them conceptually.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="demo-visualizing-high-dimensional-data-with-pca" class="slide level2 smaller">
<h2>Demo: Visualizing High-Dimensional Data with PCA</h2>
<p>One powerful use of PCA: reducing to 2D for visualization!</p>
<div id="beebb78e" class="cell" data-execution_count="15">
<div class="cell-output cell-output-stdout">
<pre><code>Reduced from 30 features to 2 components
Retained 63.2% of variance</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w13_tuesday_files/figure-revealjs/cell-16-output-2.png" width="757" height="421"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p><strong>Interpreting the 2D PCA Plot:</strong></p>
<p>Amazing! We can see clear separation between malignant and benign tumors using just 2 components. This was impossible to visualize with 30 original features.</p>
<p><strong>What PC1 represents (X-axis, ~44% of variance):</strong> - PC1 captures ‚ÄúOverall Tumor Severity‚Äù - Loads heavily on features like: radius_worst, perimeter_worst, area_worst, concave points_worst, radius_mean, perimeter_mean, area_mean - These are all measures of tumor SIZE and IRREGULARITY - <strong>High PC1 (moving right)</strong> = Larger tumors with more irregular shapes ‚Üí More likely MALIGNANT (red points) - <strong>Low PC1 (moving left)</strong> = Smaller, more regular tumors ‚Üí More likely BENIGN (teal points) - Notice how malignant tumors cluster on the right (high PC1) and benign on the left (low PC1)</p>
<p><strong>What PC2 represents (Y-axis, ~19% of variance):</strong> - PC2 captures secondary tumor characteristics not explained by overall size - Likely related to texture variation, symmetry, and smoothness - Loads on features like: texture_worst, smoothness_worst, symmetry measures - <strong>High PC2</strong> = Tumors with high texture variation and less smoothness - <strong>Low PC2</strong> = Smoother, more uniform texture - There‚Äôs some overlap here, but generally malignant tumors show more variation</p>
<p><strong>Key Teaching Points:</strong> - These 2 components alone (PC1 + PC2) capture ~63% of total variance from 30 features - PC1 is doing most of the ‚Äúheavy lifting‚Äù for separating malignant vs.&nbsp;benign - The clear visual separation shows why PCA is powerful: it found the most discriminating directions in the data - Point out the cluster centers: malignant tumors (right side, higher PC1) vs.&nbsp;benign (left side, lower PC1) - Ask: ‚ÄúIf you had to diagnose with just these 2 numbers (PC1, PC2), how would you do it?‚Äù (Answer: High PC1 ‚Üí likely malignant)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="pca-as-feature-engineering-for-machine-learning" class="slide level2 smaller">
<h2>PCA as Feature Engineering for Machine Learning</h2>
<p>Another powerful use case: <strong>Use PCA-transformed features as input to ML models</strong></p>
<p><strong>Why use PCA before modeling?</strong></p>
<ul>
<li><strong>Reduces overfitting</strong> - Fewer features = simpler model = better generalization</li>
<li><strong>Speeds up training</strong> - Fewer features = faster computation</li>
<li><strong>Handles multicollinearity</strong> - PCs are uncorrelated by design</li>
<li><strong>Removes noise</strong> - Minor components often represent noise</li>
</ul>
<p>Let‚Äôs compare model performance with and without PCA using our breast cancer data:</p>
<aside class="notes">
<p>Emphasize that PCA is often used as a preprocessing step in ML pipelines, not just for visualization. This is a key practical application that students will use in real projects.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="model-comparison-original-vs.-pca-features" class="slide level2 smaller scrollable">
<h2>Model Comparison: Original vs.&nbsp;PCA Features</h2>
<div id="9c283d92" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb12-2"><a href=""></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb12-3"><a href=""></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score, recall_score, f1_score</span>
<span id="cb12-4"><a href=""></a></span>
<span id="cb12-5"><a href=""></a><span class="co"># Split into train/test</span></span>
<span id="cb12-6"><a href=""></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb12-7"><a href=""></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb12-8"><a href=""></a>)</span>
<span id="cb12-9"><a href=""></a></span>
<span id="cb12-10"><a href=""></a><span class="co"># Standardize the features (critical!)</span></span>
<span id="cb12-11"><a href=""></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb12-12"><a href=""></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb12-13"><a href=""></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb12-14"><a href=""></a></span>
<span id="cb12-15"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Original training data shape: </span><span class="sc">{</span>X_train_scaled<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original training data shape: (398, 30)</code></pre>
</div>
</div>
<div id="bf92a651" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href=""></a><span class="co"># Model 1: All 30 original features</span></span>
<span id="cb14-2"><a href=""></a>model_original <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">5000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-3"><a href=""></a>model_original.fit(X_train_scaled, y_train)</span>
<span id="cb14-4"><a href=""></a>y_pred_original <span class="op">=</span> model_original.predict(X_test_scaled)</span>
<span id="cb14-5"><a href=""></a></span>
<span id="cb14-6"><a href=""></a><span class="co"># Model 2: 7 PCA components (from earlier analysis)</span></span>
<span id="cb14-7"><a href=""></a>pca_7 <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb14-8"><a href=""></a>X_train_pca <span class="op">=</span> pca_7.fit_transform(X_train_scaled)</span>
<span id="cb14-9"><a href=""></a>X_test_pca <span class="op">=</span> pca_7.transform(X_test_scaled)</span>
<span id="cb14-10"><a href=""></a></span>
<span id="cb14-11"><a href=""></a>model_pca <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">5000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-12"><a href=""></a>model_pca.fit(X_train_pca, y_train)</span>
<span id="cb14-13"><a href=""></a>y_pred_pca <span class="op">=</span> model_pca.predict(X_test_pca)</span>
<span id="cb14-14"><a href=""></a></span>
<span id="cb14-15"><a href=""></a><span class="co"># Calculate all metrics for both models</span></span>
<span id="cb14-16"><a href=""></a>metrics_original <span class="op">=</span> {</span>
<span id="cb14-17"><a href=""></a>    <span class="st">'Accuracy'</span>: accuracy_score(y_test, y_pred_original),</span>
<span id="cb14-18"><a href=""></a>    <span class="st">'Precision'</span>: precision_score(y_test, y_pred_original),</span>
<span id="cb14-19"><a href=""></a>    <span class="st">'Recall'</span>: recall_score(y_test, y_pred_original),</span>
<span id="cb14-20"><a href=""></a>    <span class="st">'F1-Score'</span>: f1_score(y_test, y_pred_original)</span>
<span id="cb14-21"><a href=""></a>}</span>
<span id="cb14-22"><a href=""></a></span>
<span id="cb14-23"><a href=""></a>metrics_pca <span class="op">=</span> {</span>
<span id="cb14-24"><a href=""></a>    <span class="st">'Accuracy'</span>: accuracy_score(y_test, y_pred_pca),</span>
<span id="cb14-25"><a href=""></a>    <span class="st">'Precision'</span>: precision_score(y_test, y_pred_pca),</span>
<span id="cb14-26"><a href=""></a>    <span class="st">'Recall'</span>: recall_score(y_test, y_pred_pca),</span>
<span id="cb14-27"><a href=""></a>    <span class="st">'F1-Score'</span>: f1_score(y_test, y_pred_pca)</span>
<span id="cb14-28"><a href=""></a>}</span>
<span id="cb14-29"><a href=""></a></span>
<span id="cb14-30"><a href=""></a><span class="co"># Display comparison table</span></span>
<span id="cb14-31"><a href=""></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'Model'</span><span class="sc">:&lt;25}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Features'</span><span class="sc">:&lt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Accuracy'</span><span class="sc">:&lt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Precision'</span><span class="sc">:&lt;11}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Recall'</span><span class="sc">:&lt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'F1-Score'</span><span class="sc">:&lt;10}</span><span class="ss">"</span>)</span>
<span id="cb14-32"><a href=""></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'-'</span><span class="op">*</span><span class="dv">85</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-33"><a href=""></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Original Features'</span><span class="sc">:&lt;25}</span><span class="ss"> </span><span class="sc">{</span><span class="dv">30</span><span class="sc">:&lt;10}</span><span class="ss"> </span><span class="sc">{</span>metrics_original[<span class="st">'Accuracy'</span>]<span class="sc">:&lt;10.3f}</span><span class="ss"> </span><span class="sc">{</span>metrics_original[<span class="st">'Precision'</span>]<span class="sc">:&lt;11.3f}</span><span class="ss"> </span><span class="sc">{</span>metrics_original[<span class="st">'Recall'</span>]<span class="sc">:&lt;10.3f}</span><span class="ss"> </span><span class="sc">{</span>metrics_original[<span class="st">'F1-Score'</span>]<span class="sc">:&lt;10.3f}</span><span class="ss">"</span>)</span>
<span id="cb14-34"><a href=""></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'PCA (7 components)'</span><span class="sc">:&lt;25}</span><span class="ss"> </span><span class="sc">{</span><span class="dv">7</span><span class="sc">:&lt;10}</span><span class="ss"> </span><span class="sc">{</span>metrics_pca[<span class="st">'Accuracy'</span>]<span class="sc">:&lt;10.3f}</span><span class="ss"> </span><span class="sc">{</span>metrics_pca[<span class="st">'Precision'</span>]<span class="sc">:&lt;11.3f}</span><span class="ss"> </span><span class="sc">{</span>metrics_pca[<span class="st">'Recall'</span>]<span class="sc">:&lt;10.3f}</span><span class="ss"> </span><span class="sc">{</span>metrics_pca[<span class="st">'F1-Score'</span>]<span class="sc">:&lt;10.3f}</span><span class="ss">"</span>)</span>
<span id="cb14-35"><a href=""></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Reduced features by </span><span class="sc">{</span>(<span class="dv">1</span> <span class="op">-</span> <span class="dv">7</span><span class="op">/</span><span class="dv">30</span>)<span class="op">*</span><span class="dv">100</span><span class="sc">:.0f}</span><span class="ss">% with minimal performance loss across all metrics!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Model                     Features   Accuracy   Precision   Recall     F1-Score  
-------------------------------------------------------------------------------------
Original Features         30         0.971      0.984       0.938      0.960     
PCA (7 components)        7          0.982      0.984       0.969      0.976     

Reduced features by 77% with minimal performance loss across all metrics!</code></pre>
</div>
</div>
<aside class="notes">
<p>Point out that performance is maintained across ALL metrics while reducing from 30 to 7 features (77% reduction). Show students that accuracy, precision, recall, and F1-score are all very similar between the two models. This demonstrates that PCA preserves the discriminative information needed for classification. The slight differences across metrics are often worth the benefits in speed, simplicity, and reduced overfitting.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="why-accept-slightly-lower-accuracy" class="slide level2 smaller scrollable">
<h2>Why Accept Slightly Lower Accuracy?</h2>
<p>Even if PCA features have slightly lower accuracy, the tradeoffs are often worth it:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Benefits of Using PCA:</strong></p>
<ol type="1">
<li><strong>Faster training &amp; prediction</strong>
<ul>
<li>7 features vs.&nbsp;30 = ~4√ó speedup</li>
<li>Matters for large datasets or complex models</li>
</ul></li>
<li><strong>Reduced overfitting risk</strong>
<ul>
<li>Simpler model = less prone to memorizing noise</li>
<li>Better generalization to new data</li>
</ul></li>
<li><strong>Eliminates multicollinearity</strong>
<ul>
<li>PCs are uncorrelated by design</li>
<li>Helps algorithms that assume independence</li>
</ul></li>
</ol>
</div><div class="column" style="width:50%;">
<p><strong>More Benefits:</strong></p>
<ol start="4" type="1">
<li><strong>Easier deployment</strong>
<ul>
<li>Smaller models are faster to deploy</li>
<li>Require less memory in production</li>
</ul></li>
<li><strong>Noise filtering</strong>
<ul>
<li>Discarding minor components removes noise</li>
<li>Can actually improve performance!</li>
</ul></li>
<li><strong>Scalability</strong>
<ul>
<li>With 100s-1000s of features, PCA becomes essential</li>
<li>Our 77% reduction would be even more dramatic</li>
</ul></li>
</ol>
</div></div>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>The Key Tradeoff</strong></p>
</div>
<div class="callout-content">
<p>PCA trades a small amount of accuracy for significant gains in speed, simplicity, and robustness. As datasets grow larger and wider, this tradeoff becomes increasingly favorable.</p>
</div>
</div>
</div>
</section>
<section id="using-clusteringpca-in-ml-pipelines" class="slide level2 smaller">
<h2>Using Clustering/PCA in ML Pipelines</h2>
<p><strong>Unsupervised methods often feed into supervised models:</strong></p>
<div class="cell" data-reveal="true" data-fig-width="12" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Raw Data&lt;br/&gt;100 features] --&gt; B[StandardScaler&lt;br/&gt;Standardize]
    B --&gt; C{PCA&lt;br/&gt;Reduce to 20 components}
    C --&gt; D[K-Means&lt;br/&gt;Create 5 clusters]
    D --&gt; E[Add cluster labels&lt;br/&gt;as new feature]
    E --&gt; F[Supervised Model&lt;br/&gt;Random Forest&lt;br/&gt;Predict churn]

    style A fill:#f0f0f0
    style B fill:#FFE5B4
    style C fill:#FF6B6B
    style D fill:#4ECDC4
    style E fill:#45B7D1
    style F fill:#95E1D3
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><strong>Example workflow:</strong></p>
<ol type="1">
<li>Reduce 100 features to 20 components with PCA (noise reduction)</li>
<li>Cluster customers into 5 segments using K-Means on those 20 components</li>
<li>Add cluster ID as a categorical feature</li>
<li>Train a Random Forest to predict customer churn using PCA components + cluster ID</li>
</ol>
<p><strong>Benefit</strong>: Unsupervised learning creates better features for supervised learning!</p>
<aside class="notes">
<p>This is a very common pattern in practice. Clustering and dimension reduction as preprocessing steps for prediction models. Emphasize that PCA and clustering aren‚Äôt just standalone techniques‚Äîthey‚Äôre often combined and used to engineer features for supervised learning.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="key-takeaways-next-steps" class="title-slide slide level1 center" data-background="#43464B">
<h1>Key Takeaways &amp; Next Steps</h1>

</section>
<section id="key-takeaways" class="slide level2 smaller">
<h2>Key Takeaways</h2>
<ul>
<li><p><strong>Unsupervised learning discovers patterns without labels</strong> ‚Äì Use it when you want to explore data structure rather than predict outcomes</p></li>
<li><p><strong>Clustering groups similar observations</strong> ‚Äì K-Means is the workhorse for customer segmentation, but choosing K requires judgment (elbow method, silhouette scores, business constraints)</p></li>
<li><p><strong>PCA reduces dimensionality by creating uncorrelated components</strong> ‚Äì Compress 100 features to 10 components while retaining 90%+ of information. Use scree plots to choose how many components to keep.</p></li>
<li><p><strong>ALWAYS standardize features first</strong> ‚Äì Both K-Means and PCA are highly sensitive to feature scale. Forget this and your results will be dominated by large-scale features!</p></li>
<li><p><strong>Unsupervised ‚Üí Supervised pipeline</strong> ‚Äì Often you‚Äôll use clustering/PCA as preprocessing steps to create better features for supervised learning models</p></li>
</ul>
<aside class="notes">
<p>These are the core concepts. Emphasize that unsupervised learning is about exploration and feature engineering, not prediction accuracy.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="when-to-use-which-method" class="slide level2 smaller scrollable">
<h2>When to Use Which Method</h2>
<div class="cell" data-reveal="true" data-fig-width="12" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    Start[I have unlabeled data] --&gt; Q1{What's my goal?}

    Q1 --&gt;|Find groups&lt;br/&gt;in my data| C[Use Clustering]
    Q1 --&gt;|Reduce number&lt;br/&gt;of features| D[Use Dimension Reduction]
    Q1 --&gt;|Both!| Both[Use Both:&lt;br/&gt;PCA then Clustering]

    C --&gt; C1[K-Means:&lt;br/&gt;Customer segments&lt;br/&gt;Product groups&lt;br/&gt;Market segments]

    D --&gt; D1[PCA:&lt;br/&gt;Feature compression&lt;br/&gt;Visualization&lt;br/&gt;Noise reduction]

    Both --&gt; B1[Common workflow:&lt;br/&gt;1. PCA to reduce features&lt;br/&gt;2. K-Means on components&lt;br/&gt;3. Use for supervised learning]

    style Start fill:#f0f0f0
    style Q1 fill:#43464B,color:#fff
    style C fill:#4ECDC4
    style D fill:#FF6B6B
    style Both fill:#45B7D1
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<aside class="notes">
<p>Help students build intuition for which tool fits which problem. Often you use both in sequence!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="connection-to-thursdays-lab" class="slide level2 smaller">
<h2>Connection to Thursday‚Äôs Lab</h2>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>This Week‚Äôs Lab Preview</strong></p>
</div>
<div class="callout-content">
<p>In Thursday‚Äôs lab, you‚Äôll get hands-on practice with:</p>
<ul>
<li><strong>Applying K-Means clustering</strong> to customer segmentation problems with real transaction data</li>
<li><strong>Implementing PCA</strong> to reduce high-dimensional data (like the Ames housing dataset)</li>
<li><strong>Combining both</strong> as a feature engineering step for a predictive model!</li>
</ul>
<p>Come prepared to apply today‚Äôs concepts! Bring questions about clustering vs.&nbsp;dimension reduction use cases.</p>
</div>
</div>
</div>
<aside class="notes">
<p>The lab will make all of this concrete. They‚Äôll see how clustering reveals customer segments and how PCA speeds up models while maintaining performance.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="looking-ahead" class="slide level2 smaller">
<h2>Looking Ahead</h2>
<p><strong>Btwn now &amp; Thursday:</strong> Complete reading Chapters 28-30</p>
<p><strong>Thursday Lab:</strong> Hands-on unsupervised learning exercises</p>
<p><strong>Moving Foward:</strong> Course wrap-up &amp; Final Project</p>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p>Start reviewing the final project details!</p>
</div>
</div>
</div>
<aside class="notes">
<p>Remind them that the final project is coming up. Unsupervised learning can add a lot of value to their analyses.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="any-final-questions" class="slide level2 smaller">
<h2>Any Final Questions?</h2>
<ul>
<li>About clustering and K-Means?</li>
<li>About PCA and dimension reduction?</li>
<li>About when to use which method?</li>
<li>About Thursday‚Äôs lab?</li>
<li>About the final project?</li>
</ul>
<aside class="notes">
<p>Encourage them to come to office hours, especially if they‚Äôre working on final projects. Unsupervised learning can be tricky to get right.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<center>
<strong>See you Thursday for hands-on practice with clustering and PCA!</strong>
</center>

</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>BANA 4080</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="w13_tuesday_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="w13_tuesday_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="w13_tuesday_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="w13_tuesday_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="w13_tuesday_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="w13_tuesday_files/libs/revealjs/plugin/appearance/appearance.js"></script>
  <script src="w13_tuesday_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="w13_tuesday_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="w13_tuesday_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="w13_tuesday_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="w13_tuesday_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'appearance': {"hideagain":true,"delay":300,"debug":false,"appearevent":"slidetransitionend","autoappear":false,"autoelements":false,"appearparents":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, Appearance, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>