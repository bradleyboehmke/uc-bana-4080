<!DOCTYPE html>
<html lang="en"><head>
<script src="w11_tuesday_files/libs/clipboard/clipboard.min.js"></script>
<script src="w11_tuesday_files/libs/quarto-html/tabby.min.js"></script>
<script src="w11_tuesday_files/libs/quarto-html/popper.min.js"></script>
<script src="w11_tuesday_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="w11_tuesday_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="w11_tuesday_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="w11_tuesday_files/libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="w11_tuesday_files/libs/quarto-contrib/quarto-timer-1.0.0/timer.js"></script>
<link href="w11_tuesday_files/libs/quarto-contrib/quarto-timer-1.0.0/timer.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.31">

  <title>Week 11 – Tree-Based Models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="w11_tuesday_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="w11_tuesday_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="w11_tuesday_files/libs/revealjs/dist/theme/quarto-f563837468303362081e247dddd440d0.css">
  <link rel="stylesheet" href="styles.css">
  <link href="w11_tuesday_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="w11_tuesday_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="w11_tuesday_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="w11_tuesday_files/libs/revealjs/plugin/appearance/appearance.css" rel="stylesheet">
  <link href="w11_tuesday_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <meta name="mermaid-theme" content="neutral">
  <script src="w11_tuesday_files/libs/quarto-diagram/mermaid.min.js"></script>
  <script src="w11_tuesday_files/libs/quarto-diagram/mermaid-init.js"></script>
  <link href="w11_tuesday_files/libs/quarto-diagram/mermaid.css" rel="stylesheet">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="images/trees-background.jpeg" data-background-opacity="1.0" data-background-size="cover" class="quarto-title-block center">
  <h1 class="title">Week 11 – Tree-Based Models</h1>
  <p class="subtitle">Decision Trees, Random Forests, and Feature Importance</p>

<div class="quarto-title-authors">
</div>

</section>
<section id="welcome-to-week-11" class="slide level2">
<h2>Welcome to Week 11</h2>
<ul>
<li><p>Quick overview of today’s plan:</p>
<ul>
<li><strong>Decision Trees</strong>: Learning to ask yes/no questions</li>
<li><strong>Random Forests</strong>: Combining trees for better predictions</li>
<li><strong>Feature Importance</strong>: Understanding what drives predictions</li>
<li><strong>Hands-on demos</strong>: Build and interpret tree-based models</li>
</ul></li>
</ul>
<aside class="notes">
<p>Today introduces Module 10 content - tree-based models. This is a gentle introduction before students read chapters 25-27. Thursday’s lab will reinforce with hands-on practice.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section>
<section id="discussion-homework-questions" class="title-slide slide level1 center" data-background="#43464B">
<h1>Discussion: Homework &amp; Questions</h1>

</section>
<section id="questions-from-week-10" class="slide level2 smaller">
<h2>Questions from Week 10?</h2>
<ul>
<li>Any questions about linear or logistic regression?</li>
<li>Model evaluation metrics clear?</li>
<li>Confusion about train/test splits?</li>
<li>Anything from the quiz or class lab?</li>
<li>Time to ask!</li>
</ul>
<div class="fragment">
<div class="columns">
<div class="column" style="width:70%;">
<div class="callout callout-none no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Activity</strong></p>
</div>
<div class="callout-content">
<p>Converse with your neighbor and identify…</p>
<ul>
<li>1 new thing you learned last week that you thought was clear and explained well</li>
<li>1 thing we covered last week that is still confusing</li>
</ul>
</div>
</div>
</div>
</div><div class="column" style="width:30%;">
<center>
<div id="3minReview">

</div>
<script src="_extensions/produnis/timer/timer.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        initializeTimer("3minReview", 180, "slide");
    });
</script>
</center>
</div></div>
<aside class="notes">
<p>Give students 3 minutes to discuss. Then take 2-3 volunteers to share. This helps surface any lingering confusion before moving to new material. Transition: “Today we’re moving beyond linear models to explore how trees make decisions.”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section></section>
<section>
<section id="decision-trees-learning-to-ask-questions" class="title-slide slide level1 center" data-background="#43464B">
<h1>Decision Trees: Learning to Ask Questions</h1>

</section>
<section id="linear-models-struggle-with-non-linear-patterns" class="slide level2 smaller">
<h2>Linear Models Struggle with Non-Linear Patterns</h2>
<div id="e6eecbeb" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-2-output-1.png" class="quarto-figure quarto-figure-center" width="758" height="374"></p>
</figure>
</div>
</div>
</div>
<center>
<div class="callout callout-caution callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Caution</strong></p>
</div>
<div class="callout-content">
<p><strong>Real business data rarely follows straight lines</strong></p>
</div>
</div>
</div>
</center>
<aside class="notes">
<p>Show this plot - no need for lengthy explanation. The visual tells the story: steep early gains, then plateau. This is diminishing returns in action.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="linear-models-miss-interactions" class="slide level2 smaller">
<h2>Linear Models Miss Interactions</h2>
<p><br></p>
<div class="columns">
<div class="column" style="width:45%;">
<center>
<table class="caption-top">
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;"><strong>Premium Brand</strong></th>
<th style="text-align: center;"><strong>Unknown Brand</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>High Quality</strong></td>
<td style="text-align: center;">$200</td>
<td style="text-align: center;">$80</td>
</tr>
<tr class="even">
<td><strong>Low Quality</strong></td>
<td style="text-align: center;">$120</td>
<td style="text-align: center;">$40</td>
</tr>
</tbody>
</table>
</center>
</div><div class="column" style="width:10%;">

</div><div class="column" style="width:45%;">
<p><strong>The Pattern:</strong></p>
<p>High quality means different things in different contexts.</p>
<p>Linear models struggle to capture these interactions without manual specification.</p>
</div></div>
<p><br><br></p>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Same Quality → Different Prices (Context Matters!)</strong></p>
</div>
<div class="callout-content">
<p>Same quality product gets wildly different prices based on brand. Linear models assume quality has one fixed effect - but here it depends on context.</p>
</div>
</div>
</div>
<aside class="notes">
<p>Simple example: Same quality product gets wildly different prices based on brand. Linear models assume quality has one fixed effect - but here it depends on context. Trees discover these patterns automatically.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="linear-models-are-hard-to-explain" class="slide level2 smaller">
<h2>Linear Models Are Hard to Explain</h2>
<div class="callout callout-none no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Option 1: Linear Model</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[P(\text{default}) = \frac{1}{1+e^{-(\beta_0 + 0.0032 \cdot \text{balance} - 0.0015 \cdot \text{income} + ...)}}\]</span></p>
<p><br></p>
<p><em>“For each $100 increase in balance, the log-odds of default increase by 0.32…”</em></p>
</div>
</div>
</div>
<p><br></p>
<div class="callout callout-none no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Option 2: Decision Tree</strong></p>
</div>
<div class="callout-content">
<p><br></p>
<p><strong>If balance &gt; $1,200</strong> <strong>Then 85% default risk</strong></p>
<p><br><br></p>
<p><em>“If their balance is over $1,200 they have an 85% probability of defaulting.”</em></p>
</div>
</div>
</div>
<p><br></p>
<center>
<strong>Which would you present to your boss?</strong>
</center>
<aside class="notes">
<p>Left side shows the mathematical complexity of logistic regression. Right side shows a simple tree rule. Both models might have similar accuracy, but one is far easier to communicate and act upon.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-if-there-was-a-better-way" class="slide level2 smaller">
<h2>What If There Was a Better Way?</h2>
<p><br><br></p>
<center>
<p><strong>Decision trees offer:</strong></p>
<p>✓ Capture nonlinear patterns naturally</p>
<p>✓ Automatically discover thresholds</p>
<p>✓ Naturally handle interactions</p>
<p>✓ Create clear if-then rules</p>
<p>✓ Mirror human decision-making</p>
</center>
<aside class="notes">
<p>Transition slide. We’ve seen the problems with linear models. Now we introduce the solution: decision trees are designed specifically to handle these challenges.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="think-pair-share-your-decision-process" class="slide level2 smaller">
<h2>Think-Pair-Share: Your Decision Process</h2>
<p>Think about a decision you make regularly using yes/no questions…</p>
<div class="columns">
<div class="column" style="width:70%;">
<p><strong>Examples:</strong></p>
<ul>
<li>Deciding whether to approve a loan application</li>
<li>Choosing which restaurant to visit</li>
<li>Determining if a sales lead is worth pursuing</li>
<li>Diagnosing a technical problem</li>
</ul>
<p><strong>Discuss with your neighbor:</strong></p>
<ol type="1">
<li>What’s the first question you ask?</li>
<li>How does the answer change your next question?</li>
<li>How many questions until you reach a decision?</li>
</ol>
</div><div class="column" style="width:30%;">
<center>
<div id="3minDecision">

</div>
<script src="_extensions/produnis/timer/timer.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        initializeTimer("3minDecision", 180, "slide");
    });
</script>
</center>
</div></div>
<p>Then we’ll take a few responses…</p>
<aside class="notes">
<p>After 3 minutes, ask 2-3 students to share. Draw out the tree structure on the board if time permits. Key insight: “This sequential questioning is EXACTLY how decision trees work - but they learn the optimal questions from data!”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="decision-trees-the-if-else-of-ml" class="title-slide slide level1 center" data-background="#43464B">
<h1>Decision Trees: The if-else of ML!</h1>

</section>
<section id="how-decision-trees-work" class="slide level2 smaller">
<h2>How Decision Trees Work</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>The Process:</strong></p>
<ol type="1">
<li>Start with all your data</li>
<li>Ask a yes/no question that best separates the data</li>
<li>Split data into two groups based on the answer</li>
<li>Repeat for each group until you reach clear predictions</li>
</ol>
<p><strong>Example: Loan Approval</strong></p>
<pre><code>Income &gt; $50k?
├─ YES → Credit Score &gt; 700?
│         ├─ YES → APPROVE
│         └─ NO → REVIEW
└─ NO → Has Co-signer?
          ├─ YES → CONSIDER
          └─ NO → DENY</code></pre>
</div><div class="column" style="width:50%;">
<div class="cell" data-reveal="true" data-fig-width="5" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[Loan Application] --&gt; B{"Income &gt; 50K?"}
    B --&gt;|Yes| C{"Credit Score &gt; 700?"}
    B --&gt;|No| D{"Has Co-signer?"}
    C --&gt;|Yes| E[Approve]
    C --&gt;|No| F[Review]
    D --&gt;|Yes| G[Consider]
    D --&gt;|No| H[Deny]

    style A fill:#e1f5fe
    style E fill:#c8e6c9
    style G fill:#fff3c4
    style F fill:#fff3c4
    style H fill:#ffcdd2
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Emphasize: Trees learn these questions automatically from data. You don’t specify the thresholds - the algorithm discovers them!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="tree-anatomy-understanding-the-parts" class="slide level2 smaller">
<h2>Tree Anatomy: Understanding the Parts</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Key Components:</strong></p>
<ul>
<li><strong>Root Node</strong>: Where all data starts</li>
<li><strong>Internal Nodes</strong>: Decision points (yes/no questions)</li>
<li><strong>Branches</strong>: Paths representing answers</li>
<li><strong>Leaf Nodes</strong>: Final predictions</li>
<li><strong>Depth</strong>: How many questions deep the tree goes</li>
</ul>
<p><strong>Reading a Tree:</strong></p>
<ul>
<li>Follow the path from top to bottom</li>
<li>Each split asks about ONE feature</li>
<li>Leaves give you the final prediction</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="cell" data-reveal="true" data-fig-width="5" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A["ROOT NODE&lt;br/&gt;All Data"] --&gt; B{"INTERNAL NODE&lt;br/&gt;Question 1"}
    B --&gt;|Yes| C{"INTERNAL NODE&lt;br/&gt;Question 2A"}
    B --&gt;|No| D{"INTERNAL NODE&lt;br/&gt;Question 2B"}
    C --&gt;|Yes| E["LEAF&lt;br/&gt;Prediction A"]
    C --&gt;|No| F["LEAF&lt;br/&gt;Prediction B"]
    D --&gt;|Yes| G["LEAF&lt;br/&gt;Prediction C"]
    D --&gt;|No| H["LEAF&lt;br/&gt;Prediction D"]

    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style B fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style C fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style D fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style E fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style F fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style G fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style H fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Walk through the diagram. “Imagine a customer flowing through this tree. At each internal node, we ask a question. Eventually they reach a leaf, which gives our prediction.”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-does-the-tree-decide-which-question-to-ask" class="slide level2 smaller">
<h2>How Does the Tree Decide Which Question to Ask?</h2>
<p><strong>Imagine we’re predicting credit card default. Which feature split is better?</strong></p>
<div id="bef46f1a" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-3-output-1.png" class="quarto-figure quarto-figure-center" width="1334" height="469"></p>
</figure>
</div>
</div>
</div>
<center>
<p><strong>Which split creates cleaner, more organized groups?</strong></p>
<strong>Think about it… then we’ll see how the algorithm decides!</strong>
</center>
<aside class="notes">
<p>Give students 10-15 seconds to think. The answer is visually obvious: Split A shows deeply colored, pure leaf nodes (one orange for mostly default, one blue for mostly no default). Split B shows lightly colored, mixed leaf nodes (both are pale because they’re 50/50 mixes). This color intensity represents purity - exactly what Gini impurity measures! Transition: “Your intuition is right - we want splits that create the purest, most organized groups. Let’s see how the algorithm measures this…”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="cart-algorithm-finding-the-best-splits" class="slide level2 smaller">
<h2>CART Algorithm: Finding the Best Splits</h2>
<p><strong>The algorithm formalizes what we just intuitively understood!</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>The CART Algorithm:</strong></p>
<ol type="1">
<li><strong>Test every possible split</strong> for every feature</li>
<li><strong>Measure “purity”</strong> using Gini impurity
<ul>
<li>Gini = 0: Perfect (all same class)</li>
<li>Gini = 0.5: Mixed (50/50 split)</li>
</ul></li>
<li><strong>Choose the split</strong> that creates the biggest purity improvement</li>
<li><strong>Repeat</strong> until stopping criteria met</li>
</ol>
<p><strong>Why this matters:</strong> Trees automatically find the thresholds that matter most in your data!</p>
</div><div class="column" style="width:50%;">
<p><strong>Gini Impurity: A “Messiness Meter”</strong></p>
<ul>
<li><strong>Low Gini (0.0 - 0.1)</strong>: Very organized, confident predictions</li>
<li><strong>Medium Gini (0.2 - 0.3)</strong>: Somewhat mixed, less confident</li>
<li><strong>High Gini (0.4 - 0.5)</strong>: Very messy, like flipping a coin</li>
</ul>
<p><strong>Business Translation:</strong> Lower Gini = clearer business segments = more reliable rules</p>
<p><em>Example:</em> “If balance &gt; $1,200, 95% default” (Gini ≈ 0.1) is much better than “If age &gt; 30, 55% default” (Gini ≈ 0.5)</p>
</div></div>
<aside class="notes">
<p>Connect back to the previous slide: “Split A had Gini ≈ 0.1 (very pure), Split B had Gini ≈ 0.5 (very messy). The algorithm would choose Split A! This is why trees are so good at finding natural thresholds in data.”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="interactive-demo-build-your-first-tree" class="slide level2 smaller scrollable">
<h2>Interactive Demo: Build Your First Tree</h2>
<p>Let’s build a decision tree to predict credit card defaults!</p>
<div id="f86a6532" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" data-code-line-numbers="19-20,23-27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="co"># Load data and prepare features</span></span>
<span id="cb2-2"><a href=""></a><span class="im">from</span> ISLP <span class="im">import</span> load_data</span>
<span id="cb2-3"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb2-4"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-5"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-6"><a href=""></a></span>
<span id="cb2-7"><a href=""></a><span class="co"># Load Default dataset</span></span>
<span id="cb2-8"><a href=""></a>Default <span class="op">=</span> load_data(<span class="st">'Default'</span>)</span>
<span id="cb2-9"><a href=""></a>Default[<span class="st">'default'</span>] <span class="op">=</span> (Default[<span class="st">'default'</span>] <span class="op">==</span> <span class="st">'Yes'</span>).astype(<span class="bu">int</span>)</span>
<span id="cb2-10"><a href=""></a>Default[<span class="st">'student'</span>] <span class="op">=</span> (Default[<span class="st">'student'</span>] <span class="op">==</span> <span class="st">'Yes'</span>).astype(<span class="bu">int</span>)</span>
<span id="cb2-11"><a href=""></a></span>
<span id="cb2-12"><a href=""></a><span class="co"># Prepare features and target</span></span>
<span id="cb2-13"><a href=""></a>X <span class="op">=</span> Default[[<span class="st">'student'</span>, <span class="st">'balance'</span>, <span class="st">'income'</span>]]</span>
<span id="cb2-14"><a href=""></a>y <span class="op">=</span> Default[<span class="st">'default'</span>]</span>
<span id="cb2-15"><a href=""></a></span>
<span id="cb2-16"><a href=""></a><span class="co"># Split data</span></span>
<span id="cb2-17"><a href=""></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-18"><a href=""></a></span>
<span id="cb2-19"><a href=""></a><span class="co"># Build a simple tree (max_depth=3 for interpretability)</span></span>
<span id="cb2-20"><a href=""></a>tree_model <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-21"><a href=""></a>tree_model.fit(X_train, y_train)</span>
<span id="cb2-22"><a href=""></a></span>
<span id="cb2-23"><a href=""></a><span class="co"># Visualize the tree</span></span>
<span id="cb2-24"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb2-25"><a href=""></a>plot_tree(tree_model, feature_names<span class="op">=</span>[<span class="st">'student'</span>, <span class="st">'balance'</span>, <span class="st">'income'</span>], class_names<span class="op">=</span>[<span class="st">'No Default'</span>, <span class="st">'Default'</span>], filled<span class="op">=</span><span class="va">True</span>, rounded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-26"><a href=""></a>plt.title(<span class="st">"Decision Tree: Credit Card Default Prediction"</span>)</span>
<span id="cb2-27"><a href=""></a>plt.show()</span>
<span id="cb2-28"><a href=""></a></span>
<span id="cb2-29"><a href=""></a><span class="co"># Check accuracy</span></span>
<span id="cb2-30"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Training accuracy: </span><span class="sc">{</span>tree_model<span class="sc">.</span>score(X_train, y_train)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb2-31"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Test accuracy: </span><span class="sc">{</span>tree_model<span class="sc">.</span>score(X_test, y_test)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-4-output-1.png" width="912" height="483"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training accuracy: 0.975
Test accuracy: 0.972</code></pre>
</div>
</div>
<aside class="notes">
<p>LIVE DEMO: Run this code and show the tree visualization. Point out: 1. Which feature did it split on first? (likely balance) 2. What threshold did it choose? 3. How many customers are in each leaf? 4. Can we trace through a prediction together? Keep it under 3-4 minutes total.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="random-forests-wisdom-of-crowds" class="title-slide slide level1 center" data-background="#43464B">
<h1>Random Forests: Wisdom of Crowds</h1>

</section>
<section id="the-problem-with-single-trees" class="slide level2 smaller">
<h2>The Problem with Single Trees</h2>
<p><br><br></p>
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Warning</strong></p>
</div>
<div class="callout-content">
<p>Decision trees are interpretable, but they have two critical weaknesses:</p>
<ol type="1">
<li><strong>Instability</strong></li>
<li><strong>Overfitting</strong></li>
</ol>
</div>
</div>
</div>
<p><br><br></p>
<p>Let’s see what these problems look like…</p>
<aside class="notes">
<p>Simple introduction slide. Use fragments to reveal one at a time. Transition: “Let’s visualize these problems to understand why they matter…”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="problem-1-instability" class="slide level2 smaller">
<h2>Problem #1: Instability</h2>
<p><strong>Small changes in data → completely different trees</strong></p>
<div id="9f9ec3c9" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-5-output-1.png" class="quarto-figure quarto-figure-center" width="759" height="326"></p>
</figure>
</div>
</div>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>The Problem:</strong></p>
<ul>
<li>Each colored line is a different tree</li>
<li>Same data, just sampled differently</li>
<li>Trees make very different predictions!</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Business Impact:</strong></p>
<ul>
<li>Unreliable predictions</li>
<li>Inconsistent insights</li>
<li>Hard to trust for decisions</li>
</ul>
</div></div>
<aside class="notes">
<p>Point out how the trees (colored lines) disagree wildly, especially in regions with sparse data. This is high variance - small data changes cause big prediction changes. Transition: “Instability is one problem. The second problem is overfitting…”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="problem-2-overfitting" class="slide level2 smaller">
<h2>Problem #2: Overfitting</h2>
<p><strong>Trees memorize training data instead of learning patterns</strong></p>
<div id="8b5af9e7" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-6-output-1.png" class="quarto-figure quarto-figure-center" width="1143" height="350"></p>
</figure>
</div>
</div>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>The Problem:</strong></p>
<ul>
<li>Left tree captures the pattern ✓</li>
<li>Right tree memorizes every point</li>
<li>Wildly jagged - chasing noise, not signal</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Business Impact:</strong></p>
<ul>
<li>Perfect training accuracy (1.00)</li>
<li>Poor test accuracy (0.75)</li>
<li>Unreliable on new data</li>
</ul>
</div></div>
<aside class="notes">
<p>The overfit tree (right) perfectly fits training points but creates a jagged, unreliable function. It’s learning noise, not patterns. Transition: “So we have unstable trees that overfit. How do we fix this? Enter Random Forests…”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="think-pair-share-why-consult-multiple-experts" class="slide level2 smaller">
<h2>Think-Pair-Share: Why Consult Multiple Experts?</h2>
<p>When making important decisions, we rarely trust just one opinion…</p>
<div class="columns">
<div class="column" style="width:70%;">
<p><strong>Real-world examples:</strong></p>
<ul>
<li>Hiring: Interview panel (not just one person)</li>
<li>Medical diagnosis: Second opinions for serious conditions</li>
<li>Restaurant choice: Check multiple review sites</li>
<li>Investment decisions: Consult multiple analysts</li>
</ul>
<p><strong>Discuss with your neighbor:</strong></p>
<ol type="1">
<li>Why is averaging multiple opinions more reliable than trusting one expert?</li>
<li>What makes a good “panel of experts” (rather than just asking the same person twice)?</li>
<li>How might this apply to machine learning?</li>
</ol>
</div><div class="column" style="width:30%;">
<center>
<div id="3minExperts">

</div>
<script src="_extensions/produnis/timer/timer.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        initializeTimer("3minExperts", 180, "slide");
    });
</script>
</center>
</div></div>
<p>Then we’ll take a few responses…</p>
<aside class="notes">
<p>After discussion, make the connection: “Random Forests apply this exact principle - build many diverse trees and let them vote! The key is making them diverse so they make different errors that cancel out.”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="random-forests-two-key-ingredients" class="slide level2 smaller">
<h2>Random Forests: Two Key Ingredients</h2>
<p><br><br></p>
<p>Random Forests improve on single decision trees through two main modifications:</p>
<p><br></p>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>1. Bootstrap Aggregating (Bagging)</strong></p>
</div>
<div class="callout-content">
<p>Train many trees on different random samples of data</p>
</div>
</div>
</div>
<p><br></p>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>2. Feature Randomness</strong></p>
</div>
<div class="callout-content">
<p>Each tree considers only a random subset of features at each split</p>
</div>
</div>
</div>
<p><br></p>
<center>
<p><strong>Let’s see how each one works…</strong></p>
</center>
<aside class="notes">
<p>Simple framing slide. These two innovations transform unstable, overfitting trees into a robust, accurate ensemble. Let’s explore each one visually.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="bootstrap-aggregating-bagging-1" class="slide level2 smaller">
<h2>Bootstrap Aggregating (Bagging)</h2>
<p><strong>Creating diversity through random sampling</strong></p>
<div id="ac17ae2c" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-7-output-1.png" class="quarto-figure quarto-figure-center" width="1317" height="276"></p>
</figure>
</div>
</div>
</div>
<p><strong>The Process:</strong> Original data → 3 bootstrap samples → Train 3 different trees → Aggregate predictions!</p>
<aside class="notes">
<p>Show how each bootstrap sample is slightly different (some points appear multiple times, others not at all), leading to different tree predictions. This diversity is the foundation of Random Forests.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-problem-with-bagging-alone" class="slide level2 smaller">
<h2>The Problem with Bagging Alone</h2>
<p><strong>What if one feature is much stronger than the others?</strong></p>
<div id="523648a4" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-8-output-1.png" class="quarto-figure quarto-figure-center" width="1329" height="372"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Problem: Tree Correlation</strong></p>
</div>
<div class="callout-content">
<p>All trees have nearly identical structure (balance → income → student)</p>
<p><strong>Solution:</strong> Force trees to use different features through <strong>feature randomness</strong></p>
</div>
</div>
</div>
<aside class="notes">
<p>Point out how all three trees split on the same features in the same order, despite being trained on different bootstrap samples. This is what happens when one feature (balance) is much stronger than others - all trees naturally gravitate toward it. The trees become correlated, which means their predictions are similar, so averaging doesn’t provide much benefit. We need to decorrelate the trees by forcing them to consider different feature subsets at each split. That’s where feature randomness comes in - it’s the secret sauce that transforms bagged trees into Random Forests.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="feature-randomness-secret-sauce" class="slide level2 smaller">
<h2>Feature Randomness: Secret Sauce</h2>
<p><strong>At each split, consider only a random subset of features</strong></p>
<div id="244025c4" class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-9-output-1.png" class="quarto-figure quarto-figure-center" width="1139" height="309"></p>
</figure>
</div>
</div>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>How It Works:</strong></p>
<ul>
<li>At each split, randomly select subset of features</li>
<li><strong>Classification</strong>: √p features</li>
<li><strong>Regression</strong>: p/3 features</li>
<li>Tree only considers these for that split</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>The Result:</strong></p>
<ul>
<li>Different trees explore different features</li>
<li>No single feature dominates all trees</li>
<li>Trees become decorrelated</li>
<li>More diverse predictions</li>
</ul>
</div></div>
<aside class="notes">
<p>This visualization shows three trees, each with three decision nodes. At each node, only a random subset of features (colored boxes) are available for splitting - the gray boxes show features that are not considered. Notice how each tree gets different random subsets at each node. This forces trees to explore different feature combinations even if one feature (like balance) is very strong. Some trees will split on the dominant feature, others will be forced to use alternatives, creating the diversity we need.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="impact-of-feature-randomness" class="slide level2 smaller">
<h2>Impact of Feature Randomness</h2>
<div id="a06a6660" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-10-output-1.png" class="quarto-figure quarto-figure-center" width="1143" height="327"></p>
</figure>
</div>
</div>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Without Feature Randomness:</strong></p>
<ul>
<li>All trees use same dominant features</li>
<li>Similar tree structures</li>
<li>Correlated predictions (similar slopes)</li>
<li>Limited benefit from averaging</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>With Feature Randomness:</strong></p>
<ul>
<li>Trees forced to use different features</li>
<li>Diverse tree structures</li>
<li>Decorrelated predictions (varied slopes)</li>
<li>Errors cancel out when averaged!</li>
</ul>
</div></div>
<aside class="notes">
<p>Left plot shows what happens with bagging alone - all 10 trees make similar predictions because they all split on the same strong features. The predictions are correlated. Right plot shows random forests - the trees make much more diverse predictions because they’re forced to consider different feature subsets. This diversity is powerful: when we average diverse predictions, individual errors cancel out, leaving more accurate results. This is why feature randomness is the “secret sauce” that makes random forests superior to simple bagged trees.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-power-of-feature-randomness" class="slide level2 smaller">
<h2>The Power of Feature Randomness</h2>
<p><strong>Random forests outperform bagged trees through decorrelation</strong></p>
<div class="columns">
<div class="column" style="width:65%;">
<div id="8fbe7e22" class="cell" data-execution_count="10">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-11-output-1.png" class="quarto-figure quarto-figure-center" width="759" height="326"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:35%;">
<div id="82f839ac" class="cell" data-execution_count="11">
<div class="cell-output cell-output-stdout">
<pre><code>
Final Performance (100 trees):
Bagged Trees MSE:  11.8729
Random Forest MSE: 11.1917
Improvement: 5.7%</code></pre>
</div>
</div>
</div></div>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Key Insight</strong></p>
</div>
<div class="callout-content">
<p>Feature randomness <strong>decorrelates</strong> trees, allowing their errors to cancel out more effectively when averaged. This is why random forests consistently outperform simple bagged trees!</p>
</div>
</div>
</div>
<aside class="notes">
<p>This plot demonstrates the power of feature randomness on real data. Both approaches use bootstrap sampling, but random forests add feature randomness at each split. The green line (random forests) achieves consistently lower error than the orange line (bagged trees). The improvement comes from decorrelating the trees - when trees are forced to consider different feature subsets, they make more independent errors that cancel out when averaged. This is especially powerful in datasets with strong dominant features or many correlated features. The combination of bootstrap sampling AND feature randomness is what makes random forests one of the most effective machine learning algorithms available.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside class="notes">
<p>Left plot shows correlated predictions when all trees use the same features. Right plot shows diverse predictions when feature randomness forces different tree structures. Averaging diverse predictions is much more powerful!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="demo-single-tree-vs-random-forest" class="slide level2 smaller scrollable">
<h2>Demo: Single Tree vs Random Forest</h2>
<p>Let’s compare performance on the Boston housing dataset!</p>
<div id="f484a2de" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb5" data-code-line-numbers="15-16,19-20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb5-2"><a href=""></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb5-3"><a href=""></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> root_mean_squared_error, r2_score</span>
<span id="cb5-4"><a href=""></a></span>
<span id="cb5-5"><a href=""></a><span class="co"># Load Boston data (if not already loaded)</span></span>
<span id="cb5-6"><a href=""></a><span class="im">from</span> ISLP <span class="im">import</span> load_data</span>
<span id="cb5-7"><a href=""></a>Boston <span class="op">=</span> load_data(<span class="st">'Boston'</span>)</span>
<span id="cb5-8"><a href=""></a>X <span class="op">=</span> Boston.drop(<span class="st">'medv'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-9"><a href=""></a>y <span class="op">=</span> Boston[<span class="st">'medv'</span>]</span>
<span id="cb5-10"><a href=""></a></span>
<span id="cb5-11"><a href=""></a><span class="co"># Split data</span></span>
<span id="cb5-12"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb5-13"><a href=""></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-14"><a href=""></a></span>
<span id="cb5-15"><a href=""></a><span class="co"># Build Single Decision Tree</span></span>
<span id="cb5-16"><a href=""></a>single_tree <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-17"><a href=""></a>single_tree.fit(X_train, y_train)</span>
<span id="cb5-18"><a href=""></a></span>
<span id="cb5-19"><a href=""></a><span class="co"># Build Random Forest (100 trees)</span></span>
<span id="cb5-20"><a href=""></a>rf_model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-21"><a href=""></a>rf_model.fit(X_train, y_train)</span>
<span id="cb5-22"><a href=""></a></span>
<span id="cb5-23"><a href=""></a><span class="co"># Compare performance</span></span>
<span id="cb5-24"><a href=""></a><span class="bu">print</span>(<span class="st">"=== Single Decision Tree ==="</span>)</span>
<span id="cb5-25"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Training R²: </span><span class="sc">{</span>single_tree<span class="sc">.</span>score(X_train, y_train)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb5-26"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Test R²: </span><span class="sc">{</span>single_tree<span class="sc">.</span>score(X_test, y_test)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb5-27"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Test RMSE: $</span><span class="sc">{</span>root_mean_squared_error(y_test, single_tree.predict(X_test))<span class="sc">:.2f}</span><span class="ss">k"</span>)</span>
<span id="cb5-28"><a href=""></a></span>
<span id="cb5-29"><a href=""></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Random Forest (100 trees) ==="</span>)</span>
<span id="cb5-30"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Training R²: </span><span class="sc">{</span>rf_model<span class="sc">.</span>score(X_train, y_train)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb5-31"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Test R²: </span><span class="sc">{</span>rf_model<span class="sc">.</span>score(X_test, y_test)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb5-32"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Test RMSE: $</span><span class="sc">{</span>root_mean_squared_error(y_test, rf_model.predict(X_test))<span class="sc">:.2f}</span><span class="ss">k"</span>)</span>
<span id="cb5-33"><a href=""></a></span>
<span id="cb5-34"><a href=""></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Improvement ==="</span>)</span>
<span id="cb5-35"><a href=""></a>r2_improvement <span class="op">=</span> (rf_model.score(X_test, y_test) <span class="op">-</span> single_tree.score(X_test, y_test)) <span class="op">/</span> single_tree.score(X_test, y_test)</span>
<span id="cb5-36"><a href=""></a>rmse_improvement <span class="op">=</span> (root_mean_squared_error(y_test, single_tree.predict(X_test)) <span class="op">-</span> root_mean_squared_error(y_test, rf_model.predict(X_test))) <span class="op">/</span> root_mean_squared_error(y_test, single_tree.predict(X_test))</span>
<span id="cb5-37"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Test R² improvement: </span><span class="sc">{</span>r2_improvement<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb5-38"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Test RMSE improvement: </span><span class="sc">{</span>rmse_improvement<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>=== Single Decision Tree ===
Training R²: 0.825
Test R²: 0.773
Test RMSE: $4.11k

=== Random Forest (100 trees) ===
Training R²: 0.878
Test R²: 0.805
Test RMSE: $3.81k

=== Improvement ===
Test R² improvement: 4.17%
Test RMSE improvement: 7.36%</code></pre>
</div>
</div>
<aside class="notes">
<p>LIVE DEMO: Run this and highlight: 1. Random Forest typically has better test R² (more stable) 2. Lower RMSE means better predictions 3. The gap between train/test is smaller (less overfitting) 4. This demonstrates both DecisionTreeRegressor and RandomForestRegressor! Keep demo to 2-3 minutes.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="key-insight-errors-cancel-signal-remains" class="slide level2 smaller">
<h2>Key Insight: Errors Cancel, Signal Remains</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell" data-reveal="true" data-fig-width="5" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    A[Tree 1&lt;br/&gt;Prediction] --&gt; D[Average]
    B[Tree 2&lt;br/&gt;Prediction] --&gt; D
    C[Tree 3&lt;br/&gt;Prediction] --&gt; D
    E[Tree ...&lt;br/&gt;Prediction] --&gt; D
    F[Tree 100&lt;br/&gt;Prediction] --&gt; D
    D --&gt; G[Final&lt;br/&gt;Prediction]

    style D fill:#ffd700,stroke:#ff8c00,stroke-width:3px
    style G fill:#90ee90,stroke:#228b22,stroke-width:3px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<p><strong>The Mathematics of Wisdom:</strong></p>
<ul>
<li>Each tree makes some errors</li>
<li>But errors are <strong>uncorrelated</strong> (thanks to bootstrap + feature randomness)</li>
<li>Tree 1 might overestimate, Tree 2 underestimate</li>
<li>When averaged, errors tend to cancel out</li>
<li>True patterns appear in most trees → reinforced</li>
<li>Random noise appears in few trees → averaged away</li>
</ul>
<p><strong>Result:</strong> More accurate and stable predictions!</p>
</div></div>
<aside class="notes">
<p>This is the fundamental insight of ensemble learning. Diversity is key - if all trees made the same errors, averaging wouldn’t help!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="feature-importance-opening-the-black-box" class="title-slide slide level1 center" data-background="#43464B">
<h1>Feature Importance: Opening the Black Box</h1>

</section>
<section id="the-interpretability-challenge" class="slide level2 smaller">
<h2>The Interpretability Challenge</h2>
<p><strong>The Problem:</strong> Your model is accurate, but can you explain <em>why</em>?</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>The Trade-Off:</strong></p>
<div class="cell" data-reveal="true" data-fig-width="5" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    A[Linear&lt;br/&gt;Regression] --&gt; B[Decision&lt;br/&gt;Tree]
    B --&gt; C[Random&lt;br/&gt;Forest]
    C --&gt; D[Deep&lt;br/&gt;Learning]

    style A fill:#90EE90
    style B fill:#FFD700
    style C fill:#FFA07A
    style D fill:#FF6347
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><strong>As we move right:</strong></p>
<ul>
<li>Accuracy ↑ (Better predictions)</li>
<li>Interpretability ↓ (Harder to explain)</li>
</ul>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:45%;">
<p><strong>How We Interpret Each:</strong></p>
<p><strong>Linear Regression:</strong></p>
<ul>
<li>Coefficients tell the story</li>
<li>“Each $1k income increases price by $45”</li>
<li>Simple, direct interpretation ✓</li>
</ul>
<p><strong>Decision Tree:</strong></p>
<ul>
<li>Visualize the tree structure</li>
<li>Follow the if-then rules</li>
<li>Trace individual predictions ✓</li>
</ul>
<p><strong>Random Forest:</strong></p>
<ul>
<li>Aggregating 100-1000 trees</li>
<li>Can’t visualize all trees</li>
<li>No single path to trace ❌</li>
</ul>
</div></div>
<aside class="notes">
<p>Emphasize the progression: linear models give you coefficients, trees give you visual paths, but random forests combine hundreds of trees making direct interpretation impossible. This is why we need feature importance techniques!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-business-reality" class="slide level2 smaller">
<h2>The Business Reality</h2>
<p><strong>A Common Business Conversation:</strong></p>
<p><strong>You:</strong> “Our Random Forest predicts customer churn with 94% accuracy!”</p>
<p><strong>VP:</strong> “Excellent! So which customers are at risk and why?”</p>
<p><strong>You:</strong> “Here’s a list of 500 high-risk customers.”</p>
<p><strong>VP:</strong> “Great! What should we do to retain them?”</p>
<p><strong>You:</strong> “Well… the model doesn’t exactly tell us that in a straightforward way…”</p>
<p><strong>VP:</strong> “What do you mean? How can it predict churn without knowing what causes churn?”</p>
<p><strong>You:</strong> “It does know—sort of. The patterns are just… distributed across hundreds of decision trees…”</p>
<p><strong>VP:</strong> 🤔 “So you’re telling me to spend $200,000 on retention campaigns, but you can’t explain why these specific customers are at risk?”</p>
<p><br></p>
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>The Challenge</strong></p>
</div>
<div class="callout-content">
<p>Your model is accurate, but stakeholders need more than predictions—they need <strong>explanations</strong> and <strong>actionable insights</strong>.</p>
</div>
</div>
</div>
<aside class="notes">
<p>This is where many data scientists realize accuracy alone isn’t enough. Stakeholders need to understand WHY to trust the model and take action. This leads us to feature importance as a solution.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="why-feature-importance-matters" class="slide level2 smaller">
<h2>Why Feature Importance Matters</h2>
<p>Feature importance helps us answer the critical business questions:</p>
<div class="columns">
<div class="column" style="width:47%;">
<p><strong>Building Trust:</strong></p>
<ul>
<li>“Show me which factors drive your predictions”</li>
<li>Stakeholders can validate against domain knowledge</li>
<li>Catches data leakage and model errors early</li>
</ul>
<p><strong>Supporting Decisions:</strong></p>
<ul>
<li>Translate predictions into strategy</li>
<li>“Customers with 4+ service calls are at high churn risk → proactive outreach”</li>
<li>Focus resources on what actually matters</li>
</ul>
</div><div class="column" style="width:6%;">

</div><div class="column" style="width:47%;">
<p><strong>Feature Selection:</strong></p>
<ul>
<li>Out of 50 features, maybe only 8 drive meaningful predictions</li>
<li>Simplify data collection</li>
<li>Reduce noise, improve performance</li>
</ul>
<p><strong>Regulatory Compliance:</strong></p>
<ul>
<li>Finance: Must explain why credit was denied</li>
<li>Healthcare: Medical decisions must be explainable</li>
<li>GDPR: “Right to explanation” for automated decisions</li>
</ul>
</div></div>
<aside class="notes">
<p>Feature importance bridges the gap between statistical patterns and business action. It’s often the difference between a model that sits on a shelf and one that drives real value.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="understanding-our-random-forest" class="slide level2 smaller">
<h2>Understanding Our Random Forest</h2>
<p><strong>Two critical questions about our model:</strong></p>
<p><br></p>
<div class="columns">
<div class="column" style="width:47%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Question 1: Which Features Matter Most?</strong></p>
</div>
<div class="callout-content">
<p><strong>Feature Importance</strong> tells us which variables are driving our model’s predictions.</p>
<p><em>Example:</em> “Balance is responsible for 70% of the model’s decision-making, while income contributes only 15%”</p>
</div>
</div>
</div>
</div><div class="column" style="width:6%;">

</div><div class="column" style="width:47%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Question 2: How Do They Influence Predictions?</strong></p>
</div>
<div class="callout-content">
<p><strong>Partial Dependence Plots</strong> show us how predictions change as we vary an influential feature.</p>
<p><em>Example:</em> “As balance increases from $0 to $2,000, default probability rises from 5% to 85%”</p>
</div>
</div>
</div>
</div></div>
<p><br></p>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Our Approach</strong></p>
</div>
<div class="callout-content">
<p><strong>First</strong>, identify what matters → <strong>Then</strong>, understand how it matters</p>
</div>
</div>
</div>
<aside class="notes">
<p>Set up the two-step approach: (1) Feature importance tells us WHICH features are most influential across all predictions, (2) Partial dependence plots show us HOW these features influence predictions. This creates a natural progression from identifying important features to understanding their behavior.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="measuring-what-matters" class="slide level2 smaller">
<h2>Measuring What Matters</h2>
<p><strong>Two approaches to identify influential features:</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>1. Gini/MSE Importance</strong></p>
<p><em>How it works:</em></p>
<ul>
<li>Tracks which features create the best splits</li>
<li>Aggregates across all trees</li>
</ul>
<p><em>Pros:</em></p>
<ul>
<li>Fast, built into scikit-learn</li>
<li>Easy: <code>.feature_importances_</code></li>
</ul>
<p><em>Cons:</em></p>
<ul>
<li>Biased toward continuous features</li>
<li>Uses training data only</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>2. Permutation Importance</strong></p>
<p><em>How it works:</em></p>
<ul>
<li>Shuffle one feature at a time</li>
<li>Measure performance drop</li>
</ul>
<p><em>Pros:</em></p>
<ul>
<li>Works with any model</li>
<li>More reliable rankings</li>
<li>Uses test data</li>
</ul>
<p><em>Cons:</em></p>
<ul>
<li>Slower computation</li>
<li>Needs separate calculation</li>
</ul>
</div></div>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Best Practice:</strong></p>
</div>
<div class="callout-content">
<p>Use Gini for quick checks → validate with permutation importance</p>
</div>
</div>
</div>
<aside class="notes">
<p>Think of it this way: Gini importance asks “What did the trees use during training?” Permutation importance asks “What actually helps predictions on new data?” The second question is usually more important!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="demo-extracting-feature-importance" class="slide level2 smaller scrollable">
<h2>Demo: Extracting Feature Importance</h2>
<p>Let’s see what drives housing price predictions in our Random Forest!</p>
<div id="3ee3c035" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href=""></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href=""></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb7-3"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-4"><a href=""></a></span>
<span id="cb7-5"><a href=""></a><span class="co"># We already have our trained rf_model from the Boston housing demo</span></span>
<span id="cb7-6"><a href=""></a><span class="co"># Extract Gini-based importance</span></span>
<span id="cb7-7"><a href=""></a>feature_names <span class="op">=</span> X_train.columns</span>
<span id="cb7-8"><a href=""></a>gini_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb7-9"><a href=""></a>    <span class="st">'feature'</span>: feature_names,</span>
<span id="cb7-10"><a href=""></a>    <span class="st">'gini_importance'</span>: rf_model.feature_importances_</span>
<span id="cb7-11"><a href=""></a>}).sort_values(<span class="st">'gini_importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-12"><a href=""></a></span>
<span id="cb7-13"><a href=""></a><span class="bu">print</span>(<span class="st">"=== Top 5 Features (Gini Importance) ==="</span>)</span>
<span id="cb7-14"><a href=""></a><span class="bu">print</span>(gini_importance.head())</span>
<span id="cb7-15"><a href=""></a></span>
<span id="cb7-16"><a href=""></a><span class="co"># Calculate Permutation Importance on test set</span></span>
<span id="cb7-17"><a href=""></a>perm_result <span class="op">=</span> permutation_importance(</span>
<span id="cb7-18"><a href=""></a>    rf_model, X_test, y_test,</span>
<span id="cb7-19"><a href=""></a>    n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>, scoring<span class="op">=</span><span class="st">'r2'</span></span>
<span id="cb7-20"><a href=""></a>)</span>
<span id="cb7-21"><a href=""></a></span>
<span id="cb7-22"><a href=""></a>perm_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb7-23"><a href=""></a>    <span class="st">'feature'</span>: feature_names,</span>
<span id="cb7-24"><a href=""></a>    <span class="st">'perm_importance'</span>: perm_result.importances_mean</span>
<span id="cb7-25"><a href=""></a>}).sort_values(<span class="st">'perm_importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-26"><a href=""></a></span>
<span id="cb7-27"><a href=""></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Top 5 Features (Permutation Importance) ==="</span>)</span>
<span id="cb7-28"><a href=""></a><span class="bu">print</span>(perm_importance.head())</span>
<span id="cb7-29"><a href=""></a></span>
<span id="cb7-30"><a href=""></a><span class="co"># Visualize top 8 features</span></span>
<span id="cb7-31"><a href=""></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb7-32"><a href=""></a>gini_importance.head(<span class="dv">8</span>).sort_values(<span class="st">'gini_importance'</span>).set_index(<span class="st">'feature'</span>)[<span class="st">'gini_importance'</span>].plot(</span>
<span id="cb7-33"><a href=""></a>    kind<span class="op">=</span><span class="st">'barh'</span>, ax<span class="op">=</span>ax1, color<span class="op">=</span><span class="st">'steelblue'</span>, title<span class="op">=</span><span class="st">'Gini Importance (Top 8)'</span></span>
<span id="cb7-34"><a href=""></a>)</span>
<span id="cb7-35"><a href=""></a>perm_importance.head(<span class="dv">8</span>).sort_values(<span class="st">'perm_importance'</span>).set_index(<span class="st">'feature'</span>)[<span class="st">'perm_importance'</span>].plot(</span>
<span id="cb7-36"><a href=""></a>    kind<span class="op">=</span><span class="st">'barh'</span>, ax<span class="op">=</span>ax2, color<span class="op">=</span><span class="st">'coral'</span>, title<span class="op">=</span><span class="st">'Permutation Importance (Top 8)'</span></span>
<span id="cb7-37"><a href=""></a>)</span>
<span id="cb7-38"><a href=""></a>plt.tight_layout()</span>
<span id="cb7-39"><a href=""></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>=== Top 5 Features (Gini Importance) ===
    feature  gini_importance
5        rm         0.471090
11    lstat         0.425896
7       dis         0.060453
0      crim         0.019231
10  ptratio         0.011489

=== Top 5 Features (Permutation Importance) ===
    feature  perm_importance
11    lstat         0.531901
5        rm         0.391349
7       dis         0.051834
10  ptratio         0.015919
0      crim         0.015026</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-14-output-2.png" width="1142" height="374"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>LIVE DEMO: Run and point out: 1. Which features dominate? (likely lstat, rm) 2. Do both methods agree on the top features? 3. What does this tell us about what drives housing prices? Keep to 3 minutes max.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="understanding-how-features-influence-predictions" class="slide level2 smaller">
<h2>Understanding How Features Influence Predictions</h2>
<p><strong>Feature importance tells us WHICH features matter, but not HOW they matter</strong></p>
<p><strong>What We Know:</strong></p>
<ul>
<li><code>lstat</code> is the most important feature (35% importance)</li>
<li>It drives predictions more than any other variable</li>
</ul>
<p><strong>What We Don’t Know:</strong></p>
<ul>
<li>Does increasing <code>lstat</code> increase or decrease price?</li>
<li>Is the relationship linear or non-linear?</li>
<li>Are there threshold effects?</li>
<li>At what point does the effect saturate?</li>
</ul>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Enter: Partial Dependence Plots (PDPs)</strong></p>
</div>
<div class="callout-content">
<p>PDPs show <strong>how predictions change</strong> as we vary one feature while holding all others constant.</p>
<p><strong>The insight:</strong> “As <code>lstat</code> increases from 5% to 30%, median home value decreases from $35k to $15k”</p>
<p>This is actionable intelligence!</p>
</div>
</div>
</div>
<aside class="notes">
<p>Feature importance answered “which features?” Now we need PDPs to answer “how do they work?” This is the bridge from identifying important variables to understanding their behavior and making business decisions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="demo-creating-partial-dependence-plots" class="slide level2 smaller scrollable">
<h2>Demo: Creating Partial Dependence Plots</h2>
<p>Let’s visualize how <code>lstat</code> affects housing prices!</p>
<div id="c851b8f0" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href=""></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> PartialDependenceDisplay</span>
<span id="cb9-2"><a href=""></a></span>
<span id="cb9-3"><a href=""></a><span class="co"># Create PDP for lstat (our most important feature)</span></span>
<span id="cb9-4"><a href=""></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb9-5"><a href=""></a>PartialDependenceDisplay.from_estimator(</span>
<span id="cb9-6"><a href=""></a>    rf_model,</span>
<span id="cb9-7"><a href=""></a>    X_train,</span>
<span id="cb9-8"><a href=""></a>    features<span class="op">=</span>[<span class="st">'lstat'</span>],</span>
<span id="cb9-9"><a href=""></a>    grid_resolution<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb9-10"><a href=""></a>    ax<span class="op">=</span>ax</span>
<span id="cb9-11"><a href=""></a>)</span>
<span id="cb9-12"><a href=""></a>plt.title(<span class="st">'How lstat Affects Housing Price Predictions'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb9-13"><a href=""></a>plt.tight_layout()</span>
<span id="cb9-14"><a href=""></a>plt.show()</span>
<span id="cb9-15"><a href=""></a></span>
<span id="cb9-16"><a href=""></a><span class="co"># Create PDPs for multiple top features</span></span>
<span id="cb9-17"><a href=""></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb9-18"><a href=""></a>axes <span class="op">=</span> axes.ravel()</span>
<span id="cb9-19"><a href=""></a></span>
<span id="cb9-20"><a href=""></a>top_features <span class="op">=</span> [<span class="st">'lstat'</span>, <span class="st">'rm'</span>, <span class="st">'dis'</span>, <span class="st">'crim'</span>]  <span class="co"># Top 4 features</span></span>
<span id="cb9-21"><a href=""></a>PartialDependenceDisplay.from_estimator(</span>
<span id="cb9-22"><a href=""></a>    rf_model,</span>
<span id="cb9-23"><a href=""></a>    X_train,</span>
<span id="cb9-24"><a href=""></a>    features<span class="op">=</span>top_features,</span>
<span id="cb9-25"><a href=""></a>    grid_resolution<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb9-26"><a href=""></a>    ax<span class="op">=</span>axes</span>
<span id="cb9-27"><a href=""></a>)</span>
<span id="cb9-28"><a href=""></a>plt.suptitle(<span class="st">'Partial Dependence Plots: Top 4 Features'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb9-29"><a href=""></a>plt.tight_layout()</span>
<span id="cb9-30"><a href=""></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-15-output-1.png" width="758" height="470"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="w11_tuesday_files/figure-revealjs/cell-15-output-2.png" width="1142" height="946"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>LIVE DEMO: Run this and point out: 1. PDP for lstat shows clear negative relationship - as % lower status increases, prices decrease 2. Look for threshold effects - does the relationship change at certain values? 3. Compare shapes across features - linear vs non-linear relationships 4. The vertical lines at the bottom show data density - trust the plot more where there’s more data Keep to 3 minutes max.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="wrap-up-looking-ahead" class="title-slide slide level1 center" data-background="#43464B">
<h1>Wrap-Up &amp; Looking Ahead</h1>

</section>
<section id="key-takeaways" class="slide level2">
<h2>Key Takeaways</h2>
<ul>
<li><p><strong>Decision Trees</strong> – Learn patterns through sequential yes/no questions, automatically discovering thresholds and interactions, but can be unstable and prone to overfitting.</p></li>
<li><p><strong>Random Forests</strong> – Combine hundreds of diverse trees (via bootstrap sampling and feature randomness) to create stable, accurate predictions through voting or averaging.</p></li>
<li><p><strong>Feature Importance</strong> – Bridges the gap between accuracy and interpretability, revealing which features drive predictions and enabling stakeholder trust and actionable insights.</p></li>
<li><p><strong>The Big Picture</strong> – Tree-based models offer a powerful middle ground between simple linear models and complex black boxes, delivering strong performance with reasonable interpretability.</p></li>
</ul>
</section>
<section id="looking-ahead" class="slide level2">
<h2>Looking Ahead</h2>
<p><strong>Between now and Thursday:</strong></p>
<ul>
<li>Read Chapters 25-27 (Decision Trees, Random Forests, Feature Importance)</li>
</ul>
<p><strong>Thursday’s Lab:</strong></p>
<ul>
<li>Hands-on applications with decision trees, random forests, and feature importance</li>
</ul>
<p><strong>Homework:</strong></p>
<ul>
<li>Thursday’s lab will feed into the homework assignment</li>
</ul>
</section>
<section id="any-final-questions" class="slide level2">
<h2>Any Final Questions?</h2>
<ul>
<li>About today’s concepts?</li>
<li>About Thursday’s lab?</li>
<li>About the readings?</li>
</ul>
</section>
<section class="slide level2">

<center>
<p><strong>See you Thursday for hands-on practice!</strong></p>
<em>“The best way to learn tree-based models is to build them yourself.”</em>
</center>

</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>BANA 4080</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="w11_tuesday_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="w11_tuesday_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="w11_tuesday_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="w11_tuesday_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="w11_tuesday_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="w11_tuesday_files/libs/revealjs/plugin/appearance/appearance.js"></script>
  <script src="w11_tuesday_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="w11_tuesday_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="w11_tuesday_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="w11_tuesday_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="w11_tuesday_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'appearance': {"hideagain":true,"delay":300,"debug":false,"appearevent":"slidetransitionend","autoappear":false,"autoelements":false,"appearparents":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, Appearance, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>