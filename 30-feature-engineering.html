<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>30&nbsp; Feature Engineering – BANA 4080: Data Mining</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./99-anaconda-install.html" rel="next">
<link href="./29-hyperparameter-tuning.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-5d254f1e278c2921d96b26102a150bb1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-530b29c22fe67fc61ace1451aaa50055.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-5d254f1e278c2921d96b26102a150bb1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-45c1b2e5a2b0567ccfb99e4dfc03f650.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-54ba87e1857bbaa32a381632a2aab8bf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-45c1b2e5a2b0567ccfb99e4dfc03f650.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./28-cross-validation.html">Module 11</a></li><li class="breadcrumb-item"><a href="./30-feature-engineering.html"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Feature Engineering</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">BANA 4080: Data Mining</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/bradleyboehmke/uc-bana-4080" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./BANA-4080--Data-Mining.epub" title="Download ePub" class="quarto-navigation-tool px-1" aria-label="Download ePub"><i class="bi bi-journal"></i></a>
    <a href="https://twitter.com/intent/tweet?url=|url|" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro-data-mining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-preparing-for-code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Setting Up Your Python Environment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-python-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python Basics – Working with Data and Variables</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 2</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-jupyter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Getting Started with Jupyter Notebooks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-data-structures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Data Structures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-libraries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Packages, Libraries, and Modules</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-importing-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Importing Data and Exploring Pandas DataFrames</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-dataframes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Deeper Dive on DataFrames</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-subsetting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Subsetting Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 4</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-manipulating-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Manipulating Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_aggregating_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Summarizing Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-joining-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Relational data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 5</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-data-viz-pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Intro to Data Visualization with Pandas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-data-viz-matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Fundamentals of Plotting with Matplotlib</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-data-viz-bokeh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Interactive Data Visualization with Bokeh</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 6</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-control-statements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Controlling Program Flow with Conditional Statements</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-iteration-statements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Controlling Repetition with Iteration Statements</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Writing Your Own Functions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 7</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-intro-ml-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Introduction to Machine Learning and Artificial Intelligence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-before-we-build.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Before You Build: Key Considerations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 8</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-correlation-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Correlation and Linear Regression Foundations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-regression-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Evaluating Regression Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 9</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Introduction to Logistic Regression for Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-classification-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Evaluating Classification Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 10</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-decision-trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Decision Trees: Foundations and Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26-random-forests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Random Forests: Ensemble Power and Robustness</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./27-feature-importance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Understanding Feature Importance: Peeking Inside the Black Box</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 11</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./28-cross-validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Cross-validation: Reliable model evaluation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./29-hyperparameter-tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning: Finding Optimal Model Configurations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30-feature-engineering.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Feature Engineering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99-anaconda-install.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Anaconda Installation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99-vscode-install.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">VS Code Installation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#why-feature-engineering-matters" id="toc-why-feature-engineering-matters" class="nav-link active" data-scroll-target="#why-feature-engineering-matters"><span class="header-section-number">30.1</span> Why Feature Engineering Matters</a>
  <ul class="collapse">
  <li><a href="#the-data-representation-problem" id="toc-the-data-representation-problem" class="nav-link" data-scroll-target="#the-data-representation-problem">The Data Representation Problem</a></li>
  <li><a href="#a-motivating-example-predicting-house-prices" id="toc-a-motivating-example-predicting-house-prices" class="nav-link" data-scroll-target="#a-motivating-example-predicting-house-prices">A Motivating Example: Predicting House Prices</a></li>
  <li><a href="#when-to-invest-in-feature-engineering" id="toc-when-to-invest-in-feature-engineering" class="nav-link" data-scroll-target="#when-to-invest-in-feature-engineering">When to Invest in Feature Engineering</a></li>
  </ul></li>
  <li><a href="#common-feature-engineering-techniques" id="toc-common-feature-engineering-techniques" class="nav-link" data-scroll-target="#common-feature-engineering-techniques"><span class="header-section-number">30.2</span> Common Feature Engineering Techniques</a>
  <ul class="collapse">
  <li><a href="#encoding-categorical-variables" id="toc-encoding-categorical-variables" class="nav-link" data-scroll-target="#encoding-categorical-variables">Encoding Categorical Variables</a></li>
  <li><a href="#scaling-and-normalization" id="toc-scaling-and-normalization" class="nav-link" data-scroll-target="#scaling-and-normalization">Scaling and Normalization</a></li>
  <li><a href="#creating-new-features" id="toc-creating-new-features" class="nav-link" data-scroll-target="#creating-new-features">Creating New Features</a></li>
  <li><a href="#handling-missing-data" id="toc-handling-missing-data" class="nav-link" data-scroll-target="#handling-missing-data">Handling Missing Data</a></li>
  </ul></li>
  <li><a href="#feature-engineering-with-scikit-learn" id="toc-feature-engineering-with-scikit-learn" class="nav-link" data-scroll-target="#feature-engineering-with-scikit-learn"><span class="header-section-number">30.3</span> Feature Engineering with Scikit-Learn</a>
  <ul class="collapse">
  <li><a href="#using-transformers" id="toc-using-transformers" class="nav-link" data-scroll-target="#using-transformers">Using Transformers</a></li>
  <li><a href="#building-pipelines-for-reproducible-workflows" id="toc-building-pipelines-for-reproducible-workflows" class="nav-link" data-scroll-target="#building-pipelines-for-reproducible-workflows">Building Pipelines for Reproducible Workflows</a></li>
  <li><a href="#practical-example-end-to-end-pipeline" id="toc-practical-example-end-to-end-pipeline" class="nav-link" data-scroll-target="#practical-example-end-to-end-pipeline">Practical Example: End-to-End Pipeline</a></li>
  </ul></li>
  <li><a href="#beyond-the-basics" id="toc-beyond-the-basics" class="nav-link" data-scroll-target="#beyond-the-basics"><span class="header-section-number">30.4</span> Beyond the Basics</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">30.5</span> Summary</a></li>
  <li><a href="#end-of-chapter-exercises" id="toc-end-of-chapter-exercises" class="nav-link" data-scroll-target="#end-of-chapter-exercises"><span class="header-section-number">30.6</span> End of Chapter Exercises</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/edit/main/30-feature-engineering.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./28-cross-validation.html">Module 11</a></li><li class="breadcrumb-item"><a href="./30-feature-engineering.html"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Feature Engineering</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-feature-engineering" class="quarto-section-identifier"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Feature Engineering</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Consider this scenario: You’re building a model to predict house prices using just two features—square footage and year built. Your model achieves an RMSE of 20,247. Not bad, but could be better. Now, what if you created a new feature: <em>house age</em> (calculated as current year minus year built)? Suddenly, your RMSE drops to 17,138. By creating just one thoughtful feature, you’ve significantly improved your model’s performance.</p>
<p>This is the essence of <strong>feature engineering</strong>—the process of creating, transforming, and selecting features to help machine learning models better understand patterns in your data. It’s often said that in machine learning, “garbage in, garbage out.” Feature engineering is how we turn raw data into the high-quality input that models need to make accurate predictions.</p>
<p>Back in Chapter 21, you learned about dummy encoding as a way to convert categorical variables into numerical format so you could apply a linear regression model to that data. That was your first introduction to feature engineering! In this chapter, we’ll explore the full toolkit of feature engineering techniques—from encoding and scaling to creating new features and handling missing data. You’ll also learn how to build reproducible pipelines that prevent common pitfalls like data leakage. By the end, you’ll understand not just <em>how</em> to engineer features, but <em>when</em> and <em>why</em> each technique is appropriate for different situations.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li>Explain why feature engineering is critical for model performance and when to invest effort in it</li>
<li>Apply encoding strategies for categorical variables (dummy/one-hot, label, and ordinal encoding)</li>
<li>Scale and normalize numerical features using StandardScaler and MinMaxScaler</li>
<li>Create new features using polynomial terms, interaction terms, and domain knowledge</li>
<li>Handle missing data strategically through imputation or deletion, including missingness indicators</li>
<li>Build end-to-end feature engineering pipelines with scikit-learn to prevent data leakage</li>
<li>Recognize when different techniques are appropriate based on your data, model, and goals</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Follow along in Colab
</div>
</div>
<div class="callout-body-container callout-body">
<p>As you read through this chapter, we encourage you to follow along using the <a href="https://github.com/bradleyboehmke/uc-bana-4080/blob/main/example-notebooks/30_feature_engineering.ipynb">companion notebook</a> in Google Colab (or another editor of your choice). This interactive notebook lets you run all the code examples covered here—and experiment with your own ideas.</p>
<p>👉 Open the <a href="https://colab.research.google.com/github/bradleyboehmke/uc-bana-4080/blob/main/example-notebooks/30_feature_engineering.ipynb">Feature Engineering Notebook in Colab</a>.</p>
</div>
</div>
<section id="why-feature-engineering-matters" class="level2" data-number="30.1">
<h2 data-number="30.1" class="anchored" data-anchor-id="why-feature-engineering-matters"><span class="header-section-number">30.1</span> Why Feature Engineering Matters</h2>
<section id="the-data-representation-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-data-representation-problem">The Data Representation Problem</h3>
<p>Machine learning algorithms learn patterns from the data you provide. However, raw data often doesn’t directly represent the underlying patterns you want to learn. This is what we call the <strong>data representation problem</strong>.</p>
<p>Consider these examples:</p>
<ul>
<li><strong>Dates and times</strong>: The value “2024-03-15 14:30:00” doesn’t directly tell a model that it’s a Friday afternoon in March, even though this timing might be crucial for predicting website traffic</li>
<li><strong>Text data</strong>: The phrase “excellent product!” needs to be converted into numbers before most algorithms can process it</li>
<li><strong>Measurements</strong>: Height and weight are useful, but Body Mass Index (BMI), which combines these measurements, might be even more predictive for health-related predictions</li>
</ul>
<p>Good feature engineering bridges this gap by transforming raw data into representations that make it easier for algorithms to identify patterns.</p>
</section>
<section id="a-motivating-example-predicting-house-prices" class="level3">
<h3 class="anchored" data-anchor-id="a-motivating-example-predicting-house-prices">A Motivating Example: Predicting House Prices</h3>
<p>Let’s see feature engineering in action. Imagine you’re predicting house prices using the Ames housing dataset. You might start with these basic features:</p>
<ul>
<li><strong>GrLivArea</strong>: Above-ground living area in square feet</li>
<li><strong>YearBuilt</strong>: Original construction year</li>
<li><strong>FullBath</strong>: Number of full bathrooms</li>
</ul>
<p>Now, think like a homebuyer. What really matters when you’re evaluating a house?</p>
<ul>
<li>Instead of year built, you probably care about <strong>house age</strong>—a 5-year-old house feels much newer than a 50-year-old house</li>
<li>Instead of just full bathrooms, you might want to know the <strong>total number of bathrooms</strong> (including half baths)</li>
<li>You might care about the <strong>square footage per room</strong>—a house with 3000 sq ft and 10 rooms (bedrooms, bathrooms, living vs dining room) may feel cramped, while 3000 sq ft with 5 rooms feels spacious and aligns with a more modern open concept.</li>
<li>Also, consider that these features are on <strong>different numeric scales</strong>—GrLivArea ranges from hundreds to thousands, YearBuilt ranges from 1800s to 2000s, and FullBath ranges from 0 to 4. With many ML algorithms (especially those based on distances or gradients), larger-valued features like GrLivArea can dominate smaller-valued features like FullBath, even if both are equally important to homebuyers. This is why <strong>standardizing</strong> (scaling) your features is often necessary.</li>
</ul>
<p>By creating these engineered features and properly scaling them, you’re helping your model understand what makes houses valuable in ways that raw data alone can’t capture.</p>
</section>
<section id="when-to-invest-in-feature-engineering" class="level3">
<h3 class="anchored" data-anchor-id="when-to-invest-in-feature-engineering">When to Invest in Feature Engineering</h3>
<p>Feature engineering can be time-consuming. So when should you invest the effort?</p>
<p><strong>Invest heavily in feature engineering when:</strong></p>
<ul>
<li><strong>You have domain expertise</strong>: Knowledge about real estate, finance, healthcare, etc., can guide powerful feature creation. If you lack the knowledge or access to those that do have the knowledge, then some feature engineering efforts may be fruitless.</li>
<li><strong>You have smaller datasets</strong>: With fewer than 10,000 rows, good features are critical.</li>
<li><strong>You’re using traditional ML algorithms</strong>: Linear regression, decision trees, and SVMs benefit greatly from well-engineered features.</li>
<li><strong>Interpretability matters</strong>: Engineered features can make models easier to explain to stakeholders.</li>
<li><strong>You have time to experiment</strong>: Feature engineering is iterative—you create, test, and refine.</li>
</ul>
<p><strong>Invest less in feature engineering when:</strong></p>
<ul>
<li><strong>You have massive datasets</strong>: With millions of rows, deep learning can automatically discover feature representations.</li>
<li><strong>You need quick baseline models</strong>: Sometimes speed matters more than optimal performance.</li>
<li><strong>Raw features already work well</strong>: If your baseline performs well, complex feature engineering may not be needed.</li>
<li><strong>You’re using algorithms that handle feature interactions</strong>: Gradient boosting machines and neural networks can capture some interactions automatically.</li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>The 80/20 Rule
</div>
</div>
<div class="callout-body-container callout-body">
<p>Data scientists often spend 80% of their time on data preparation and feature engineering, and only 20% on model selection and tuning. This isn’t inefficiency—it’s because good features make a bigger difference than fancy algorithms!</p>
</div>
</div>
</section>
</section>
<section id="common-feature-engineering-techniques" class="level2" data-number="30.2">
<h2 data-number="30.2" class="anchored" data-anchor-id="common-feature-engineering-techniques"><span class="header-section-number">30.2</span> Common Feature Engineering Techniques</h2>
<section id="encoding-categorical-variables" class="level3">
<h3 class="anchored" data-anchor-id="encoding-categorical-variables">Encoding Categorical Variables</h3>
<p>Machine learning algorithms work with numbers, not categories. When you have categorical variables (like neighborhood names or product types), you need to convert them into numerical format. You’ve already learned about dummy encoding—let’s review it and explore other encoding strategies.</p>
<section id="revisiting-dummyone-hot-encoding" class="level4">
<h4 class="anchored" data-anchor-id="revisiting-dummyone-hot-encoding">Revisiting Dummy/One-Hot Encoding</h4>
<p><strong>Dummy encoding</strong> (also called one-hot encoding) creates separate binary columns for each category:</p>
<div id="d5d9e132" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Ames housing data</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>ames <span class="op">=</span> pd.read_csv(<span class="st">'../data/ames_clean.csv'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the BldgType (building type) variable</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Building types in the dataset:"</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ames[<span class="st">'BldgType'</span>].value_counts())</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dummy variables for building type</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>bldg_dummies <span class="op">=</span> pd.get_dummies(ames[<span class="st">'BldgType'</span>], prefix<span class="op">=</span><span class="st">'BldgType'</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Show first few rows</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Dummy encoded building types (first 5 rows):"</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>bldg_dummies.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Building types in the dataset:
BldgType
1Fam      1220
TwnhsE     114
Duplex      52
Twnhs       43
2fmCon      31
Name: count, dtype: int64

Dummy encoded building types (first 5 rows):</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">BldgType_1Fam</th>
<th data-quarto-table-cell-role="th">BldgType_2fmCon</th>
<th data-quarto-table-cell-role="th">BldgType_Duplex</th>
<th data-quarto-table-cell-role="th">BldgType_Twnhs</th>
<th data-quarto-table-cell-role="th">BldgType_TwnhsE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>This creates five new columns (one for each building type like <code>BldgType_1Fam</code>, <code>BldgType_TwnhsE</code>, etc.), each containing <code>True</code> or <code>False</code> (the equivalent to <code>1</code> or <code>0</code>) to indicate whether that house is of that type.</p>
<p><strong>When to use dummy encoding:</strong></p>
<ul>
<li>The categorical variable has <strong>no inherent order</strong> (like building types or neighborhood names)</li>
<li>You’re using <strong>linear models</strong> or algorithms that require numerical input</li>
<li>The number of categories is <strong>relatively small</strong> (typically fewer than 10-15)</li>
</ul>
<p><strong>Watch out for:</strong></p>
<ul>
<li><strong>The dummy variable trap</strong>: For linear regression, drop one category to avoid multicollinearity</li>
<li><strong>High cardinality</strong>: Variables with many categories (like ZIP codes with 40,000+ values) create too many features</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Avoid the dummy variable trap by dropping the first category</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>bldg_dummies_safe <span class="op">=</span> pd.get_dummies(ames[<span class="st">'BldgType'</span>],</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>                                   prefix<span class="op">=</span><span class="st">'BldgType'</span>,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>                                   drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Original columns: </span><span class="sc">{</span><span class="bu">len</span>(bldg_dummies.columns)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"After dropping first: </span><span class="sc">{</span><span class="bu">len</span>(bldg_dummies_safe.columns)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="label-encoding" class="level4">
<h4 class="anchored" data-anchor-id="label-encoding">Label Encoding</h4>
<p>While dummy encoding is powerful, it has a drawback: it can create many columns when you have categories with high cardinality (many unique values). The Ames dataset has 28 different neighborhoods—dummy encoding would create 28 new columns! This can quickly make your dataset unwieldy and slow down model training.</p>
<p><strong>Label encoding</strong> offers a more compact alternative by assigning a unique integer to each category (or neighborhood in our example), creating just one column instead of many. However, this simplicity comes with an important caveat that you need to understand before using it.</p>
<div id="3d34ef8e" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Check how many neighborhoods we have</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of unique neighborhoods: </span><span class="sc">{</span>ames[<span class="st">'Neighborhood'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Sample neighborhoods:"</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ames[<span class="st">'Neighborhood'</span>].value_counts().head())</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply label encoding</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>ames[<span class="st">'Neighborhood_Encoded'</span>] <span class="op">=</span> le.fit_transform(ames[<span class="st">'Neighborhood'</span>])</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the mapping for a few examples</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Label encoding results (first 10 rows):"</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>ames[[<span class="st">'Neighborhood'</span>, <span class="st">'Neighborhood_Encoded'</span>]].head(<span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of unique neighborhoods: 25

Sample neighborhoods:
Neighborhood
NAmes      225
CollgCr    150
OldTown    113
Edwards    100
Somerst     86
Name: count, dtype: int64

Label encoding results (first 10 rows):</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Neighborhood</th>
<th data-quarto-table-cell-role="th">Neighborhood_Encoded</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>CollgCr</td>
<td>5</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>Veenker</td>
<td>24</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>CollgCr</td>
<td>5</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>Crawfor</td>
<td>6</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>NoRidge</td>
<td>15</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">5</th>
<td>Mitchel</td>
<td>11</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">6</th>
<td>Somerst</td>
<td>21</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">7</th>
<td>NWAmes</td>
<td>14</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">8</th>
<td>OldTown</td>
<td>17</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">9</th>
<td>BrkSide</td>
<td>3</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p><strong>When to use label encoding:</strong></p>
<ul>
<li>With <strong>tree-based models</strong> (decision trees, random forests) that can handle ordinal relationships</li>
<li>For <strong>ordinal variables</strong> with natural ordering (Small &lt; Medium &lt; Large)</li>
<li>When you need to <strong>save memory</strong> with high-cardinality features</li>
</ul>
<p><strong>When NOT to use label encoding:</strong></p>
<ul>
<li>With <strong>linear models</strong>—they’ll incorrectly assume the numbers have mathematical meaning (e.g., that “Suburbs=2” is twice “Downtown=0”)</li>
<li>For <strong>nominal categories</strong> with no inherent order</li>
</ul>
<div class="callout callout-style-simple callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Common Pitfall
</div>
</div>
<div class="callout-body-container callout-body">
<p>Never use label encoding for non-ordinal categorical variables with linear models! The model will treat the numeric codes as if they have magnitude (e.g., category 3 is “three times” category 1), which is rarely meaningful.</p>
</div>
</div>
</section>
<section id="ordinal-encoding" class="level4">
<h4 class="anchored" data-anchor-id="ordinal-encoding">Ordinal Encoding</h4>
<p>Not all categorical variables are created equal. Some categories have a natural, meaningful order—like rating scales (Poor &lt; Fair &lt; Good &lt; Excellent), education levels (High School &lt; Bachelor’s &lt; Master’s &lt; PhD), or t-shirt sizes (Small &lt; Medium &lt; Large &lt; XL). These are called <strong>ordinal variables</strong>.</p>
<p>For ordinal variables, we want to preserve the inherent ordering in our encoding. Simply using label encoding might accidentally assign numbers that don’t reflect the true order (e.g., “Fair” might get 3 and “Poor” might get 1, but that’s arbitrary). Instead, we should create custom mappings that explicitly capture the meaningful order. This allows our models to understand that “Excellent” is better than “Good,” which is better than “Fair.”</p>
<p>The Ames dataset has several ordinal quality variables. Let’s use <code>ExterQual</code> (exterior material quality) as an example:</p>
<div id="a128f48a" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the exterior quality variable</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Exterior quality categories:"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ames[<span class="st">'ExterQual'</span>].value_counts().sort_index())</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create custom ordinal mapping that preserves the quality order</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># In the Ames data: Po = Poor, Fa = Fair, TA = Typical/Average, Gd = Good, Ex = Excellent</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>quality_map <span class="op">=</span> {</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Po'</span>: <span class="dv">1</span>,  <span class="co"># Poor</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Fa'</span>: <span class="dv">2</span>,  <span class="co"># Fair</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'TA'</span>: <span class="dv">3</span>,  <span class="co"># Typical/Average</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Gd'</span>: <span class="dv">4</span>,  <span class="co"># Good</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Ex'</span>: <span class="dv">5</span>   <span class="co"># Excellent</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the mapping</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>ames[<span class="st">'ExterQual_Encoded'</span>] <span class="op">=</span> ames[<span class="st">'ExterQual'</span>].<span class="bu">map</span>(quality_map)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the results</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Ordinal encoding results (first 10 rows):"</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ames[[<span class="st">'ExterQual'</span>, <span class="st">'ExterQual_Encoded'</span>]].head(<span class="dv">10</span>))</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify the encoding preserves order</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Mean sale price by exterior quality:"</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ames.groupby(<span class="st">'ExterQual_Encoded'</span>)[<span class="st">'SalePrice'</span>].mean().sort_index())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Exterior quality categories:
ExterQual
Ex     52
Fa     14
Gd    488
TA    906
Name: count, dtype: int64

Ordinal encoding results (first 10 rows):
  ExterQual  ExterQual_Encoded
0        Gd                  4
1        TA                  3
2        Gd                  4
3        TA                  3
4        Gd                  4
5        TA                  3
6        Gd                  4
7        TA                  3
8        TA                  3
9        TA                  3

Mean sale price by exterior quality:
ExterQual_Encoded
2     87985.214286
3    144341.313466
4    231633.510246
5    367360.961538
Name: SalePrice, dtype: float64</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Knowledge Check: Encoding Strategies
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Question:</strong> You’re building a linear regression model to predict customer satisfaction scores. You have three categorical variables:</p>
<ol type="1">
<li><strong>City</strong> (50 unique values: New York, Los Angeles, Chicago, etc.)</li>
<li><strong>Product Type</strong> (4 unique values: Basic, Standard, Premium, Deluxe)</li>
<li><strong>Customer Segment</strong> (3 unique values: A, B, C - with no inherent order)</li>
</ol>
<p>Which encoding strategy would you use for each variable and why?</p>
<details>
<summary>
Click to reveal answer
</summary>
<ol type="1">
<li><p><strong>City</strong> → <strong>Target encoding or label encoding</strong> (if using tree-based models). With 50 unique cities, dummy encoding would create 50 columns, leading to a sparse, high-dimensional dataset. For linear models, target encoding (replacing each city with average satisfaction for that city) can work well, though be careful of data leakage. For tree-based models, simple label encoding is fine.</p></li>
<li><p><strong>Product Type</strong> → <strong>Ordinal encoding</strong>. The products have a natural order (Basic &lt; Standard &lt; Premium &lt; Deluxe) that reflects increasing quality/features. Create a mapping like <code>{'Basic': 1, 'Standard': 2, 'Premium': 3, 'Deluxe': 4}</code>.</p></li>
<li><p><strong>Customer Segment</strong> → <strong>Dummy encoding (one-hot)</strong>. These segments have no inherent order, so dummy encoding is appropriate. With only 3 categories, this creates just 2-3 columns (use <code>drop_first=True</code> for linear regression to avoid multicollinearity).</p></li>
</ol>
</details>
</div>
</div>
</section>
</section>
<section id="scaling-and-normalization" class="level3">
<h3 class="anchored" data-anchor-id="scaling-and-normalization">Scaling and Normalization</h3>
<p><strong>Scaling</strong> and <strong>normalization</strong> are techniques that transform numerical features to a common range or distribution. While these terms are sometimes used interchangeably, they serve the same core purpose: putting all features on a level playing field so that no single feature dominates simply because of its numeric range.</p>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Why does this matter?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Many machine learning algorithms are sensitive to the scale of features. Imagine a dataset with house size (ranging from 500 to 5000 square feet) and number of bedrooms (ranging from 1 to 6). Without scaling, algorithms that use distance calculations—like k-Nearest Neighbors—would treat a difference of 100 square feet as much more significant than a difference of 1 bedroom, even though both might be equally important for predicting house prices.</p>
</div>
</div>
<p><strong>The two most common approaches are:</strong></p>
<ol type="1">
<li><p><strong>Standardization (Z-score normalization)</strong>: Transforms features to have a mean of 0 and standard deviation of 1. This centers your data and expresses values in terms of how many standard deviations they are from the mean.</p></li>
<li><p><strong>Min-Max scaling (normalization)</strong>: Transforms features to a fixed range, typically [0, 1]. This preserves the original distribution shape while compressing it into the specified range.</p></li>
</ol>
<p>Let’s explore both methods and understand when to use each one.</p>
<section id="standardscaler-z-score-normalization" class="level4">
<h4 class="anchored" data-anchor-id="standardscaler-z-score-normalization">StandardScaler (Z-score Normalization)</h4>
<p><strong>StandardScaler</strong> transforms features to have a mean of 0 and standard deviation of 1 based on:</p>
<p><span class="math display">\[z = \frac{x - \mu}{\sigma}\]</span></p>
<p>where <span class="math inline">\(x\)</span> is the feature value, <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation. Let’s see this in action:</p>
<div id="2f564e9c" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'HouseSize'</span>: [<span class="dv">1200</span>, <span class="dv">1800</span>, <span class="dv">950</span>, <span class="dv">2400</span>, <span class="dv">1600</span>],</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Bedrooms'</span>: [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">3</span>]</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply StandardScaler</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>scaled_data <span class="op">=</span> scaler.fit_transform(data)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>scaled_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    scaled_data,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">'HouseSize_Scaled'</span>, <span class="st">'Bedrooms_Scaled'</span>]</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(scaled_df)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>   HouseSize_Scaled  Bedrooms_Scaled
0         -0.776283        -1.069045
1          0.417998         0.267261
2         -1.273900        -1.069045
3          1.612280         1.603567
4          0.019905         0.267261</code></pre>
</div>
</div>
<p><strong>When to use StandardScaler:</strong></p>
<ul>
<li>For algorithms sensitive to feature magnitude (SVM, neural networks, k-NN)</li>
<li>When features have different units (age in years, income in dollars)</li>
<li>For linear regression with regularization (Ridge, Lasso)</li>
<li>As a <strong>default choice</strong>—it’s widely applicable</li>
</ul>
</section>
<section id="minmaxscaler" class="level4">
<h4 class="anchored" data-anchor-id="minmaxscaler">MinMaxScaler</h4>
<p><strong>MinMaxScaler</strong> transforms features to a fixed range, typically [0, 1] based on:</p>
<p><span class="math display">\[x_{scaled} = \frac{x - x_{min}}{x_{max} - x_{min}}\]</span></p>
<div id="55fd5b41" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>minmax <span class="op">=</span> MinMaxScaler()</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>minmax_scaled <span class="op">=</span> minmax.fit_transform(data)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>minmax_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    minmax_scaled,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">'HouseSize_MinMax'</span>, <span class="st">'Bedrooms_MinMax'</span>]</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(minmax_df)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>   HouseSize_MinMax  Bedrooms_MinMax
0          0.172414              0.0
1          0.586207              0.5
2          0.000000              0.0
3          1.000000              1.0
4          0.448276              0.5</code></pre>
</div>
</div>
<p><strong>When to use MinMaxScaler:</strong></p>
<ul>
<li>When you need features <strong>bounded in a specific range</strong></li>
<li>For neural networks with sigmoid or tanh activation functions</li>
<li>When you want to <strong>preserve zero values</strong> in sparse data</li>
<li>When your data <strong>isn’t normally distributed</strong></li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>When Scaling Matters (and When It Doesn’t)
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Scaling DOES matter for:</strong></p>
<ul>
<li>Linear regression with regularization (Lasso, Ridge, Elastic Net)</li>
<li>Support Vector Machines (SVM)</li>
<li>k-Nearest Neighbors (k-NN)</li>
<li>Neural networks</li>
<li>Principal Component Analysis (PCA)</li>
<li>K-means clustering</li>
<li>Gradient descent-based algorithms</li>
</ul>
<p><strong>Scaling DOESN’T matter for:</strong></p>
<ul>
<li>Tree-based models (decision trees, random forests, gradient boosting)</li>
<li>Naive Bayes</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Knowledge Check: When to Scale Features
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Question:</strong> You’re working on three different prediction problems. For each scenario, decide whether you need to scale your features and which scaling method (if any) would be most appropriate:</p>
<p><strong>Scenario 1:</strong> Predicting house prices using k-Nearest Neighbors (k-NN). Your features include square footage (ranging from 800-4,000), number of bedrooms (1-6), and year built (1920-2020).</p>
<p><strong>Scenario 2:</strong> Predicting customer churn using a Random Forest classifier. Features include account age in days (30-3,650), monthly charges in dollars (20-150), and number of support calls (0-25).</p>
<p><strong>Scenario 3:</strong> Predicting sales revenue using Ridge regression (L2 regularization). Features include advertising spend in thousands of dollars (1-500), website visits (100-50,000), and email open rate as a percentage (5-60).</p>
<details>
<summary>
Click to reveal answer
</summary>
<p><strong>Scenario 1:</strong> <strong>Yes, scale using StandardScaler (or MinMaxScaler).</strong> k-NN is distance-based, so it’s highly sensitive to feature magnitude. Without scaling, square footage (800-4,000 range) would dominate the distance calculation over bedrooms (1-6 range), even though bedrooms might be equally important. StandardScaler is a good default choice.</p>
<p><strong>Scenario 2:</strong> <strong>No scaling needed.</strong> Random Forest is tree-based and makes decisions through sequential splits, not distance or gradient calculations. Trees naturally handle features on different scales since they split based on thresholds, not absolute magnitudes. Scaling won’t hurt, but it won’t help either, and you can skip this preprocessing step.</p>
<p><strong>Scenario 3:</strong> <strong>Yes, scale using StandardScaler.</strong> Ridge regression uses L2 regularization, which penalizes the magnitude of coefficients. If features are on different scales, the regularization will unfairly penalize features with larger numeric ranges. Standardizing puts all features on equal footing, ensuring the regularization works fairly across all features. This is critical for any regularized linear model (Ridge, Lasso, Elastic Net).</p>
</details>
</div>
</div>
</section>
</section>
<section id="creating-new-features" class="level3">
<h3 class="anchored" data-anchor-id="creating-new-features">Creating New Features</h3>
<p>So far, we’ve focused on encoding categorical variables and scaling numerical features—essentially preparing the raw data we already have. But some of the most powerful features are ones you create yourself by combining or transforming existing features in meaningful ways. This is where feature engineering becomes truly creative and where domain knowledge becomes increasingly important.</p>
<p>Creating new features allows you to:</p>
<ul>
<li><strong>Capture relationships</strong> that aren’t obvious in individual features (e.g., the ratio of living area to lot size)</li>
<li><strong>Express domain insights</strong> that experts understand but raw data doesn’t capture (e.g., house age is often more meaningful than year built)</li>
<li><strong>Help models learn non-linear patterns</strong> even when using simple algorithms (e.g., adding squared terms to linear regression)</li>
<li><strong>Combine information</strong> from multiple features into a single, more predictive variable</li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>The role of domain knowledge
</div>
</div>
<div class="callout-body-container callout-body">
<p>While techniques like polynomial features are somewhat mechanical, the most impactful features come from understanding the problem domain. A real estate expert knows that square footage per room matters. A healthcare professional understands that BMI (weight/height²) is more predictive than weight or height alone. A marketing analyst recognizes that customer lifetime value depends on purchase frequency × average order value.</p>
<p>These insights don’t come from algorithms—they come from talking to experts, studying the domain, and thinking deeply about what truly drives the outcome you’re trying to predict.</p>
</div>
</div>
<p>Let’s explore three main approaches to creating new features:</p>
<section id="polynomial-features" class="level4">
<h4 class="anchored" data-anchor-id="polynomial-features">Polynomial Features</h4>
<p>Real-world relationships are often non-linear. Consider house prices and square footage: the first 1,000 square feet might add $100,000 to a home’s value, but the next 1,000 square feet might only add $60,000, and the third 1,000 square feet might add just $40,000. This is <strong>diminishing returns</strong>—a curved relationship that a simple linear model (which assumes constant returns) would miss.</p>
<p><strong>Polynomial features</strong> help capture these non-linear relationships by creating powers and products of your original features. When you add a squared term (<span class="math inline">\(\text{SqFt}^2\)</span>) to your model, you’re allowing it to learn curves instead of just straight lines. When you add cubic terms (<span class="math inline">\(\text{SqFt}^3\)</span>), you’re allowing even more complex curvature.</p>
<p>Let’s see how polynomial features capture different types of curves:</p>
<div id="cell-fig-polynomial-degrees" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div id="fig-polynomial-degrees" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-polynomial-degrees-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="30-feature-engineering_files/figure-html/fig-polynomial-degrees-output-1.png" width="758" height="374" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-polynomial-degrees-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;30.1: Comparison of linear vs polynomial relationships. The 2nd degree polynomial captures the gentle curve of diminishing returns, while the 3rd degree can model more complex patterns.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Notice how the linear model (red dashed line) misses the curve in the data, while the 2nd degree polynomial (blue line) captures the diminishing returns pattern nicely. The 3rd degree polynomial (green dotted line) can capture even more complex curves, but be careful—with higher degrees, you risk overfitting!</p>
<p><strong>Creating polynomial features in practice:</strong></p>
<div id="bdbece33" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> PolynomialFeatures</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Original data</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x1'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x2'</span>: [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create polynomial features (degree=2)</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>poly <span class="op">=</span> PolynomialFeatures(degree<span class="op">=</span><span class="dv">2</span>, include_bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>poly_features <span class="op">=</span> poly.fit_transform(data)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>poly_df <span class="op">=</span> pd.DataFrame(poly_features, columns<span class="op">=</span>poly.get_feature_names_out())</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(poly_df)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Creates: x1, x2, x1^2, x1*x2, x2^2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>    x1   x2  x1^2  x1 x2  x2^2
0  1.0  4.0   1.0    4.0  16.0
1  2.0  5.0   4.0   10.0  25.0
2  3.0  6.0   9.0   18.0  36.0</code></pre>
</div>
</div>
<p>For degree=2, this creates:</p>
<ul>
<li><strong>Original features</strong>: <span class="math inline">\(x_1, x_2\)</span></li>
<li><strong>Squared terms</strong>: <span class="math inline">\(x_1^2, x_2^2\)</span> (capture curvature in each feature)</li>
<li><strong>Interaction terms</strong>: <span class="math inline">\(x_1 \cdot x_2\)</span> (capture how features affect each other)</li>
</ul>
<p><strong>When to use polynomial features:</strong></p>
<ul>
<li>When relationships appear <strong>non-linear</strong> in scatter plots</li>
<li>To help <strong>linear models capture curvature</strong></li>
<li>When you have <strong>relatively few features</strong> (polynomials grow exponentially!)</li>
</ul>
<p><strong>Watch out for:</strong></p>
<ul>
<li><strong>Feature explosion</strong>: 10 features with degree=3 creates 220 features!</li>
<li><strong>Overfitting</strong>: Higher degrees can lead to overly complex models</li>
<li><strong>Computation time</strong>: More features = longer training time</li>
</ul>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>The Reality of High-Dimensional Data
</div>
</div>
<div class="callout-body-container callout-body">
<p>In our examples above, visualizing polynomial relationships is straightforward because we’re working with just one or two features. You can easily plot square footage vs.&nbsp;price and see the curve.</p>
<p>However, in real-world practice, you often deal with <strong>tens or even hundreds of features</strong>. Once you have more than 3 features, visualization becomes impossible, and identifying which features need polynomial terms becomes a significant challenge. You can’t simply “look at the curve” when working in 50-dimensional space!</p>
<p>This is why in practice, data scientists often:</p>
<ul>
<li>Start with <strong>domain knowledge</strong> to identify likely non-linear relationships</li>
<li>Use <strong>exploratory analysis</strong> to examine scatter plots for key features</li>
<li>Apply <strong>regularization techniques</strong> (like Lasso) that automatically handle feature selection</li>
<li>Rely on <strong>tree-based models</strong> (like random forests) that inherently capture non-linear relationships without needing polynomial features</li>
<li>Be selective: Add polynomial features only for the most important features, not all of them</li>
</ul>
</div>
</div>
</section>
<section id="interaction-terms" class="level4">
<h4 class="anchored" data-anchor-id="interaction-terms">Interaction Terms</h4>
<p><strong>Interaction terms</strong> capture how the effect of one feature depends on another:</p>
<div id="679cd274" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Real estate example</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>houses <span class="op">=</span> pd.DataFrame({</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Size_Sqft'</span>: [<span class="dv">1200</span>, <span class="dv">1200</span>, <span class="dv">2400</span>, <span class="dv">2400</span>],</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Neighborhood_Quality'</span>: [<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">5</span>]  <span class="co"># 1=poor, 5=excellent</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create interaction</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>houses[<span class="st">'Size_x_Quality'</span>] <span class="op">=</span> houses[<span class="st">'Size_Sqft'</span>] <span class="op">*</span> houses[<span class="st">'Neighborhood_Quality'</span>]</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(houses)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Size_Sqft  Neighborhood_Quality  Size_x_Quality
0       1200                     1            1200
1       1200                     5            6000
2       2400                     1            2400
3       2400                     5           12000</code></pre>
</div>
</div>
<p>This interaction captures an important insight: an extra square foot in an excellent neighborhood is worth more than an extra square foot in a poor neighborhood.</p>
<p><strong>Common interaction patterns:</strong></p>
<ul>
<li><strong>Quantity × Quality</strong>: Size × Neighborhood rating</li>
<li><strong>Time × Activity</strong>: Hour of day × Day of week (for predicting traffic)</li>
<li><strong>Price × Demand</strong>: Product price × Season (for sales forecasting)</li>
</ul>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>The Interaction Term Challenge
</div>
</div>
<div class="callout-body-container callout-body">
<p>Similar to polynomial features, creating interaction terms manually is reasonable when you have just a few features. You can thoughtfully identify which pairs of features might interact based on domain knowledge or exploratory analysis.</p>
<p>However, as your feature count grows, the number of potential interactions explodes even faster than polynomial terms. With 10 features, there are 45 possible pairwise interactions. With 50 features, there are 1,225 possible pairwise interactions. With 100 features, there are 4,950! Manually testing all these combinations is impractical, and including all of them leads to severe overfitting and computational issues.</p>
<p><strong>This is where certain models shine:</strong> Decision trees, random forests, gradient boosted machines (like XGBoost), and neural networks are particularly valuable because they <strong>automatically identify and capture interaction relationships</strong> during training.</p>
<ul>
<li><strong>Decision trees</strong> naturally model interactions through their splitting process—a split on feature A followed by a split on feature B effectively creates an A × B interaction</li>
<li><strong>Random forests and gradient boosting</strong> extend this capability across many trees, capturing complex interaction patterns</li>
<li><strong>Neural networks</strong> learn interactions through their hidden layers, combining features in increasingly complex ways</li>
</ul>
<p>This is one reason why tree-based models often perform well “out of the box” without extensive feature engineering—they’re discovering useful interactions automatically rather than requiring you to specify them manually.</p>
</div>
</div>
</section>
<section id="domain-specific-feature-creation" class="level4">
<h4 class="anchored" data-anchor-id="domain-specific-feature-creation">Domain-Specific Feature Creation</h4>
<p>While polynomial and interaction features are algorithmic approaches that you can apply to any dataset, <strong>domain-specific feature creation</strong> is where human expertise and creativity truly shine. This is where you step back from mechanical transformations and ask: “What do experts in this field actually care about? What drives the outcome I’m trying to predict?”</p>
<p>The most impactful features often come from this kind of domain knowledge. Instead of blindly creating <span class="math inline">\(x^2\)</span> or <span class="math inline">\(x \times y\)</span> for every feature, you thoughtfully create features that capture meaningful concepts in your problem domain:</p>
<ul>
<li>A <strong>real estate agent</strong> might tell you that “price per square foot” and “home age” matter more than raw square footage or year built</li>
<li>A <strong>doctor</strong> might explain that BMI, blood pressure ratios, or glucose change over time are more diagnostic than individual measurements</li>
<li>A <strong>marketing analyst</strong> might reveal that “average order value,” “time since last purchase,” or “purchase frequency” better predict customer lifetime value than raw transaction counts</li>
</ul>
<p>These features aren’t discovered through automated processes—they emerge from conversations with experts, reading domain literature, and developing intuition about what makes sense in context. Let’s see some examples in real estate:</p>
<div id="6ea8c3f3" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Real estate domain knowledge</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>houses <span class="op">=</span> pd.DataFrame({</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'GrLivArea'</span>: [<span class="dv">1500</span>, <span class="dv">2000</span>, <span class="dv">1800</span>],</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'LotArea'</span>: [<span class="dv">8000</span>, <span class="dv">10000</span>, <span class="dv">7500</span>],</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'YearBuilt'</span>: [<span class="dv">1990</span>, <span class="dv">2005</span>, <span class="dv">1978</span>],</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'YearRemodAdd'</span>: [<span class="dv">2015</span>, <span class="dv">2005</span>, <span class="dv">1978</span>],</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'TotalBsmtSF'</span>: [<span class="dv">1000</span>, <span class="dv">1200</span>, <span class="dv">900</span>],</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'GarageArea'</span>: [<span class="dv">400</span>, <span class="dv">500</span>, <span class="dv">350</span>]</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature 1: House age (more intuitive than year built)</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>current_year <span class="op">=</span> pd.Timestamp.now().year</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>houses[<span class="st">'Age'</span>] <span class="op">=</span> current_year <span class="op">-</span> houses[<span class="st">'YearBuilt'</span>]</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature 2: Was the house renovated?</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>houses[<span class="st">'Was_Renovated'</span>] <span class="op">=</span> (houses[<span class="st">'YearRemodAdd'</span>] <span class="op">&gt;</span> houses[<span class="st">'YearBuilt'</span>]).astype(<span class="bu">int</span>)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature 3: Years since renovation</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>houses[<span class="st">'Years_Since_Reno'</span>] <span class="op">=</span> current_year <span class="op">-</span> houses[<span class="st">'YearRemodAdd'</span>]</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature 4: Ratio of living area to lot area</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>houses[<span class="st">'Living_to_Lot_Ratio'</span>] <span class="op">=</span> houses[<span class="st">'GrLivArea'</span>] <span class="op">/</span> houses[<span class="st">'LotArea'</span>]</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature 5: Total interior space</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>houses[<span class="st">'Total_Interior_SF'</span>] <span class="op">=</span> houses[<span class="st">'GrLivArea'</span>] <span class="op">+</span> houses[<span class="st">'TotalBsmtSF'</span>]</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature 6: Total property size</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>houses[<span class="st">'Total_Property_SF'</span>] <span class="op">=</span> houses[<span class="st">'Total_Interior_SF'</span>] <span class="op">+</span> houses[<span class="st">'GarageArea'</span>]</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>houses[[<span class="st">'Age'</span>, <span class="st">'Was_Renovated'</span>, <span class="st">'Years_Since_Reno'</span>, <span class="st">'Living_to_Lot_Ratio'</span>, <span class="st">'Total_Interior_SF'</span>, <span class="st">'Total_Property_SF'</span>]]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Was_Renovated</th>
<th data-quarto-table-cell-role="th">Years_Since_Reno</th>
<th data-quarto-table-cell-role="th">Living_to_Lot_Ratio</th>
<th data-quarto-table-cell-role="th">Total_Interior_SF</th>
<th data-quarto-table-cell-role="th">Total_Property_SF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>35</td>
<td>1</td>
<td>10</td>
<td>0.1875</td>
<td>2500</td>
<td>2900</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>20</td>
<td>0</td>
<td>20</td>
<td>0.2000</td>
<td>3200</td>
<td>3700</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>47</td>
<td>0</td>
<td>47</td>
<td>0.2400</td>
<td>2700</td>
<td>3050</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Talk to Domain Experts
</div>
</div>
<div class="callout-body-container callout-body">
<p>The best features come from understanding the domain. If you’re working on real estate, talk to agents. For healthcare, consult doctors. For e-commerce, speak with sales teams. They’ll reveal what truly matters—insights you can’t get from the data alone.</p>
</div>
</div>
</section>
</section>
<section id="handling-missing-data" class="level3">
<h3 class="anchored" data-anchor-id="handling-missing-data">Handling Missing Data</h3>
<p>Real-world data is messy, and missing values are inevitable. Whether it’s a survey respondent who skipped a question, a sensor that malfunctioned, or a data entry error, you’ll encounter gaps in your data.</p>
<div class="callout callout-style-simple callout-important">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>How you handle these missing values can significantly impact your model’s performance and validity.</strong></p>
</div>
</div>
</div>
<p>The challenge is that most machine learning algorithms can’t handle missing values—they’ll either throw an error or silently exclude observations with missing data. This means you need a strategy for dealing with missingness before you can train your models.</p>
<p><strong>Why does this matter?</strong> Consider these scenarios:</p>
<ul>
<li>If you <strong>drop all rows with any missing values</strong>, you might lose 50% of your data, severely limiting your model’s ability to learn</li>
<li>If you <strong>fill in missing values poorly</strong>, you introduce bias—for example, replacing all missing incomes with $50,000 when most missing values are actually from high earners who declined to answer</li>
<li>If you <strong>ignore the pattern of missingness</strong>, you might miss important signals—for instance, customers who don’t provide their phone number might behave differently than those who do</li>
</ul>
<p>There are two main approaches: <strong>imputation</strong> (filling in missing values) and <strong>deletion</strong> (removing data with missing values). Let’s explore the most common imputation strategies first, then discuss when deletion might be appropriate.</p>
<section id="simple-imputation-strategies" class="level4">
<h4 class="anchored" data-anchor-id="simple-imputation-strategies">Simple Imputation Strategies</h4>
<p><strong>Strategy 1: Mean/Median Imputation</strong></p>
<p><strong>What it does:</strong> Replace missing numerical values with the mean (average) or median (middle value) of the non-missing values in that feature.</p>
<p><strong>When to use it:</strong></p>
<ul>
<li>For <strong>numerical features</strong> with missing values</li>
<li>When you believe missing values are <strong>randomly distributed</strong> (missing at random)</li>
<li>As a <strong>quick baseline</strong> to establish whether imputation helps</li>
<li>When the feature is <strong>roughly normally distributed</strong> (mean) or has <strong>outliers</strong> (median)</li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Best practice
</div>
</div>
<div class="callout-body-container callout-body">
<p>Prefer <strong>median over mean</strong> for most cases, as the median is more robust to outliers and extreme values. The mean can be skewed by a few very large or small values, while the median represents the “typical” value better.</p>
</div>
</div>
<div id="780b315c" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Data with missing values</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Age'</span>: [<span class="dv">25</span>, <span class="dv">30</span>, np.nan, <span class="dv">45</span>, np.nan, <span class="dv">35</span>],</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Income'</span>: [<span class="dv">50000</span>, <span class="dv">60000</span>, <span class="dv">55000</span>, np.nan, <span class="dv">70000</span>, <span class="dv">65000</span>]</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original data with missing values:"</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute with median (more robust to outliers)</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>imputed_data <span class="op">=</span> imputer.fit_transform(data)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>imputed_df <span class="op">=</span> pd.DataFrame(imputed_data, columns<span class="op">=</span>[<span class="st">'Age'</span>, <span class="st">'Income'</span>])</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">After median imputation:"</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(imputed_df)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original data with missing values:
    Age   Income
0  25.0  50000.0
1  30.0  60000.0
2   NaN  55000.0
3  45.0      NaN
4   NaN  70000.0
5  35.0  65000.0

After median imputation:
    Age   Income
0  25.0  50000.0
1  30.0  60000.0
2  32.5  55000.0
3  45.0  60000.0
4  32.5  70000.0
5  35.0  65000.0</code></pre>
</div>
</div>
<p><strong>Strategy 2: Mode Imputation</strong></p>
<p><strong>What it does:</strong> Replace missing values in categorical variables with the most frequently occurring category (the mode).</p>
<p><strong>When to use it:</strong></p>
<ul>
<li>For <strong>categorical features</strong> with missing values</li>
<li>When you believe the most common category is a <strong>reasonable default</strong></li>
<li>When categories represent <strong>discrete choices</strong> rather than ordinal rankings</li>
<li>As a simple baseline for categorical data</li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Best practice
</div>
</div>
<div class="callout-body-container callout-body">
<p>This works well when one category is dominant (appears much more frequently than others). If categories are evenly distributed, mode imputation essentially makes an arbitrary choice. In such cases, consider whether treating missingness as its own category (“Unknown”) might be more honest.</p>
</div>
</div>
<div id="a8e8c24b" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Categorical data with missing values</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>cat_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Color'</span>: [<span class="st">'Red'</span>, <span class="st">'Blue'</span>, np.nan, <span class="st">'Red'</span>, <span class="st">'Blue'</span>, np.nan, <span class="st">'Red'</span>]</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original categorical data:"</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cat_data)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute with most frequent value (mode)</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'most_frequent'</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>cat_data[<span class="st">'Color_Imputed'</span>] <span class="op">=</span> imputer.fit_transform(cat_data[[<span class="st">'Color'</span>]]).ravel()</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">After mode imputation:"</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cat_data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original categorical data:
  Color
0   Red
1  Blue
2   NaN
3   Red
4  Blue
5   NaN
6   Red

After mode imputation:
  Color Color_Imputed
0   Red           Red
1  Blue          Blue
2   NaN           Red
3   Red           Red
4  Blue          Blue
5   NaN           Red
6   Red           Red</code></pre>
</div>
</div>
<p><strong>Strategy 3: Constant Imputation</strong></p>
<p><strong>What it does:</strong> Fill all missing values with a specific constant value that you choose (like 0, -1, -999, or “Unknown”).</p>
<p><strong>When to use it:</strong></p>
<ul>
<li>When you want to <strong>explicitly mark missing values</strong> rather than pretend you know what they should be</li>
<li>When <strong>0 has special meaning</strong> in your domain (e.g., 0 items purchased, 0 days since last login)</li>
<li>When missing values might represent a <strong>distinct category</strong> (e.g., “Unknown”, “Not Applicable”)</li>
<li>For categorical variables where you want to <strong>preserve the missingness as information</strong></li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Best practice
</div>
</div>
<div class="callout-body-container callout-body">
<p>Choose your fill value carefully based on your domain. For numerical data, use a value that’s clearly outside the normal range (like -999 for age) so it’s obvious it’s a placeholder. For categorical data, use descriptive labels like “Unknown” or “Not_Provided” rather than arbitrary values. Consider combining this with a missingness indicator feature.</p>
</div>
</div>
<div id="5bab790c" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute with a constant value</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'constant'</span>, fill_value<span class="op">=</span><span class="st">'Unknown'</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>cat_data[<span class="st">'Color_Constant'</span>] <span class="op">=</span> imputer.fit_transform(cat_data[[<span class="st">'Color'</span>]]).ravel()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">After constant imputation with 'Unknown':"</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cat_data)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Example with numerical data using a clear placeholder</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>age_data <span class="op">=</span> pd.DataFrame({<span class="st">'Age'</span>: [<span class="dv">25</span>, <span class="dv">30</span>, np.nan, <span class="dv">45</span>, np.nan, <span class="dv">35</span>]})</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>imputer_num <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'constant'</span>, fill_value<span class="op">=-</span><span class="dv">999</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>age_data[<span class="st">'Age_Imputed'</span>] <span class="op">=</span> imputer_num.fit_transform(age_data[[<span class="st">'Age'</span>]]).ravel()</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Numerical constant imputation (placeholder: -999):"</span>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(age_data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
After constant imputation with 'Unknown':
  Color Color_Imputed Color_Constant
0   Red           Red            Red
1  Blue          Blue           Blue
2   NaN           Red        Unknown
3   Red           Red            Red
4  Blue          Blue           Blue
5   NaN           Red        Unknown
6   Red           Red            Red

Numerical constant imputation (placeholder: -999):
    Age  Age_Imputed
0  25.0         25.0
1  30.0         30.0
2   NaN       -999.0
3  45.0         45.0
4   NaN       -999.0
5  35.0         35.0</code></pre>
</div>
</div>
</section>
<section id="when-to-drop-vs.-impute" class="level4">
<h4 class="anchored" data-anchor-id="when-to-drop-vs.-impute">When to Drop vs.&nbsp;Impute</h4>
<p>One of the most important decisions in handling missing data is whether to <strong>delete</strong> observations/features with missing values or <strong>impute</strong> (fill in) those missing values. This choice involves trade-offs between data quantity and data quality.</p>
<p><strong>The fundamental trade-off:</strong></p>
<ul>
<li><strong>Dropping data</strong> preserves the integrity of your remaining data (you’re only working with truly observed values), but you lose information and potentially introduce bias if the missing data isn’t random</li>
<li><strong>Imputing data</strong> preserves your sample size, but you’re making assumptions about what the missing values should be, which could introduce different biases</li>
</ul>
<p><strong>Drop missing values when:</strong></p>
<ul>
<li>You have <strong>plenty of data</strong> and few missing values (&lt; 5%)—losing a few rows won’t hurt your model’s ability to learn</li>
<li>Missing values occur <strong>completely at random</strong> (MCAR)—there’s no pattern to what’s missing, so dropping them won’t bias your results</li>
<li>The feature isn’t critical to your analysis—if a column is mostly empty, it probably won’t help predictions anyway</li>
<li><strong>The missingness pattern suggests data quality issues</strong>—if an entire survey section is skipped or a sensor malfunctioned, those rows might be unreliable overall</li>
</ul>
<div id="a0ac8544" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample data for demonstration</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>sample_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Age'</span>: [<span class="dv">25</span>, <span class="dv">30</span>, np.nan, <span class="dv">45</span>, np.nan, <span class="dv">35</span>],</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Income'</span>: [<span class="dv">50000</span>, <span class="dv">60000</span>, <span class="dv">55000</span>, np.nan, <span class="dv">70000</span>, <span class="dv">65000</span>]</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop rows with any missing values</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>data_dropped <span class="op">=</span> sample_data.dropna()</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original rows: </span><span class="sc">{</span><span class="bu">len</span>(sample_data)<span class="sc">}</span><span class="ss">, After dropping: </span><span class="sc">{</span><span class="bu">len</span>(data_dropped)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Data after dropping rows with missing values:"</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_dropped)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop columns with more than 50% missing</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="bu">len</span>(sample_data)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>data_drop_cols <span class="op">=</span> sample_data.dropna(thresh<span class="op">=</span>threshold, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Original columns: </span><span class="sc">{</span>sample_data<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">, After dropping: </span><span class="sc">{</span>data_drop_cols<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_drop_cols)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original rows: 6, After dropping: 3

Data after dropping rows with missing values:
    Age   Income
0  25.0  50000.0
1  30.0  60000.0
5  35.0  65000.0

Original columns: 2, After dropping: 2
    Age   Income
0  25.0  50000.0
1  30.0  60000.0
2   NaN  55000.0
3  45.0      NaN
4   NaN  70000.0
5  35.0  65000.0</code></pre>
</div>
</div>
<p><strong>Impute missing values when:</strong></p>
<ul>
<li>Missing values are <strong>numerous</strong> (&gt; 5%)—dropping rows would significantly reduce your dataset size and statistical power</li>
<li>You <strong>can’t afford to lose data</strong>—in small datasets, every observation matters</li>
<li>The <strong>missingness is not random</strong> (MAR or MNAR)—there’s a systematic pattern to what’s missing, so dropping those rows would introduce bias</li>
<li>The feature is <strong>highly predictive</strong>—you don’t want to lose an important feature just because some values are missing</li>
<li>You’re doing <strong>predictive modeling</strong> rather than statistical inference—slight bias from imputation may be acceptable if it improves predictions</li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Practical Advice
</div>
</div>
<div class="callout-body-container callout-body">
<p>In practice, you should often <strong>try both approaches</strong> (dropping vs.&nbsp;imputing) and evaluate which gives better model performance on a validation set. The “best” approach depends on your specific dataset and prediction task. Don’t assume imputation is always better just because it preserves more data!</p>
</div>
</div>
<p><strong>Advanced technique: Missingness indicator</strong></p>
<p>This is one of the most valuable but underused techniques in feature engineering. The core insight is: <strong>Sometimes the fact that a value is missing is itself informative</strong>.</p>
<p><strong>Why missingness can be informative:</strong></p>
<p>Consider these real-world examples where missing data tells a story:</p>
<ul>
<li><strong>Income surveys</strong>: High earners often decline to report income due to privacy concerns. A missing income value might actually signal “likely high earner” rather than being random noise</li>
<li><strong>Medical records</strong>: Missing test results might indicate a doctor didn’t think the test was necessary (suggesting the patient is healthier), or that the patient couldn’t afford it (suggesting lower socioeconomic status)</li>
<li><strong>E-commerce</strong>: Customers who don’t provide a phone number might be more privacy-conscious and have different shopping behaviors</li>
<li><strong>Credit applications</strong>: Missing employment history might indicate job instability or gaps in employment</li>
</ul>
<p>In all these cases, we don’t just want to impute the missing value—we want to <strong>capture the fact that it was missing</strong> as a feature itself.</p>
<p><strong>How to implement it:</strong></p>
<p>The approach is simple: create a binary indicator variable (0 or 1) that flags whether a value was originally missing, then impute the original feature:</p>
<div id="e93b67a2" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create fresh data for this example</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>indicator_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Age'</span>: [<span class="dv">25</span>, <span class="dv">30</span>, np.nan, <span class="dv">45</span>, np.nan, <span class="dv">35</span>],</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Income'</span>: [<span class="dv">50000</span>, <span class="dv">60000</span>, <span class="dv">55000</span>, np.nan, <span class="dv">70000</span>, <span class="dv">65000</span>]</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create indicator for missingness</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>indicator_data[<span class="st">'Age_Was_Missing'</span>] <span class="op">=</span> indicator_data[<span class="st">'Age'</span>].isna().astype(<span class="bu">int</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Then impute the original column</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>indicator_data[<span class="st">'Age'</span>] <span class="op">=</span> indicator_data[<span class="st">'Age'</span>].fillna(indicator_data[<span class="st">'Age'</span>].median())</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Data with missingness indicator:"</span>)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(indicator_data[[<span class="st">'Age'</span>, <span class="st">'Age_Was_Missing'</span>]])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data with missingness indicator:
    Age  Age_Was_Missing
0  25.0                0
1  30.0                0
2  32.5                1
3  45.0                0
4  32.5                1
5  35.0                0</code></pre>
</div>
</div>
<p><strong>What this gives you:</strong></p>
<p>Now your model has access to <strong>two pieces of information</strong> instead of one:</p>
<ol type="1">
<li><strong>The imputed value</strong> (Age = 32.5 for rows that were missing)—this keeps your model from breaking due to missing data</li>
<li><strong>The fact that it was missing</strong> (Age_Was_Missing = 1)—this lets the model learn that “missing age” might correlate with your target variable</li>
</ol>
<p><strong>When to use missingness indicators:</strong></p>
<ul>
<li>When you suspect <strong>missingness is not random</strong>—there’s a reason some values are missing</li>
<li>When you have <strong>domain knowledge</strong> suggesting missingness is meaningful</li>
<li>When <strong>exploratory analysis</strong> shows that rows with missing values have different outcomes than rows without missing values</li>
<li>As a <strong>defensive strategy</strong>—even if you’re not sure, adding the indicator is low cost and gives your model more information to work with</li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Best practice
</div>
</div>
<div class="callout-body-container callout-body">
<p>Start by creating missingness indicators for a few key features where you suspect non-random missingness. Check whether these indicators are predictive by examining their feature importance scores after training. If they’re not useful, you can drop them later. But don’t systematically add indicators for every single feature—that clutters your feature space unnecessarily.</p>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Knowledge Check: Handling Missing Data
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Question:</strong> You’re analyzing a customer dataset with 10,000 rows to predict purchase likelihood. You discover missing values in several features:</p>
<ul>
<li><strong>Income</strong>: 8% missing (800 rows)</li>
<li><strong>Email Address</strong>: 45% missing (4,500 rows)</li>
<li><strong>Age</strong>: 2% missing (200 rows)</li>
<li><strong>Product Preference</strong>: 12% missing (1,200 rows)</li>
</ul>
<p>Your exploratory analysis reveals that customers with missing income values actually have a <strong>higher average purchase rate</strong> (35%) compared to customers who provided income (22%).</p>
<p>For each feature, decide whether to drop or impute, choose an imputation strategy if applicable, and explain your reasoning:</p>
<details>
<summary>
Click to reveal answer
</summary>
<p><strong>Income (8% missing):</strong> - <strong>Strategy:</strong> Impute with median + add missingness indicator - <strong>Reasoning:</strong> 8% is substantial enough that dropping would lose significant data. More importantly, the exploratory analysis revealed that missing income correlates with higher purchase rates—this is NOT missing at random! The missingness itself is informative (likely high earners declining to share). Use median imputation to fill the values so your model doesn’t break, but CREATE a binary <code>Income_Was_Missing</code> feature to capture this important signal.</p>
<p><strong>Email Address (45% missing):</strong> - <strong>Strategy:</strong> Drop the feature or impute with constant value “missing@unknown.com” depending on use case - <strong>Reasoning:</strong> 45% missing is too much for reliable imputation. If email address is just for customer contact (not prediction), drop it from the model. If you believe having/not having an email is predictive behavior, you could dummy encode it or create a binary <code>Has_Email</code> feature (1 if provided, 0 if missing). Don’t try to “fill in” fake email addresses.</p>
<p><strong>Age (2% missing):</strong> - <strong>Strategy:</strong> Drop rows with missing age OR impute with median - <strong>Reasoning:</strong> Only 2% missing—small enough that dropping these rows won’t significantly reduce your dataset size. This is the easiest approach. Alternatively, median imputation is fine here if you want to preserve every row. No need for missingness indicator since the percentage is so small and unlikely to be systematically informative.</p>
<p><strong>Product Preference (12% missing):</strong> - <strong>Strategy:</strong> Impute with mode (most common category) OR treat “Missing” as its own category - <strong>Reasoning:</strong> This is categorical data, so median/mean don’t apply. With 12% missing, you don’t want to lose that much data. Mode imputation (most frequent product preference) is one option. However, “not providing a preference” might itself be a meaningful signal (indecisive customers?), so you could also treat “Missing” as its own category in your one-hot encoding.</p>
</details>
</div>
</div>
</section>
</section>
</section>
<section id="feature-engineering-with-scikit-learn" class="level2" data-number="30.3">
<h2 data-number="30.3" class="anchored" data-anchor-id="feature-engineering-with-scikit-learn"><span class="header-section-number">30.3</span> Feature Engineering with Scikit-Learn</h2>
<p>So far, we’ve learned individual feature engineering techniques—encoding, scaling, creating features, and handling missing data. But in practice, you need to apply multiple transformations in sequence, and you need to do so in a way that’s <strong>reproducible</strong> and prevents <strong>data leakage</strong>. Scikit-learn provides a systematic framework for chaining these transformations together while ensuring your workflow follows best practices, centering on two key concepts: <strong>transformers</strong> and <strong>pipelines</strong>.</p>
<section id="using-transformers" class="level3">
<h3 class="anchored" data-anchor-id="using-transformers">Using Transformers</h3>
<p>A <strong>transformer</strong> in scikit-learn is any object that can learn parameters from data (using <code>.fit()</code>) and apply transformations (using <code>.transform()</code>). This two-step process is crucial: the transformer learns statistics from your training data (like the mean and standard deviation for scaling), then applies those same learned statistics when transforming both training and test data. This ensures consistency across your datasets and, critically, prevents information from your test set from leaking into your training process:</p>
<div id="8518793e" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'feature1'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>],</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'feature2'</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="dv">70</span>]</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into training and test sets</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>train_data, test_data <span class="op">=</span> train_test_split(data, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and fit scaler on TRAINING data only</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>scaler.fit(train_data)  <span class="co"># Learns mean and std from training data</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform both training and test data using training statistics</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>train_scaled <span class="op">=</span> scaler.transform(train_data)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>test_scaled <span class="op">=</span> scaler.transform(test_data)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training data scaled (using training mean/std):"</span>)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_scaled)</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Test data scaled (using training mean/std):"</span>)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_scaled)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training data scaled (using training mean/std):
[[-1.18321596 -1.18321596]
 [ 0.16903085  0.16903085]
 [-0.50709255 -0.50709255]
 [ 1.52127766  1.52127766]]

Test data scaled (using training mean/std):
[[-2.53546276 -2.53546276]
 [-1.85933936 -1.85933936]
 [ 0.84515425  0.84515425]]</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Preventing Data Leakage
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Critical rule</strong>: Always fit transformers on training data only, then apply them to both training and test data. Never fit on test data!</p>
<p><strong>Why?</strong> If you fit on test data, information from the test set “leaks” into your model training process. This gives you unrealistically optimistic performance estimates that won’t hold up when you deploy your model on truly new data.</p>
</div>
</div>
</section>
<section id="building-pipelines-for-reproducible-workflows" class="level3">
<h3 class="anchored" data-anchor-id="building-pipelines-for-reproducible-workflows">Building Pipelines for Reproducible Workflows</h3>
<p>While transformers handle individual operations, real-world machine learning workflows require multiple sequential steps—perhaps imputation, then scaling, then modeling. <strong>Pipelines</strong> solve this by chaining multiple transformers and a final estimator (model) into a single object that you can fit and predict with in one step. This not only makes your code cleaner and more readable, but also ensures that all transformations are applied in the correct order and prevents common mistakes like forgetting to scale your test data:</p>
<div id="e6be7074" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a pipeline</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'scaler'</span>, StandardScaler()),</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'model'</span>, LinearRegression())</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data (using first 100 rows as an example)</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> pd.DataFrame({</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'GrLivArea'</span>: [<span class="dv">1200</span>, <span class="dv">1500</span>, <span class="dv">1800</span>, <span class="dv">2100</span>],</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'YearBuilt'</span>: [<span class="dv">1990</span>, <span class="dv">2000</span>, <span class="dv">1985</span>, <span class="dv">2015</span>]</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> pd.Series([<span class="dv">200000</span>, <span class="dv">250000</span>, <span class="dv">240000</span>, <span class="dv">350000</span>])</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the entire pipeline</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>pipeline.fit(X, y)</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions (scaling happens automatically!)</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> pipeline.predict(X)</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predictions:"</span>, predictions)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Predictions: [198043.47826087 252826.08695652 240217.39130435 348913.04347826]</code></pre>
</div>
</div>
<p><strong>Benefits of pipelines:</strong></p>
<ul>
<li><strong>Prevents data leakage</strong>: Transformations are learned from training data only</li>
<li><strong>Less code</strong>: One <code>.fit()</code> call instead of multiple steps</li>
<li><strong>Easier deployment</strong>: The entire workflow is contained in one object</li>
<li><strong>Prevents mistakes</strong>: You can’t forget to scale test data</li>
</ul>
</section>
<section id="practical-example-end-to-end-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="practical-example-end-to-end-pipeline">Practical Example: End-to-End Pipeline</h3>
<p>The previous example showed a simple pipeline with one transformer and one model, but real datasets often have a mix of numerical and categorical features that require different preprocessing steps. Scikit-learn’s <code>ColumnTransformer</code> allows you to apply different transformations to different columns, and when combined with <code>Pipeline</code>, you can build production-ready workflows that handle complex feature engineering automatically. Let’s build a complete pipeline for the Ames housing data that handles both numerical features (which need imputation and scaling) and categorical features (which need imputation and encoding):</p>
<div id="2a0fc1e3" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>ames <span class="op">=</span> pd.read_csv(<span class="st">'../data/ames_clean.csv'</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define feature types</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'GrLivArea'</span>, <span class="st">'YearBuilt'</span>, <span class="st">'TotalBsmtSF'</span>]</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>categorical_features <span class="op">=</span> [<span class="st">'Neighborhood'</span>, <span class="st">'BldgType'</span>]</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create preprocessing for numeric features</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>numeric_transformer <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'imputer'</span>, SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>)),</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'scaler'</span>, StandardScaler())</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Create preprocessing for categorical features</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>categorical_transformer <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'imputer'</span>, SimpleImputer(strategy<span class="op">=</span><span class="st">'constant'</span>, fill_value<span class="op">=</span><span class="st">'missing'</span>)),</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'onehot'</span>, OneHotEncoder(handle_unknown<span class="op">=</span><span class="st">'ignore'</span>, sparse_output<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine preprocessing steps</span></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> ColumnTransformer(</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>    transformers<span class="op">=</span>[</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'num'</span>, numeric_transformer, numeric_features),</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'cat'</span>, categorical_transformer, categorical_features)</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Create full pipeline with model</span></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>full_pipeline <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, preprocessor),</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'model'</span>, Ridge(alpha<span class="op">=</span><span class="fl">1.0</span>))</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data</span></span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> ames[numeric_features <span class="op">+</span> categorical_features]</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> ames[<span class="st">'SalePrice'</span>]</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data</span></span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the entire pipeline</span></span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>full_pipeline.fit(X_train, y_train)</span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate</span></span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>train_score <span class="op">=</span> full_pipeline.score(X_train, y_train)</span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>test_score <span class="op">=</span> full_pipeline.score(X_test, y_test)</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training R² Score: </span><span class="sc">{</span>train_score<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test R² Score: </span><span class="sc">{</span>test_score<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training R² Score: 0.785
Test R² Score: 0.805</code></pre>
</div>
</div>
<p>This pipeline automatically:</p>
<ol type="1">
<li>Imputes missing values in numeric features (using median)</li>
<li>Scales numeric features (using StandardScaler)</li>
<li>Imputes missing values in categorical features (with “missing”)</li>
<li>One-hot encodes categorical features</li>
<li>Trains a Ridge regression model</li>
</ol>
<p>All in one reusable, production-ready object!</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Try It Yourself
</div>
</div>
<div class="callout-body-container callout-body">
<p>Extend the pipeline above by:</p>
<ol type="1">
<li>Adding polynomial features for numeric variables (use <code>PolynomialFeatures</code>)</li>
<li>Creating a custom feature for house age (current year - YearBuilt)</li>
<li>Trying different models in the final step (LinearRegression, DecisionTreeRegressor, etc.)</li>
<li>Experimenting with different imputation strategies</li>
</ol>
<p>Compare the performance of your enhanced pipeline to the basic version. Which changes made the biggest difference?</p>
</div>
</div>
</section>
</section>
<section id="beyond-the-basics" class="level2" data-number="30.4">
<h2 data-number="30.4" class="anchored" data-anchor-id="beyond-the-basics"><span class="header-section-number">30.4</span> Beyond the Basics</h2>
<p>Feature engineering is a vast field with many additional techniques beyond what we’ve covered in this chapter. The techniques you’ve learned—encoding, scaling, feature creation, handling missing data, and pipelines—form a solid foundation for most machine learning projects. However, as you go deeper into machine learning and work on more complex problems, you’ll benefit from continuing to learn new and alternative feature engineering approaches. Each new technique you master expands your toolkit and gives you more ways to extract signal from data.</p>
<p>Here are some more advanced techniques you’ll encounter as you continue your machine learning journey. No need to memorize these, rather, just click on a few to get an idea of what they do.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-21-contents" aria-controls="callout-21" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span><strong>Target Encoding (Mean Encoding)</strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-21" class="callout-21-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Summary:</strong> Replace categorical values with the mean of the target variable for that category. For example, replace “Neighborhood_A” with the average house price in that neighborhood.</p>
<p><strong>Business Application:</strong> E-commerce companies use this to encode customer segments, replacing segment IDs with the average purchase amount per segment, helping predict individual customer value more accurately than one-hot encoding when you have hundreds of segments.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span><strong>Binning/Discretization</strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Summary:</strong> Convert continuous numerical features into categorical bins or groups (e.g., converting age into “young,” “middle-aged,” “senior” or income into quartiles).</p>
<p><strong>Business Application:</strong> Credit card companies bin transaction amounts into risk categories (small/medium/large) because fraud patterns often differ by transaction size brackets rather than following a smooth continuous relationship.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-23-contents" aria-controls="callout-23" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span><strong>Time-Series Features</strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-23" class="callout-23-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Summary:</strong> Create lag features (values from previous time periods), rolling statistics (moving averages, rolling standard deviations), and time-based features (day of week, seasonality indicators).</p>
<p><strong>Business Application:</strong> Retailers use lag features and rolling averages of past sales to predict inventory needs, incorporating patterns like “sales this week correlate with sales 7 days ago” and “moving average indicates trend.”</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-24-contents" aria-controls="callout-24" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span><strong>Text Feature Extraction</strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-24" class="callout-24-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Summary:</strong> Transform text into numerical features using techniques like TF-IDF (term frequency-inverse document frequency), word embeddings, or counting specific keywords.</p>
<p><strong>Business Application:</strong> Customer service teams extract features from support tickets (sentiment scores, urgency keywords, product mentions) to automatically route tickets to the right department and prioritize urgent issues.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-25-contents" aria-controls="callout-25" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span><strong>Feature Crosses</strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-25" class="callout-25-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Summary:</strong> Create new features by multiplying or combining multiple features together, similar to interaction terms but often used in larger-scale combinations (e.g., crossing city × day_of_week × hour to predict traffic).</p>
<p><strong>Business Application:</strong> Ride-sharing companies cross location, time of day, and weather conditions to predict surge pricing needs—each combination tells a different story about demand.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-26-contents" aria-controls="callout-26" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span><strong>Dimensionality Reduction (PCA, t-SNE, UMAP)</strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-26" class="callout-26-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Summary:</strong> Compress many features into fewer dimensions while preserving as much information as possible. PCA finds linear combinations; t-SNE and UMAP capture non-linear patterns.</p>
<p><strong>Business Application:</strong> Financial institutions use PCA to reduce hundreds of economic indicators down to a handful of principal components that capture the major drivers of market behavior, simplifying risk models.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-27-contents" aria-controls="callout-27" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span><strong>Feature Selection Methods</strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-27" class="callout-27-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Summary:</strong> Automatically identify which features are most important and discard the rest using techniques like Lasso regression (which zeros out unimportant features), mutual information, or recursive feature elimination.</p>
<p><strong>Business Application:</strong> Healthcare ML models use feature selection to identify which of hundreds of patient measurements (vitals, lab tests, symptoms) are most predictive of disease, improving model interpretability for doctors.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-28-contents" aria-controls="callout-28" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span><strong>Automated Feature Engineering Tools</strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-28" class="callout-28-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Summary:</strong> Tools like Featuretools, tsfresh, and AutoFeat automatically generate many candidate features from your raw data, then select the most promising ones.</p>
<p><strong>Business Application:</strong> Marketing teams use automated feature engineering to explore thousands of potential features from customer behavior data (website clicks, email opens, purchase history) without manually creating each one.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Where to learn more?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Books:</strong></p>
<ul>
<li><a href="https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/">Feature Engineering for Machine Learning</a> by Alice Zheng and Amanda Casari</li>
<li><a href="http://www.feat.engineering/">Feature Engineering and Selection</a> by Max Kuhn and Kjell Johnson</li>
<li><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning</a> by Aurélien Géron</li>
</ul>
<p><strong>Online Courses:</strong></p>
<ul>
<li><a href="https://www.kaggle.com/learn/feature-engineering">Kaggle’s Feature Engineering Course</a></li>
<li><a href="https://course.fast.ai/">Fast.ai Practical Deep Learning</a></li>
<li><a href="https://www.coursera.org/learn/python-machine-learning">Coursera: Applied Machine Learning in Python</a></li>
</ul>
<p><strong>Practice:</strong></p>
<ul>
<li><a href="https://www.kaggle.com/competitions">Kaggle Competitions</a></li>
<li><a href="https://www.kaggle.com/code">Kaggle Notebooks</a></li>
</ul>
</div>
</div>
</section>
<section id="summary" class="level2" data-number="30.5">
<h2 data-number="30.5" class="anchored" data-anchor-id="summary"><span class="header-section-number">30.5</span> Summary</h2>
<p>Feature engineering transforms raw data into representations that help machine learning models learn better. It’s where data science becomes as much art as science, blending technical skills with domain knowledge and creativity. The techniques you’ve learned in this chapter—encoding categorical variables, scaling numerical features, creating new features through transformations and domain knowledge, and handling missing data strategically—form the foundation of effective machine learning practice.</p>
<p>Two critical principles should guide your feature engineering efforts. First, <strong>feature engineering often matters more than model selection</strong>—a simple model with well-engineered features typically outperforms a sophisticated model with poor features. Second, always use <strong>scikit-learn pipelines to prevent data leakage</strong> by ensuring transformations are fit on training data only, then applied consistently to both training and test data. Pipelines make your workflow reproducible and deployment-ready while protecting against common mistakes.</p>
<p>Finally, remember that feature engineering is iterative and context-dependent. The “best” approach depends on your specific data, model, and goals. Use dummy encoding for nominal categories with linear models, but label encoding may be fine for tree-based models. Scale features for distance-based algorithms, but not for decision trees. Create features from domain knowledge when possible, as these often prove most powerful. Test different approaches, measure their impact on model performance, and let the results guide your decisions. As you gain experience, you’ll develop intuition for which techniques work best in different situations.</p>
</section>
<section id="end-of-chapter-exercises" class="level2" data-number="30.6">
<h2 data-number="30.6" class="anchored" data-anchor-id="end-of-chapter-exercises"><span class="header-section-number">30.6</span> End of Chapter Exercises</h2>
<p>Now it’s time to apply what you’ve learned! These exercises will give you hands-on experience with feature engineering using the Ames housing dataset.</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Before You Start
</div>
</div>
<div class="callout-body-container callout-body">
<p>Make sure you have:</p>
<ul>
<li>The <a href="https://github.com/bradleyboehmke/uc-bana-4080/blob/main/data/ames_clean.csv"><code>ames_clean.csv</code></a> dataset loaded into a pandas DataFrame</li>
<li>Imported necessary libraries: <code>pandas</code>, <code>numpy</code>, <code>sklearn.preprocessing</code>, <code>sklearn.impute</code>, <code>sklearn.pipeline</code></li>
<li>Defined your features (X) and target variable (y = SalePrice)</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-31-contents" aria-controls="callout-31" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 1: Encoding Categorical Variables
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-31" class="callout-31-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Objective:</strong> Practice different encoding strategies on the Ames dataset.</p>
<p><strong>Tasks:</strong></p>
<ol type="1">
<li><p>Identify all categorical variables in the Ames dataset (use <code>.select_dtypes(include='object')</code>).</p></li>
<li><p>For the <code>MSZoning</code> variable (general zoning classification):</p>
<ul>
<li>Apply one-hot encoding using <code>pd.get_dummies()</code></li>
<li>How many new columns were created?</li>
<li>Use the <code>drop_first=True</code> parameter. Why is this important for linear regression?</li>
</ul></li>
<li><p>For the <code>OverallQual</code> variable (overall material and finish quality, rated 1-10):</p>
<ul>
<li>Although this is stored as an integer, it’s actually an ordinal variable. Why doesn’t it need special encoding?</li>
<li>Create a scatter plot showing the relationship between <code>OverallQual</code> and <code>SalePrice</code>. Is the relationship linear or non-linear?</li>
</ul></li>
<li><p><strong>Challenge:</strong> The Ames dataset has <code>KitchenQual</code> (kitchen quality: Ex, Gd, TA, Fa, Po). Create a custom ordinal encoding mapping for this variable and apply it. Verify your encoding makes sense by comparing mean sale prices across quality levels.</p></li>
</ol>
<p><strong>Hints</strong>:</p>
<ul>
<li>For task 2, remember that one-hot encoding creates k columns for k categories (or k-1 if you use <code>drop_first=True</code>)</li>
<li>For task 4, use a dictionary like <code>quality_map = {'Po': 1, 'Fa': 2, ...}</code> and apply it with <code>.map()</code></li>
<li>Check your results with <code>groupby()</code> and <code>.mean()</code> to ensure higher quality values correspond to higher prices</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-32-contents" aria-controls="callout-32" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 2: Feature Scaling
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-32" class="callout-32-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Objective:</strong> Understand the impact of scaling on different algorithms.</p>
<p><strong>Tasks:</strong></p>
<ol type="1">
<li>Select three numerical features from Ames: <code>GrLivArea</code>, <code>YearBuilt</code>, and <code>GarageArea</code>.
<ul>
<li>Calculate and compare their ranges (max - min) and standard deviations.</li>
<li>Explain why these features are on very different scales.</li>
</ul></li>
<li>Apply StandardScaler to these three features:
<ul>
<li>Split your data into train (80%) and test (20%) sets first.</li>
<li>Fit the scaler on the training data only.</li>
<li>Transform both training and test data.</li>
<li>Verify that the scaled training data has mean ≈ 0 and std ≈ 1.</li>
</ul></li>
<li>Apply MinMaxScaler to the same features:
<ul>
<li>Follow the same train/test split process.</li>
<li>Verify that the scaled training data ranges from 0 to 1.</li>
<li>Compare: Which scaler would you prefer if you discovered extreme outliers in <code>GrLivArea</code>? Why?</li>
</ul></li>
<li><strong>Challenge:</strong> Build two linear regression models predicting <code>SalePrice</code>:
<ul>
<li>Model A: Using the original unscaled features.</li>
<li>Model B: Using StandardScaler on the features.</li>
<li>Compare their R² scores. Does scaling improve performance for linear regression? Why or why not?</li>
</ul></li>
</ol>
<p><strong>Hints</strong>:</p>
<ul>
<li>Use <code>train_test_split</code> from <code>sklearn.model_selection</code></li>
<li>Always fit scalers on training data only: <code>scaler.fit(X_train)</code></li>
<li>Check scaled data properties with <code>.mean()</code> and <code>.std()</code> for StandardScaler</li>
<li>Linear regression without regularization typically doesn’t require scaling, but it doesn’t hurt</li>
<li>The real benefit of scaling shows up with regularized models (Ridge, Lasso) or distance-based algorithms (k-NN)</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-33-contents" aria-controls="callout-33" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 3: Creating New Features
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-33" class="callout-33-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Objective:</strong> Engineer domain-specific features for house price prediction.</p>
<p><strong>Tasks:</strong></p>
<ol type="1">
<li>Create the following new features from existing Ames variables:
<ul>
<li><code>TotalBathrooms</code> = <code>FullBath</code> + (0.5 × <code>HalfBath</code>) + <code>BsmtFullBath</code> + (0.5 × <code>BsmtHalfBath</code>)</li>
<li><code>HouseAge</code> = Current year - <code>YearBuilt</code></li>
<li><code>YearsSinceRemodel</code> = Current year - <code>YearRemodAdd</code></li>
<li><code>TotalSF</code> = <code>TotalBsmtSF</code> + <code>1stFlrSF</code> + <code>2ndFlrSF</code></li>
<li><code>PorchArea</code> = <code>OpenPorchSF</code> + <code>EnclosedPorch</code> + <code>3SsnPorch</code> + <code>ScreenPorch</code></li>
</ul></li>
<li>Create polynomial features for <code>GrLivArea</code>:
<ul>
<li>Use <code>PolynomialFeatures(degree=2)</code> from sklearn.</li>
<li>How many features are created? What do they represent?</li>
<li>Train a linear regression model with the polynomial features and compare its performance to a model with just the original <code>GrLivArea</code>.</li>
</ul></li>
<li>Create an interaction feature:
<ul>
<li>Multiply <code>GrLivArea</code> × <code>OverallQual</code> to create <code>Size_Quality_Interaction</code>.</li>
<li>Calculate the correlation between this new feature and <code>SalePrice</code>.</li>
<li>Does this interaction feature have stronger correlation with price than the individual features alone?</li>
</ul></li>
<li><strong>Challenge:</strong> Create a “desirability score” feature that combines multiple quality ratings:
<ul>
<li>Combine <code>OverallQual</code>, <code>KitchenQual</code> (encoded), and <code>ExterQual</code> (encoded) into a single score.</li>
<li>You could take their average, weighted average, or create your own formula.</li>
<li>Justify your approach based on domain knowledge about what makes a house valuable.</li>
</ul></li>
</ol>
<p><strong>Hints:</strong></p>
<ul>
<li>Use <code>pd.Timestamp.now().year</code> to get the current year dynamically</li>
<li>Watch for missing values in bathroom-related columns—handle them before creating <code>TotalBathrooms</code></li>
<li>For polynomial features, remember to fit on training data and transform both train and test</li>
<li>Use <code>.corr()</code> to calculate correlation: <code>data[['feature', 'SalePrice']].corr()</code></li>
<li>For the challenge, think about whether all quality metrics are equally important</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-34-contents" aria-controls="callout-34" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 4: Handling Missing Data
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-34" class="callout-34-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Objective:</strong> Develop a strategy for handling missing values in the Ames dataset.</p>
<p><strong>Tasks:</strong></p>
<ol type="1">
<li>Identify missing values:
<ul>
<li>Use <code>.isnull().sum()</code> to see how many missing values each feature has.</li>
<li>Calculate the percentage of missing values for each feature.</li>
<li>Identify features with more than 20% missing values.</li>
</ul></li>
<li>For features with substantial missing values (like <code>PoolQC</code>, <code>MiscFeature</code>, <code>Alley</code>, <code>Fence</code>):
<ul>
<li>Research what these features represent in the Ames data documentation.</li>
<li>Determine whether “missing” actually means “absent” (e.g., “no pool”, “no fence”).</li>
<li>Decide whether to drop these features or encode “missing” as its own meaningful category.</li>
</ul></li>
<li>For <code>LotFrontage</code> (about 17% missing):
<ul>
<li>Apply median imputation using <code>SimpleImputer</code>.</li>
<li>Create a missingness indicator variable <code>LotFrontage_Was_Missing</code>.</li>
<li>Check if houses with missing lot frontage have different sale prices than houses with known lot frontage.</li>
</ul></li>
<li><strong>Challenge:</strong> Build a complete preprocessing pipeline for missing data:
<ul>
<li>Identify all numerical features with missing values and impute with median.</li>
<li>Identify all categorical features with missing values and impute with mode or “missing” as appropriate.</li>
<li>Create missingness indicators for features where you suspect non-random missingness.</li>
<li>Compare model performance with and without missingness indicators.</li>
</ul></li>
</ol>
<p><strong>Hints:</strong></p>
<ul>
<li>Calculate percentage missing: <code>(df.isnull().sum() / len(df)) * 100</code></li>
<li>The Ames documentation suggests many “missing” values are actually “feature not present” (NA = not applicable)</li>
<li>Use <code>SimpleImputer(strategy='median')</code> for numerical features</li>
<li>Use <code>SimpleImputer(strategy='most_frequent')</code> for categorical features</li>
<li>Create indicators before imputation: <code>df['Feature_Was_Missing'] = df['Feature'].isna().astype(int)</code></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-35-contents" aria-controls="callout-35" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">None</span>Exercise 5: Building an End-to-End Pipeline
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-35" class="callout-35-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Objective:</strong> Combine everything into a production-ready pipeline.</p>
<p><strong>Tasks:</strong></p>
<ol type="1">
<li>Create separate pipelines for numerical and categorical features:
<ul>
<li><strong>Numerical pipeline:</strong> Imputation (median) → StandardScaler</li>
<li><strong>Categorical pipeline:</strong> Imputation (constant, fill_value=‘missing’) → OneHotEncoder</li>
</ul></li>
<li>Use <code>ColumnTransformer</code> to apply different pipelines to different column types:
<ul>
<li>Define lists of numerical and categorical features.</li>
<li>Create a preprocessor that applies the appropriate pipeline to each feature type.</li>
</ul></li>
<li>Create a complete pipeline that includes preprocessing and a model:
<ul>
<li>Use the preprocessor from task 2.</li>
<li>Add a Ridge regression model as the final step.</li>
<li>Fit the pipeline on training data and evaluate on test data.</li>
</ul></li>
<li><strong>Challenge:</strong> Extend your pipeline to include feature engineering:
<ul>
<li>Create a custom transformer using <code>FunctionTransformer</code> or write your own transformer class that adds engineered features (like <code>HouseAge</code>, <code>TotalBathrooms</code>, etc.).</li>
<li>Insert this transformer at the beginning of your pipeline, before the preprocessing steps.</li>
<li>Compare the performance of your enhanced pipeline to the basic pipeline from task 3.</li>
</ul></li>
</ol>
<p><strong>Hints</strong>:</p>
<ul>
<li><p>Structure your pipeline like this:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>Pipeline([</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocessor'</span>, ColumnTransformer(...)),</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'model'</span>, Ridge())</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>For the challenge, you can use <code>FunctionTransformer</code> to wrap a function that adds new features:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> FunctionTransformer</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_features(X):</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> X.copy()</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    X[<span class="st">'HouseAge'</span>] <span class="op">=</span> pd.Timestamp.now().year <span class="op">-</span> X[<span class="st">'YearBuilt'</span>]</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add more features...</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>feature_adder <span class="op">=</span> FunctionTransformer(add_features)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Make sure your custom features are added before the ColumnTransformer so they can be processed appropriately</p></li>
</ul>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./29-hyperparameter-tuning.html" class="pagination-link" aria-label="Hyperparameter Tuning: Finding Optimal Model Configurations">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning: Finding Optimal Model Configurations</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./99-anaconda-install.html" class="pagination-link" aria-label="Anaconda Installation">
        <span class="nav-page-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Anaconda Installation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/edit/main/30-feature-engineering.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bradleyboehmke/uc-bana-4080/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>