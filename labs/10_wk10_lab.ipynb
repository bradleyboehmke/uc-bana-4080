{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Week 10 Lab: Logistic Regression and Classification Evaluation\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/bradleyboehmke/uc-bana-4080/blob/main/labs/10_wk10_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "Welcome to Week 10! This lab serves as both your Thursday class session and your homework for the week. You'll apply logistic regression and classification evaluation techniques to two important business scenarios: credit risk assessment and medical diagnosis support.\n",
    "\n",
    "In the business world, classification problems are everywhere‚Äîfrom determining loan approvals to medical screenings. Today you'll master the complete workflow from data preparation through model evaluation, learning to choose appropriate metrics that align with business objectives and costs.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this lab, you will be able to:\n",
    "- Apply the complete logistic regression workflow: data preparation, model fitting, and interpretation\n",
    "- Calculate and interpret baseline ratios for imbalanced classification problems\n",
    "- Evaluate classification models using precision, recall, F1-score, and ROC-AUC metrics\n",
    "- Select appropriate evaluation metrics based on business context and error costs\n",
    "\n",
    "## üìö This Lab Reinforces\n",
    "- **Chapter 23: Introduction to Logistic Regression for Classification**\n",
    "- **Chapter 24: Evaluating Classification Models**\n",
    "- **Tuesday's Lecture: Classification Methods and Model Evaluation**\n",
    "\n",
    "## üïê Estimated Time & Structure\n",
    "**Total Time:** 75 minutes  \n",
    "**Mode:** Individual work (this serves as your homework)\n",
    "\n",
    "- **[0‚Äì10 min]** Review: Default dataset logistic regression workflow\n",
    "- **[10‚Äì35 min]** Application: Breast Cancer Wisconsin dataset analysis\n",
    "- **[35‚Äì70 min]** Independent challenges: Specific homework questions\n",
    "- **[70‚Äì75 min]** Wrap-up and submission preparation\n",
    "\n",
    "## üí° Why This Matters\n",
    "Classification problems drive critical business decisions across industries. Credit companies need to assess default risk, healthcare systems require diagnostic support, and marketing teams must identify likely customers. The ability to build, evaluate, and interpret classification models‚Äîwhile understanding the business implications of different types of errors‚Äîis essential for data-driven decision making. Today's lab prepares you to tackle these real-world challenges with confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We'll work with two datasets: the Default dataset from ISLP (for review) and the Breast Cancer Wisconsin dataset (for our main analysis). Both represent important classification scenarios in business and healthcare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üéØ Ready to dive into classification analysis!\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "from ISLP import load_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üéØ Ready to dive into classification analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Part 1 ‚Äî Review: Default Dataset Logistic Regression (10 minutes)\n",
    "\n",
    "Let's quickly review the complete logistic regression workflow using the Default dataset from Chapters 23-24. This will reinforce the key concepts before we tackle the main dataset.\n",
    "\n",
    "### Quick Workflow Review\n",
    "\n",
    "We'll walk through each step systematically:\n",
    "\n",
    "**üìã Step-by-step process:**\n",
    "1. Load data and compute baseline ratio\n",
    "2. Prepare features with dummy encoding\n",
    "3. Split data into training and test sets\n",
    "4. Fit logistic regression model and interpret coefficients\n",
    "5. Make predictions and evaluate using multiple metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Dataset Overview:\n",
      "Shape: (10000, 4)\n",
      "\n",
      "Columns: ['default', 'student', 'balance', 'income']\n",
      "\n",
      "First few rows:\n",
      "  default student      balance        income\n",
      "0      No      No   729.526495  44361.625074\n",
      "1      No     Yes   817.180407  12106.134700\n",
      "2      No      No  1073.549164  31767.138947\n",
      "3      No      No   529.250605  35704.493935\n",
      "4      No      No   785.655883  38463.495879\n",
      "\n",
      "üìä Baseline Analysis:\n",
      "Default rate: 3.3%\n",
      "Non-default rate: 96.7%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Default dataset and examine baseline\n",
    "Default = load_data('Default')\n",
    "\n",
    "print(\"Default Dataset Overview:\")\n",
    "print(f\"Shape: {Default.shape}\")\n",
    "print(f\"\\nColumns: {Default.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(Default.head())\n",
    "\n",
    "# Compute baseline ratio\n",
    "baseline_default_rate = (Default['default'] == 'Yes').mean()\n",
    "print(f\"\\nüìä Baseline Analysis:\")\n",
    "print(f\"Default rate: {baseline_default_rate:.1%}\")\n",
    "print(f\"Non-default rate: {1-baseline_default_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation Complete:\n",
      "Features shape: (10000, 3)\n",
      "Target shape: (10000,)\n",
      "\n",
      "Feature columns: ['balance', 'income', 'student_Yes']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Prepare data with dummy encoding\n",
    "# Convert categorical variables to numeric\n",
    "Default_encoded = pd.get_dummies(Default, columns=['student'], drop_first=True)\n",
    "Default_encoded['default_binary'] = (Default_encoded['default'] == 'Yes').astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = Default_encoded[['balance', 'income', 'student_Yes']]\n",
    "y = Default_encoded['default_binary']\n",
    "\n",
    "print(\"Data Preparation Complete:\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Split Results:\n",
      "Training set: 7,000 observations\n",
      "Test set: 3,000 observations\n",
      "\n",
      "Training set default rate: 3.4%\n",
      "Test set default rate: 3.1%\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Split data (70-30 split as specified for homework questions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"üìä Data Split Results:\")\n",
    "print(f\"Training set: {len(X_train):,} observations\")\n",
    "print(f\"Test set: {len(X_test):,} observations\")\n",
    "print(f\"\\nTraining set default rate: {y_train.mean():.1%}\")\n",
    "print(f\"Test set default rate: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Model Coefficients:\n",
      "Intercept: -11.108164\n",
      "balance: 0.005789\n",
      "income: 0.000006\n",
      "student_Yes: -0.467459\n",
      "\n",
      "üí° Interpretation:\n",
      "‚Ä¢ Balance: Positive coefficient means higher balance increases default risk\n",
      "‚Ä¢ Income: Very small coefficient suggests minimal impact after accounting for balance\n",
      "‚Ä¢ Student: Negative coefficient means students have lower default risk (holding other factors constant)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Fit logistic regression model\n",
    "model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extract and interpret coefficients\n",
    "print(\"üîç Model Coefficients:\")\n",
    "print(f\"Intercept: {model.intercept_[0]:.6f}\")\n",
    "for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "    print(f\"{feature}: {coef:.6f}\")\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"‚Ä¢ Balance: Positive coefficient means higher balance increases default risk\")\n",
    "print(f\"‚Ä¢ Income: Very small coefficient suggests minimal impact after accounting for balance\")\n",
    "print(f\"‚Ä¢ Student: Negative coefficient means students have lower default risk (holding other factors constant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Make predictions and evaluate comprehensively\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate all key metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"üìà Model Performance Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy:.1%}\")\n",
    "print(f\"Precision: {precision:.1%}\")\n",
    "print(f\"Recall:    {recall:.1%}\")\n",
    "print(f\"F1-Score:  {f1:.1%}\")\n",
    "print(f\"ROC-AUC:   {auc:.3f}\")\n",
    "\n",
    "print(f\"\\nüí° What These Metrics Mean for Credit Risk:\")\n",
    "print(f\"‚Ä¢ Accuracy (97.3%): Overall correctness - 97.3% of all predictions are correct\")\n",
    "print(f\"‚Ä¢ Precision (69.4%): Of customers flagged as 'will default', 69.4% actually do\")\n",
    "print(f\"  ‚Üí Low false alarms but still 30.6% false positives\")\n",
    "print(f\"‚Ä¢ Recall (26.6%): Only catches 26.6% of actual defaulters\")\n",
    "print(f\"  ‚Üí Misses 73.4% of customers who will default - major business risk!\")\n",
    "print(f\"‚Ä¢ F1-Score (38.5%): Balanced measure showing poor overall classification performance\")\n",
    "print(f\"‚Ä¢ ROC-AUC (0.947): Excellent ability to rank customers by default risk\")\n",
    "print(f\"  ‚Üí Model is very good at scoring, but default threshold may need adjustment\")\n",
    "\n",
    "# Show confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nüîç Confusion Matrix:\")\n",
    "print(f\"[[{cm[0,0]:4d}, {cm[0,1]:3d}]]\")\n",
    "print(f\"[[{cm[1,0]:4d}, {cm[1,1]:3d}]]\")\n",
    "print(f\"\\nThis shows: TN={cm[0,0]}, FP={cm[0,1]}, FN={cm[1,0]}, TP={cm[1,1]}\")\n",
    "print(f\"Business Impact: {cm[1,0]} defaulters missed (lost revenue), {cm[0,1]} customers wrongly rejected (lost business)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Part 2 ‚Äî Main Analysis: Breast Cancer Wisconsin Dataset (25 minutes)\n",
    "\n",
    "Now let's apply these skills to a new healthcare dataset. The **Breast Cancer Wisconsin (Diagnostic) dataset** contains features computed from digitized images of fine needle aspirate (FNA) of breast masses. Our goal is to predict whether a tumor is **malignant** (cancerous) or **benign** (non-cancerous).\n",
    "\n",
    "### üî¨ About This Dataset\n",
    "\n",
    "**Data Source**: Originally created by Dr. William H. Wolberg, W. Nick Street, and Olvi L. Mangasarian at the University of Wisconsin-Madison. This dataset is widely used in machine learning research and medical informatics.\n",
    "\n",
    "**Data Collection Process**: For each breast mass sample, a fine needle aspirate (FNA) was performed, then digitized images were analyzed to compute quantitative features describing the cell nuclei characteristics.\n",
    "\n",
    "### üìä Feature Categories\n",
    "\n",
    "The dataset contains **30 quantitative features** organized into three groups for each characteristic:\n",
    "\n",
    "1. **Mean values** (`_mean`): Average across all cells in the sample\n",
    "2. **Standard error** (`_se`): Standard error of the measurements  \n",
    "3. **Worst values** (`_worst`): Mean of the three largest (most severe) values\n",
    "\n",
    "**The 10 core characteristics measured are:**\n",
    "\n",
    "- **`radius`**: Distance from center to perimeter points\n",
    "- **`texture`**: Standard deviation of gray-scale values  \n",
    "- **`perimeter`**: Total boundary length of the cell nucleus\n",
    "- **`area`**: Total area enclosed by the cell nucleus boundary\n",
    "- **`smoothness`**: Local variation in radius lengths\n",
    "- **`compactness`**: (perimeter¬≤ / area) - 1.0, measuring shape regularity\n",
    "- **`concavity`**: Severity of concave portions of the boundary\n",
    "- **`concave_points`**: Number of concave portions of the boundary\n",
    "- **`symmetry`**: Bilateral symmetry of the cell nucleus\n",
    "- **`fractal_dimension`**: Fractal complexity using coastline approximation\n",
    "\n",
    "### üéØ Simplified Analysis Focus\n",
    "\n",
    "For this part of the lab, we'll focus on the **5 mean features** to keep our analysis manageable:\n",
    "- `radius_mean`, `texture_mean`, `perimeter_mean`, `area_mean`, `smoothness_mean`\n",
    "\n",
    "These provide a representative sample of size, texture, and shape characteristics that are clinically relevant for distinguishing malignant from benign tumors.\n",
    "\n",
    "**Business Context**: In medical diagnosis, the costs of different errors are dramatically different. Missing a malignant tumor (false negative) can be life-threatening, while incorrectly flagging a benign tumor as malignant (false positive) leads to unnecessary stress and additional testing costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Data Loading and Exploration\n",
    "\n",
    "**Your Task**: Load the breast cancer dataset and perform initial exploratory analysis.\n",
    "\n",
    "**Instructions**:\n",
    "1. Load the dataset from the provided URL\n",
    "2. Examine the dataset structure (shape, columns, first few rows)\n",
    "3. Calculate the baseline ratio of malignant vs benign diagnoses\n",
    "4. Check for any missing values in the dataset\n",
    "\n",
    "**Questions to Answer**:\n",
    "- How many observations and features does the dataset contain?\n",
    "- What percentage of cases are malignant vs benign?\n",
    "- Are there any missing values that need to be handled?\n",
    "\n",
    "Write your code below to answer these questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.1: Your code here\n",
    "\n",
    "# URL for the breast cancer dataset\n",
    "url = \"https://raw.githubusercontent.com/bradleyboehmke/uc-bana-4080/refs/heads/main/data/breast_cancer.csv\"\n",
    "\n",
    "# Task 1: Load the dataset (PROVIDED)\n",
    "cancer_data = pd.read_csv(url)\n",
    "print(\"‚úÖ Breast Cancer Wisconsin dataset loaded successfully!\")\n",
    "\n",
    "# Task 2: Examine dataset structure (shape, columns, first few rows)\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Task 3: Calculate baseline ratio of malignant vs benign diagnoses\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Task 4: Check for missing values\n",
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution will be provided by TA during lab\n",
    "\n",
    "# This cell will contain the solution code that the TA will walk through\n",
    "# Students should attempt the exercise above before seeing the solution\n",
    "\n",
    "print(\"‚úÖ TA will provide solution during lab walkthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Data Preparation and Modeling (Using Mean Features Only)\n",
    "\n",
    "**Your Task**: Prepare the breast cancer data for logistic regression analysis using only the `_mean` features.\n",
    "\n",
    "**Background**: For this exercise, we'll focus on a subset of features to keep the analysis manageable. You'll work with the 10 `_mean` features, which represent the average measurements across all cells in each sample.\n",
    "\n",
    "**Instructions**:\n",
    "1. Create a binary target variable (0=Benign, 1=Malignant) from the diagnosis column\n",
    "2. Select only the features ending with `_mean` for your feature matrix\n",
    "3. Split the data into training and test sets (70-30 split)\n",
    "4. Fit a logistic regression model and examine the coefficients\n",
    "5. Make predictions on the test set\n",
    "\n",
    "**Important**: Use `RANDOM_STATE` variable (defined at the beginning) for consistent results across all students.\n",
    "\n",
    "**Questions to Answer**:\n",
    "- How many `_mean` features are available in the dataset?\n",
    "- What are the training and test set sizes after the split?\n",
    "- Which `_mean` features have positive vs negative coefficients?\n",
    "- What do the coefficient signs suggest about malignancy risk?\n",
    "\n",
    "Write your code below to complete these tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.2: Your code here\n",
    "# Assume the cancer_data DataFrame is available from Exercise 2.1\n",
    "\n",
    "# Task 1: Create binary target variable (0=Benign, 1=Malignant)\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Task 2: Select only the features ending with '_mean' (PROVIDED)\n",
    "mean_features = [col for col in cancer_data.columns if col.endswith('_mean')]\n",
    "X_cancer_mean = cancer_data[mean_features]\n",
    "print(f\"‚úÖ Selected {len(mean_features)} mean features:\")\n",
    "print(f\"Features: {mean_features}\")\n",
    "\n",
    "# Task 3: Split data into training and test sets (70-30 split using RANDOM_STATE)\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Task 4: Fit logistic regression model and examine coefficients\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Task 5: Make predictions on test set  \n",
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution will be provided by TA during lab\n",
    "\n",
    "# This cell will contain the solution code that the TA will walk through\n",
    "# Students should attempt Exercise 2.2 above before seeing the solution\n",
    "\n",
    "print(\"‚úÖ TA will provide solution during lab walkthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Model Evaluation\n",
    "\n",
    "**Your Task**: Evaluate the performance of your logistic regression model using multiple classification metrics.\n",
    "\n",
    "**Instructions**:\n",
    "1. Calculate accuracy, precision, recall, and F1-score on the test set\n",
    "2. Calculate the ROC-AUC score\n",
    "3. Create and interpret the confusion matrix\n",
    "4. Discuss which metrics are most important for medical diagnosis\n",
    "\n",
    "**Questions to Answer**:\n",
    "- What is the model's performance across different metrics?\n",
    "- In the context of cancer diagnosis, which type of error (false positive vs false negative) is more concerning?\n",
    "- How does this model's performance compare to the baseline?\n",
    "\n",
    "Write your code below to evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.3: Your code here\n",
    "# Assume you have y_test and predictions available from Exercise 2.2\n",
    "\n",
    "# Task 1: Calculate classification metrics\n",
    "# Write your code here for accuracy, precision, recall, F1-score\n",
    "\n",
    "\n",
    "# Task 2: Calculate ROC-AUC score  \n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Task 3: Create and display confusion matrix\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Task 4: Interpret results in medical context\n",
    "# Write your analysis as comments:\n",
    "# - Which metric is most important for cancer diagnosis and why?\n",
    "# - What are the implications of false positives vs false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Part 3 ‚Äî Independent Analysis: Full Feature Model (35 minutes)\n",
    "\n",
    "Now that you've worked through the logistic regression process with the `_mean` features, it's time to apply the same workflow using **all available features** in the dataset. This will give you experience with higher-dimensional data and allow you to compare model performance.\n",
    "\n",
    "### üéØ Your Challenge\n",
    "\n",
    "Repeat the complete logistic regression analysis from Part 2, but this time use **all 30 quantitative features** (mean, standard error, and worst values for each of the 10 characteristics). This represents a more realistic scenario where you have access to the full feature set.\n",
    "\n",
    "**Key Differences from Part 2**:\n",
    "- Use ALL features except the `diagnosis` column (30 features total)\n",
    "- Follow the same workflow: data prep ‚Üí modeling ‚Üí evaluation\n",
    "- Compare results with your Part 2 model using only `_mean` features\n",
    "- Work independently to write all the code\n",
    "\n",
    "### üìã Workflow Steps to Complete\n",
    "\n",
    "1. **Data Preparation**\n",
    "   - Create binary target variable \n",
    "   - Select all quantitative features (exclude 'diagnosis')\n",
    "   - Split into 70-30 train/test (use `RANDOM_STATE` for consistency)\n",
    "\n",
    "2. **Model Training**\n",
    "   - Fit logistic regression model\n",
    "   - Examine and interpret coefficients\n",
    "   - Make predictions on test set\n",
    "\n",
    "3. **Model Evaluation**\n",
    "   - Calculate all classification metrics\n",
    "   - Create confusion matrix\n",
    "   - Compare performance to Part 2 model\n",
    "\n",
    "4. **Analysis and Comparison**\n",
    "   - Which model performs better and why?\n",
    "   - Does using more features always improve performance?\n",
    "   - Which features seem most important for prediction?\n",
    "\n",
    "**Important Notes**:\n",
    "- Work independently on this section\n",
    "- Use the same `RANDOM_STATE` for consistent results\n",
    "- Feel free to ask conceptual questions, but write your own code\n",
    "- We'll review solutions together at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation with All Features\n",
    "\n",
    "**Task**: Prepare the data using all 30 quantitative features instead of just the `_mean` features.\n",
    "\n",
    "Write your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation with All Features\n",
    "# Assume cancer_data DataFrame is available from Part 2\n",
    "\n",
    "# Create binary target variable (if not already done)\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Select ALL quantitative features (exclude 'diagnosis' column)\n",
    "# Hint: You can use cancer_data.drop() or select columns that aren't 'diagnosis'\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Split into training and test sets (70-30 split using RANDOM_STATE)\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Verify your data preparation\n",
    "# Write code to check shapes and feature count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Step 2: Model Training with All Features\n",
    "\n",
    "**Task**: Train a logistic regression model using all 30 features and examine the results.\n",
    "\n",
    "Write your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Model Training with All Features\n",
    "\n",
    "# Fit logistic regression model using RANDOM_STATE\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Examine model coefficients\n",
    "# Write your code here to display intercept and feature coefficients\n",
    "\n",
    "\n",
    "# Make predictions on test set (both binary and probability predictions)\n",
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### Step 3: Model Evaluation and Comparison\n",
    "\n",
    "**Task**: Evaluate your full-feature model and compare it with the `_mean`-only model from Part 2.\n",
    "\n",
    "Write your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Evaluation and Comparison\n",
    "\n",
    "# Calculate all classification metrics for the full-feature model\n",
    "# Write your code here for accuracy, precision, recall, F1-score, ROC-AUC\n",
    "\n",
    "\n",
    "# Create and display confusion matrix\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Compare with Part 2 results\n",
    "# Write code to display metrics from both models side by side\n",
    "\n",
    "\n",
    "# Analysis questions (answer in comments):\n",
    "# 1. Which model performs better overall?\n",
    "# 2. Does using more features improve performance? Why or why not?\n",
    "# 3. Are there any trade-offs between the two models?\n",
    "# 4. In a real medical setting, which model would you prefer and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01564e5",
   "metadata": {},
   "source": [
    "### Step 4: Feature Importance Analysis\n",
    "\n",
    "**Understanding Feature Importance**: \n",
    "\n",
    "While we haven't formally covered feature importance methods yet, we can gain insights about which features matter most in our logistic regression model by examining the **magnitude (absolute value) of the coefficients**.\n",
    "\n",
    "**Key Concept**: In logistic regression, features with **larger absolute coefficient values** have more influence on the prediction. Here's why:\n",
    "\n",
    "- **Large positive coefficient**: Strong evidence that higher values of this feature increase the likelihood of malignancy\n",
    "- **Large negative coefficient**: Strong evidence that higher values of this feature decrease the likelihood of malignancy  \n",
    "- **Small coefficient (near zero)**: This feature has minimal impact on the prediction\n",
    "\n",
    "**For this analysis**, we'll assume that features with the largest absolute coefficient values represent the most influential features in our model. This gives us insight into which measurements are most important for distinguishing between malignant and benign tumors.\n",
    "\n",
    "**Your Task**: Identify which features have the strongest influence on predictions and interpret what this means clinically.\n",
    "\n",
    "Write your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Step 4: Feature Importance Analysis\n",
    "\n",
    "# Find features with largest positive and negative coefficients\n",
    "# Write your code here to identify most influential features\n",
    "\n",
    "\n",
    "# Create a visualization of feature importance (optional)\n",
    "# You could create a bar plot or horizontal bar plot of coefficients\n",
    "\n",
    "\n",
    "# Interpretation questions (answer in comments):\n",
    "# 1. Which features have the strongest positive coefficients (increase malignancy risk)?\n",
    "# 2. Which features have the strongest negative coefficients (decrease malignancy risk)?\n",
    "# 3. Do these results make biological/medical sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "### Step 5 ‚Äî Business Cost Analysis\n",
    "\n",
    "**Question**: Using your full-feature model from Part 3, calculate the business cost of classification errors using the same cost structure from the Default dataset example:\n",
    "\n",
    "- False Negative (missed cancer): $50,000 per case\n",
    "- False Positive (unnecessary alarm): $2,000 per case\n",
    "\n",
    "Compare this with the cost if you used the Part 2 model. Which model is more cost-effective?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2: Business Cost Analysis\n",
    "\n",
    "# Calculate costs for full-feature model (Part 3)\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Calculate costs for mean-only model (Part 2) \n",
    "# Write your code here\n",
    "\n",
    "\n",
    "# Compare total costs and determine which model is more cost-effective\n",
    "# Write your analysis here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446bc66c",
   "metadata": {},
   "source": [
    "## üéì Lab Summary & Wrap-Up\n",
    "\n",
    "### ‚úÖ What You Accomplished Today\n",
    "\n",
    "Congratulations! You've completed a comprehensive analysis of classification models using real medical data. Here's what you mastered:\n",
    "\n",
    "**Part 1 - Review**: \n",
    "- Complete logistic regression workflow with Default dataset\n",
    "- Understanding baseline ratios and model evaluation metrics\n",
    "- Interpreting results in business context (credit risk)\n",
    "\n",
    "**Part 2 - Guided Practice**:\n",
    "- Loading and exploring the Breast Cancer Wisconsin dataset\n",
    "- Data preparation with feature selection (`_mean` features only)\n",
    "- Model training and coefficient interpretation\n",
    "- Classification evaluation in medical context\n",
    "\n",
    "**Part 3 - Independent Analysis**:\n",
    "- Building models with all 30 features\n",
    "- Comparing model performance across different feature sets\n",
    "- Understanding trade-offs between model complexity and performance\n",
    "\n",
    "### üìä Key Results to Save\n",
    "\n",
    "**üö® IMPORTANT: Save Your Results for Homework! üö®**\n",
    "\n",
    "Make sure you have calculated and recorded the following results from your analysis:\n",
    "\n",
    "**From Part 3 (All Features Model)**:\n",
    "- [ ] Training/test set sizes and malignant rates\n",
    "- [ ] Model coefficients for each `_mean` feature\n",
    "- [ ] Classification metrics: accuracy, precision, recall, F1-score, ROC-AUC\n",
    "- [ ] Comparison of performance between mean-only vs full-feature models\n",
    "- [ ] Feature importance insights (which features have strongest coefficients)\n",
    "- [ ] Business cost analysis\n",
    "\n",
    "### üí° Key Learning Insights\n",
    "\n",
    "**Model Performance**:\n",
    "- How does adding more features affect model performance?\n",
    "- Which evaluation metrics are most important for medical diagnosis?\n",
    "- What are the trade-offs between false positives and false negatives in healthcare?\n",
    "\n",
    "**Business Context**:\n",
    "- Why might a model with high accuracy still be problematic for medical use?\n",
    "- How do business costs influence model selection and threshold decisions?\n",
    "- What factors beyond accuracy should influence model deployment decisions?\n",
    "\n",
    "### üìã Next Steps & Homework Preparation\n",
    "\n",
    "**This Week's Homework**: \n",
    "Your homework will include specific questions about the models you built today. Make sure you can access:\n",
    "- Your model performance metrics\n",
    "- Specific coefficient values\n",
    "- Predictions for individual observations\n",
    "- Cost analysis results\n",
    "\n",
    "**Study Tips**:\n",
    "- Review Chapter 23 (Logistic Regression) and Chapter 24 (Classification Evaluation)\n",
    "- Practice interpreting confusion matrices and ROC curves\n",
    "- Understand the business implications of different error types\n",
    "\n",
    "### üîß Before You Leave\n",
    "\n",
    "**Save Your Work**:\n",
    "1. **Save this notebook** with all your completed code and results\n",
    "2. **Take screenshots** of key results (confusion matrices, metric summaries)\n",
    "3. **Export your notebook** (File ‚Üí Download as ‚Üí HTML) as a backup\n",
    "4. **Note key variable names** you used (e.g., model names, prediction arrays)\n",
    "\n",
    "**Double-Check Your Results**:\n",
    "- Did you use `RANDOM_STATE = 42` consistently?\n",
    "- Are your train/test splits 70-30?\n",
    "- Do you have both probability and binary predictions saved?\n",
    "- Are your model performance metrics calculated correctly?\n",
    "\n",
    "---\n",
    "\n",
    "**üéØ Great work today!** You've gained hands-on experience with real-world classification problems and learned to evaluate models from both statistical and business perspectives. These skills are essential for data-driven decision making in healthcare, finance, and many other industries.\n",
    "\n",
    "**Questions?** If you have any questions about your results or need clarification on concepts, reach out before the homework is due. Make sure you understand not just how to calculate the metrics, but what they mean in the context of medical diagnosis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
