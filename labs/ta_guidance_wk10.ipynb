{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TA Guidance: Week 10 Lab - Logistic Regression and Classification Evaluation\n",
    "\n",
    "## üéØ Lab Overview and Teaching Philosophy\n",
    "\n",
    "**Critical Understanding:** This lab serves as **BOTH** the in-class Thursday lab **AND** the weekly homework assignment. Students will complete Part 2 exercises with TA guidance, but Part 3 is their independent homework that should NOT be provided with solutions.\n",
    "\n",
    "### Learning Objectives\n",
    "- Students will apply the complete logistic regression workflow: data preparation, model fitting, and interpretation\n",
    "- Students will calculate and interpret baseline ratios for imbalanced classification problems\n",
    "- Students will evaluate classification models using precision, recall, F1-score, and ROC-AUC metrics\n",
    "- Students will select appropriate evaluation metrics based on business context and error costs\n",
    "\n",
    "### Time Allocation & Teaching Strategy\n",
    "- **Part 1 (10 minutes)**: TA presents complete Default dataset workflow\n",
    "- **Part 2 (25 minutes)**: **Guided student exercises** - TA provides progressive support\n",
    "- **Part 3 (35 minutes)**: **Independent homework work** - NO solutions provided\n",
    "- **Wrap-up (5 minutes)**: Homework reminders and save instructions\n",
    "\n",
    "### Content Alignment\n",
    "- Directly reinforces Tuesday's slides on logistic regression and classification\n",
    "- Provides hands-on practice with concepts from Chapters 23-24\n",
    "- Uses real medical data for authentic business context\n",
    "- Bridges credit risk (Part 1) and medical diagnosis (Parts 2-3) applications\n",
    "\n",
    "## üõ†Ô∏è Pre-Lab Setup Instructions\n",
    "\n",
    "**Technical Setup:**\n",
    "- Ensure all students can access Google Colab and load the lab notebook\n",
    "- Test that breast cancer dataset URL loads correctly\n",
    "- Verify sklearn imports work properly\n",
    "- Have backup plan for dataset loading issues\n",
    "\n",
    "**Important Teaching Approach:**\n",
    "- **Part 2**: Provide progressive help - allow 5-10 minutes independent work, then provide hints/solutions\n",
    "- **Part 3**: Students work completely independently - this is their homework\n",
    "\n",
    "**Materials Needed:**\n",
    "- Lab notebook: `10_wk10_lab.ipynb`\n",
    "- This TA guidance notebook\n",
    "- Access to course datasets\n",
    "\n",
    "## üìö Key Concepts to Emphasize\n",
    "\n",
    "1. **Classification vs Regression**: This week we predict categories (malignant/benign) not continuous values\n",
    "2. **Business Context Matters**: Medical diagnosis has very different error costs than credit risk\n",
    "3. **Multiple Metrics Needed**: Unlike regression's R¬≤, classification requires precision, recall, F1-score, ROC-AUC\n",
    "4. **Baseline Comparison**: Always compare model performance to the baseline (naive) prediction\n",
    "5. **Consistent Random State**: Students must use RANDOM_STATE = 42 for reproducible homework results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Teaching Guide: Default Dataset Review (10 minutes)\n",
    "\n",
    "### Teaching Approach for Part 1\n",
    "- **Rapid walkthrough**: Students should follow along but this is review material\n",
    "- **Emphasize business context**: \"Credit companies need to identify customers likely to default\"\n",
    "- **Highlight workflow**: This systematic approach applies to any classification problem\n",
    "- **Interpret metrics meaningfully**: Connect each metric to business implications\n",
    "- **Set expectations**: \"You'll apply this same workflow to medical data next\"\n",
    "\n",
    "### Key Teaching Points:\n",
    "- **Baseline matters**: 3.3% default rate means naive \"always predict no default\" is 96.7% accurate\n",
    "- **Imbalanced data**: Default detection is challenging because defaults are rare\n",
    "- **Coefficient interpretation**: Positive coefficient means feature increases default probability\n",
    "- **Evaluation complexity**: High accuracy (97.3%) but low recall (26.6%) - what does this mean?\n",
    "- **Business implications**: Missing 73% of defaulters costs real money\n",
    "\n",
    "### Critical Insights to Emphasize:\n",
    "- **ROC-AUC (0.947)**: Model is excellent at ranking customers by risk\n",
    "- **Low recall problem**: Model misses most actual defaulters\n",
    "- **Threshold sensitivity**: Default 0.5 threshold may not be optimal for business\n",
    "- **Cost considerations**: False negatives (missed defaults) much more expensive than false positives\n",
    "\n",
    "### Transition to Part 2:\n",
    "\"Now you'll apply this same systematic approach to medical diagnosis data. The workflow is identical, but the business context and error costs are completely different. Let's see how that changes our interpretation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Teaching Strategy: Guided Student Exercises (25 minutes)\n",
    "\n",
    "### üö® Critical Teaching Philosophy for Part 2\n",
    "\n",
    "**Progressive Guidance Approach:**\n",
    "1. **Give students 5-10 minutes** to work independently on each exercise\n",
    "2. **Check in with the class** - \"How is everyone doing?\"\n",
    "3. **Provide hints or solutions** as needed to keep progress moving\n",
    "4. **Walk through solutions** for exercises they struggle with\n",
    "5. **Ensure everyone completes Part 2** before moving to Part 3\n",
    "\n",
    "### Exercise 2.1: Data Loading and Exploration (8 minutes)\n",
    "**Student Work Time**: 5 minutes independent, then 3 minutes guided solutions\n",
    "\n",
    "**Common Questions & Support:**\n",
    "- \"How do I check dataset shape?\" ‚Üí `cancer_data.shape`\n",
    "- \"How do I calculate percentages?\" ‚Üí `(cancer_data['diagnosis'] == 'M').mean()`\n",
    "- \"What's the baseline?\" ‚Üí Explain that 62.7% benign means predicting \"always benign\" gives 62.7% accuracy\n",
    "\n",
    "**Key Teaching Moments:**\n",
    "- **Dataset context**: Real medical data from University of Wisconsin\n",
    "- **Balanced vs imbalanced**: 37.3% malignant is much more balanced than 3.3% default rate\n",
    "- **Missing data**: Clean dataset makes modeling simpler\n",
    "\n",
    "### Exercise 2.2: Data Preparation and Modeling (10 minutes)  \n",
    "**Student Work Time**: 7 minutes independent, then 3 minutes guided solutions\n",
    "\n",
    "**Common Issues & Solutions:**\n",
    "- \"How do I create binary target?\" ‚Üí `(cancer_data['diagnosis'] == 'M').astype(int)`\n",
    "- \"List comprehension confusion\" ‚Üí Show alternative: `cancer_data.filter(regex='_mean$')`\n",
    "- \"Train/test split syntax\" ‚Üí Emphasize `random_state=RANDOM_STATE` for consistency\n",
    "- \"Coefficient interpretation\" ‚Üí Positive = increases malignancy risk, negative = decreases risk\n",
    "\n",
    "**Key Teaching Moments:**\n",
    "- **Feature selection rationale**: Starting with mean features for simplicity\n",
    "- **Random state importance**: Must be consistent for homework questions\n",
    "- **Coefficient magnitudes**: Larger absolute values = stronger influence\n",
    "- **Medical interpretation**: Connect coefficients to cell biology\n",
    "\n",
    "### Exercise 2.3: Model Evaluation (7 minutes)\n",
    "**Student Work Time**: 5 minutes independent, then 2 minutes guided solutions\n",
    "\n",
    "**Critical Teaching Points:**\n",
    "- **Precision vs Recall trade-off**: In medical diagnosis, recall (catching cancer) often more important\n",
    "- **False negative cost**: Missing cancer diagnosis can be life-threatening\n",
    "- **False positive cost**: Unnecessary anxiety and additional testing\n",
    "- **ROC-AUC interpretation**: Measures ranking ability independent of threshold\n",
    "\n",
    "**Expected Results Discussion:**\n",
    "- Model should perform much better than credit default model\n",
    "- Higher precision/recall due to more balanced dataset\n",
    "- Medical context changes which metrics matter most\n",
    "\n",
    "### Solutions Timing:\n",
    "- **If students struggle**: Provide solutions earlier to maintain momentum\n",
    "- **If students succeed**: Let them work longer independently\n",
    "- **Always ensure**: Everyone completes Part 2 before Part 3 begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Teaching Strategy: Independent Homework Work (35 minutes)\n",
    "\n",
    "### üö® CRITICAL: NO SOLUTIONS FOR PART 3\n",
    "\n",
    "**Part 3 is the students' homework assignment. You must NOT provide step-by-step solutions or complete answers.**\n",
    "\n",
    "### Your Role During Part 3:\n",
    "1. **Circulate and observe**: Walk around, check in with individual students\n",
    "2. **Answer conceptual questions**: Help with understanding, not code solutions\n",
    "3. **Provide strategic hints**: Guide thinking without giving away answers\n",
    "4. **Debug syntax errors**: Help with Python/pandas syntax issues\n",
    "5. **Encourage persistence**: \"This is challenging - keep working through it\"\n",
    "\n",
    "### What YOU CAN Do:\n",
    "- ‚úÖ **Help with syntax errors**: \"You need double brackets for single feature selection\"\n",
    "- ‚úÖ **Clarify concepts**: \"Recall measures how many actual cancer cases we catch\"\n",
    "- ‚úÖ **Provide general guidance**: \"Try using the same workflow as Part 2 but with all features\"\n",
    "- ‚úÖ **Answer method questions**: \"Use cancer_data.drop(['diagnosis'], axis=1) to select all features except diagnosis\"\n",
    "\n",
    "### What YOU CANNOT Do:\n",
    "- ‚ùå **Write complete code solutions**: Let students struggle and learn\n",
    "- ‚ùå **Provide specific numerical answers**: These will be used for homework grading\n",
    "- ‚ùå **Walk through the entire workflow**: They need to apply what they learned\n",
    "- ‚ùå **Give away the analysis insights**: Let them discover the model comparison results\n",
    "\n",
    "### Strategic Support Approaches:\n",
    "\n",
    "**For Data Preparation Questions:**\n",
    "- *Student*: \"How do I select all features?\"\n",
    "- *TA*: \"Think about what columns you want to exclude. The `drop()` method might be helpful.\"\n",
    "\n",
    "**For Model Building Questions:**\n",
    "- *Student*: \"My model won't fit\"\n",
    "- *TA*: \"Check your feature matrix shape. Does it look right? Are there any missing values?\"\n",
    "\n",
    "**For Interpretation Questions:**\n",
    "- *Student*: \"Which model is better?\"\n",
    "- *TA*: \"Look at your metrics. In medical diagnosis, which metrics matter most? Why?\"\n",
    "\n",
    "**For Code Errors:**\n",
    "- *Student*: \"I'm getting an error\"\n",
    "- *TA*: \"What does the error message say? Let's debug that specific issue.\"\n",
    "\n",
    "### Time Management:\n",
    "- **First 15 minutes**: Let students work independently, minimal intervention\n",
    "- **Middle 15 minutes**: Increase circulation, provide strategic hints\n",
    "- **Final 5 minutes**: Ensure students save their work, remind about homework status\n",
    "\n",
    "### Managing Student Frustration:\n",
    "- **Normalize the challenge**: \"This is homework-level difficulty - it's supposed to be challenging\"\n",
    "- **Encourage persistence**: \"The struggle is where the learning happens\"\n",
    "- **Provide emotional support**: \"You have all the tools you need from Part 2\"\n",
    "- **Remind of resources**: \"You can reference Part 2 solutions and Tuesday's materials\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Solutions - FOR TA REFERENCE AND GUIDED INSTRUCTION\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT**: Use these solutions to guide students through Part 2 exercises progressively. After students work independently for 5-10 minutes, provide hints or show solutions as needed.\n",
    "\n",
    "### Setup Code (Students should have this completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "from ISLP import load_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1 Solutions: Data Loading and Exploration\n",
    "\n",
    "**Teaching Notes**: Walk through these solutions after students work independently for 5 minutes. Emphasize the business context and dataset characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.1 Solutions\n",
    "\n",
    "# URL for the breast cancer dataset (already provided)\n",
    "url = \"https://raw.githubusercontent.com/bradleyboehmke/uc-bana-4080/refs/heads/main/data/breast_cancer.csv\"\n",
    "\n",
    "# Task 1: Load the dataset (PROVIDED)\n",
    "cancer_data = pd.read_csv(url)\n",
    "print(\"‚úÖ Breast Cancer Wisconsin dataset loaded successfully!\")\n",
    "\n",
    "# Task 2: Examine dataset structure (shape, columns, first few rows)\n",
    "print(f\"\\n=== Task 2: Dataset Structure ===\")\n",
    "print(f\"Dataset shape: {cancer_data.shape}\")\n",
    "print(f\"Number of observations: {cancer_data.shape[0]}\")\n",
    "print(f\"Number of features: {cancer_data.shape[1]}\")\n",
    "\n",
    "print(f\"\\nColumn names:\")\n",
    "print(cancer_data.columns.tolist())\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(cancer_data.head())\n",
    "\n",
    "# Task 3: Calculate baseline ratio of malignant vs benign diagnoses\n",
    "print(f\"\\n=== Task 3: Baseline Analysis ===\")\n",
    "diagnosis_counts = cancer_data['diagnosis'].value_counts()\n",
    "print(f\"Diagnosis distribution:\")\n",
    "print(diagnosis_counts)\n",
    "\n",
    "malignant_rate = (cancer_data['diagnosis'] == 'M').mean()\n",
    "benign_rate = (cancer_data['diagnosis'] == 'B').mean()\n",
    "\n",
    "print(f\"\\nBaseline ratios:\")\n",
    "print(f\"Malignant (M): {malignant_rate:.1%}\")\n",
    "print(f\"Benign (B): {benign_rate:.1%}\")\n",
    "\n",
    "print(f\"\\nBaseline accuracy: {max(malignant_rate, benign_rate):.1%}\")\n",
    "print(f\"(If we always predicted the most common class)\")\n",
    "\n",
    "# Task 4: Check for missing values\n",
    "print(f\"\\n=== Task 4: Missing Values ===\")\n",
    "missing_values = cancer_data.isnull().sum().sum()\n",
    "print(f\"Total missing values: {missing_values}\")\n",
    "\n",
    "if missing_values == 0:\n",
    "    print(\"‚úÖ No missing values - clean dataset!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Found {missing_values} missing values\")\n",
    "    print(cancer_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaching Points for Exercise 2.1:\n",
    "- **569 observations, 31 features**: Substantial dataset for medical research\n",
    "- **37.3% malignant**: Much more balanced than credit default (3.3%)\n",
    "- **No missing values**: Makes analysis straightforward\n",
    "- **Baseline of 62.7%**: Any model should beat this easily\n",
    "- **Real medical data**: Emphasize the importance and responsibility of working with health data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2 Solutions: Data Preparation and Modeling\n",
    "\n",
    "**Teaching Notes**: Students should work on this for 7 minutes, then provide progressive hints. Walk through solutions for any tasks they struggle with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.2 Solutions\n",
    "\n",
    "# Task 1: Create binary target variable (0=Benign, 1=Malignant)\n",
    "print(\"=== Task 1: Binary Target Variable ===\")\n",
    "cancer_data['diagnosis_binary'] = (cancer_data['diagnosis'] == 'M').astype(int)\n",
    "\n",
    "print(f\"Binary encoding:\")\n",
    "print(f\"Benign (B) ‚Üí 0: {(cancer_data['diagnosis_binary'] == 0).sum()} cases\")\n",
    "print(f\"Malignant (M) ‚Üí 1: {(cancer_data['diagnosis_binary'] == 1).sum()} cases\")\n",
    "\n",
    "# Task 2: Select only the features ending with '_mean' (PROVIDED)\n",
    "mean_features = [col for col in cancer_data.columns if col.endswith('_mean')]\n",
    "X_cancer_mean = cancer_data[mean_features]\n",
    "y_cancer = cancer_data['diagnosis_binary']\n",
    "\n",
    "print(f\"\\n=== Task 2: Feature Selection ===\")\n",
    "print(f\"Selected {len(mean_features)} mean features:\")\n",
    "print(f\"Features: {mean_features}\")\n",
    "print(f\"Feature matrix shape: {X_cancer_mean.shape}\")\n",
    "print(f\"Target vector shape: {y_cancer.shape}\")\n",
    "\n",
    "# Task 3: Split data into training and test sets (70-30 split using RANDOM_STATE)\n",
    "print(f\"\\n=== Task 3: Train/Test Split ===\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_cancer_mean, y_cancer, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} observations\")\n",
    "print(f\"Test set: {len(X_test)} observations\")\n",
    "print(f\"Training malignant rate: {y_train.mean():.1%}\")\n",
    "print(f\"Test malignant rate: {y_test.mean():.1%}\")\n",
    "\n",
    "# Task 4: Fit logistic regression model and examine coefficients\n",
    "print(f\"\\n=== Task 4: Model Training ===\")\n",
    "model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Model successfully trained!\")\n",
    "print(f\"\\nModel coefficients:\")\n",
    "print(f\"Intercept: {model.intercept_[0]:.6f}\")\n",
    "\n",
    "print(f\"\\nFeature coefficients:\")\n",
    "for feature, coef in zip(mean_features, model.coef_[0]):\n",
    "    direction = \"‚Üë increases\" if coef > 0 else \"‚Üì decreases\"\n",
    "    print(f\"{feature:20s}: {coef:8.6f} ({direction} malignancy risk)\")\n",
    "\n",
    "# Task 5: Make predictions on test set\n",
    "print(f\"\\n=== Task 5: Predictions ===\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Binary predictions shape: {y_pred.shape}\")\n",
    "print(f\"Probability predictions shape: {y_pred_proba.shape}\")\n",
    "print(f\"Predictions completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaching Points for Exercise 2.2:\n",
    "- **10 mean features**: Covers size, texture, and shape characteristics\n",
    "- **Consistent random state**: Critical for reproducible homework results\n",
    "- **Coefficient interpretation**: Positive = increases cancer risk, negative = protective\n",
    "- **Medical relevance**: Connect coefficients to cell biology (larger nuclei, irregular texture, etc.)\n",
    "- **Two prediction types**: Binary (0/1) for classification, probabilities for ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3 Solutions: Model Evaluation\n",
    "\n",
    "**Teaching Notes**: Allow 5 minutes independent work, then walk through solutions. Emphasize medical context for metric interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.3 Solutions\n",
    "\n",
    "# Task 1: Calculate classification metrics\n",
    "print(\"=== Task 1: Classification Metrics ===\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.1%}\")\n",
    "print(f\"Precision: {precision:.1%}\")\n",
    "print(f\"Recall:    {recall:.1%}\")\n",
    "print(f\"F1-Score:  {f1:.1%}\")\n",
    "\n",
    "# Task 2: Calculate ROC-AUC score\n",
    "print(f\"\\n=== Task 2: ROC-AUC Score ===\")\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC-AUC:   {auc:.3f}\")\n",
    "\n",
    "# Task 3: Create and display confusion matrix\n",
    "print(f\"\\n=== Task 3: Confusion Matrix ===\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"[[{cm[0,0]:4d}, {cm[0,1]:3d}]]\")\n",
    "print(f\"[[{cm[1,0]:4d}, {cm[1,1]:3d}]]\")\n",
    "\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"True Negatives (TN):  {cm[0,0]} (correctly identified benign)\")\n",
    "print(f\"False Positives (FP): {cm[0,1]} (benign misclassified as malignant)\")\n",
    "print(f\"False Negatives (FN): {cm[1,0]} (malignant misclassified as benign)\")\n",
    "print(f\"True Positives (TP):  {cm[1,1]} (correctly identified malignant)\")\n",
    "\n",
    "# Task 4: Interpret results in medical context\n",
    "print(f\"\\n=== Task 4: Medical Context Interpretation ===\")\n",
    "\n",
    "print(f\"\\nüí° What These Metrics Mean for Cancer Diagnosis:\")\n",
    "print(f\"‚Ä¢ Accuracy ({accuracy:.1%}): Overall correctness across all cases\")\n",
    "print(f\"‚Ä¢ Precision ({precision:.1%}): Of patients flagged as having cancer, {precision:.1%} actually do\")\n",
    "print(f\"  ‚Üí {100-precision*100:.1f}% false alarm rate\")\n",
    "print(f\"‚Ä¢ Recall ({recall:.1%}): We successfully catch {recall:.1%} of actual cancer cases\")\n",
    "print(f\"  ‚Üí We miss {100-recall*100:.1f}% of cancer cases - major concern!\")\n",
    "print(f\"‚Ä¢ F1-Score ({f1:.1%}): Balanced measure of precision and recall\")\n",
    "print(f\"‚Ä¢ ROC-AUC ({auc:.3f}): Excellent ability to rank patients by cancer risk\")\n",
    "\n",
    "print(f\"\\nüè• Clinical Implications:\")\n",
    "print(f\"‚Ä¢ False Negatives ({cm[1,0]} cases): Missed cancer diagnoses - potentially life-threatening\")\n",
    "print(f\"‚Ä¢ False Positives ({cm[0,1]} cases): Unnecessary anxiety and additional testing costs\")\n",
    "print(f\"‚Ä¢ In medical screening, RECALL is typically the most critical metric\")\n",
    "print(f\"‚Ä¢ Better to have some false alarms than to miss actual cancer cases\")\n",
    "\n",
    "# Compare to baseline\n",
    "baseline_accuracy = max(y_test.mean(), 1 - y_test.mean())\n",
    "print(f\"\\nüìä Baseline Comparison:\")\n",
    "print(f\"Baseline accuracy (always predict most common class): {baseline_accuracy:.1%}\")\n",
    "print(f\"Model accuracy: {accuracy:.1%}\")\n",
    "print(f\"Improvement over baseline: {accuracy - baseline_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaching Points for Exercise 2.3:\n",
    "- **Medical context changes priorities**: Recall often more important than precision\n",
    "- **Cost of errors differs**: False negatives can be life-threatening\n",
    "- **Multiple metrics needed**: Each tells a different part of the story\n",
    "- **ROC-AUC strength**: Good ranking ability regardless of threshold\n",
    "- **Baseline beating**: Model should significantly outperform naive prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö® Part 3 - NO SOLUTIONS PROVIDED\n",
    "\n",
    "**CRITICAL REMINDER**: Part 3 is the students' homework assignment. Do NOT provide complete solutions or step-by-step walkthroughs.\n",
    "\n",
    "### What You Can Help With:\n",
    "- **Syntax errors**: Python/pandas technical issues\n",
    "- **Conceptual clarification**: \"What does precision mean again?\"\n",
    "- **Method guidance**: \"How do I select all columns except diagnosis?\"\n",
    "- **General workflow**: \"Use the same steps as Part 2 but with all features\"\n",
    "\n",
    "### Expected Student Challenges:\n",
    "1. **Feature selection**: Students may struggle with selecting all 30 features\n",
    "2. **Model comparison**: Deciding which model performs better\n",
    "3. **Feature importance**: Interpreting coefficient magnitudes\n",
    "4. **Business costs**: Calculating false positive/negative costs\n",
    "5. **Threshold analysis**: Understanding how changing thresholds affects metrics\n",
    "\n",
    "### Strategic Hints You Can Provide:\n",
    "- \"Think about which columns you want to exclude from your feature matrix\"\n",
    "- \"Compare the same metrics between your two models\"\n",
    "- \"Look at the absolute values of coefficients to find the most influential features\"\n",
    "- \"Remember the confusion matrix shows you FP and FN counts\"\n",
    "- \"Lower thresholds typically increase recall but decrease precision\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Wrap-Up Guidance (5 minutes)\n",
    "\n",
    "### Key Points to Emphasize:\n",
    "1. **Homework Status**: \"Part 3 is your homework for this week - continue working on it outside class\"\n",
    "2. **Save Everything**: \"Save your notebook with all your results - you'll need them for homework questions\"\n",
    "3. **Business Context**: \"Classification problems are everywhere in business - this workflow applies broadly\"\n",
    "4. **Evaluation Complexity**: \"Classification requires multiple metrics - each tells a different story\"\n",
    "\n",
    "### Critical Reminders:\n",
    "- **Use RANDOM_STATE = 42 consistently**: \"This ensures reproducible results for homework\"\n",
    "- **Save your numerical results**: \"Record your model performance metrics\"\n",
    "- **Complete Part 3 independently**: \"This is your homework - work through it systematically\"\n",
    "- **Export notebook**: \"Download as HTML for backup\"\n",
    "\n",
    "### Preview Next Week:\n",
    "- \"Next Tuesday: Advanced classification algorithms (Random Forest, SVM)\"\n",
    "- \"We'll build on today's evaluation framework with more sophisticated models\"\n",
    "- \"The train/test methodology you learned applies to all machine learning models\"\n",
    "\n",
    "## üö® Common Issues & Solutions\n",
    "\n",
    "### Technical Issues:\n",
    "1. **Import errors**: Ensure sklearn version is recent enough\n",
    "2. **Dataset loading**: Provide backup CSV if URL fails\n",
    "3. **Random state confusion**: Emphasize consistency across all splits\n",
    "4. **Feature selection**: Students may include diagnosis column accidentally\n",
    "\n",
    "### Conceptual Issues:\n",
    "1. **Metric interpretation**: Keep connecting back to business context\n",
    "2. **Threshold understanding**: Use simple examples (\"stricter vs lenient screening\")\n",
    "3. **Model comparison**: Help students think about what \"better\" means\n",
    "4. **Feature importance**: Emphasize absolute coefficient values\n",
    "\n",
    "### Time Management:\n",
    "- If behind schedule: Focus on completing Part 2, let students finish Part 3 as homework\n",
    "- If ahead of schedule: Encourage deeper discussion of medical ethics and model deployment\n",
    "- Always preserve time for save/export reminders\n",
    "\n",
    "## üìã Post-Lab Checklist\n",
    "\n",
    "**For TAs:**\n",
    "- [ ] All students completed Part 2 with understanding\n",
    "- [ ] Students understand Part 3 is their homework\n",
    "- [ ] Save/export instructions clearly communicated\n",
    "- [ ] Students know to use consistent random states\n",
    "- [ ] Note any concepts that need reinforcement next week\n",
    "\n",
    "**For Students:**\n",
    "- [ ] Have working Part 2 solutions for reference\n",
    "- [ ] Understand the medical context of classification metrics\n",
    "- [ ] Know how to interpret precision, recall, F1-score, ROC-AUC\n",
    "- [ ] Ready to work independently on Part 3 (homework)\n",
    "- [ ] Have saved their notebook with all results\n",
    "\n",
    "---\n",
    "\n",
    "**Lab Success Metrics:**\n",
    "- Students can build and evaluate classification models independently\n",
    "- Students understand the business context drives metric selection\n",
    "- Students can interpret results in medical/business terms\n",
    "- Students are prepared to complete Part 3 as homework\n",
    "- Students understand the importance of proper model evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
